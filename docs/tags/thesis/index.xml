<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hippocamplus </title>
    <link>/Hippocamplus/tags/thesis/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2018</rights>
    <updated>2018-05-07 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>Converting scientific reviews to EPUB</title>
          <link>/Hippocamplus/2018/05/07/epub-reviews/</link>
          <pubDate>Mon, 07 May 2018 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2018/05/07/epub-reviews/</guid>
          <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#first-check-on-pubmed-central&#34;&gt;First, check on PubMed Central&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#convert-the-html-page-to-epub&#34;&gt;Convert the HTML page to EPUB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#clean-up-the-html-before-conversion&#34;&gt;Clean up the HTML before conversion&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#compiling-several-reviews-into-one-epub-document&#34;&gt;Compiling several reviews into one EPUB document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vpn-paywall-and-pandoc&#34;&gt;VPN, paywall and Pandoc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limitations&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#methods&#34;&gt;Methods&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-epub-resources&#34;&gt;Other EPUB resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;Third post on the series of &lt;em&gt;“Things I did instead of writing my thesis to help me write my thesis”&lt;/em&gt;: how to find/convert reviews in the EPUB format to read in an ebook reader.&lt;/p&gt;
&lt;p&gt;To motivate myself to write the thesis introduction and get some “style” inspiration, I read a few reviews. Reviews are longer and often more wordy than original research articles so I’d sometimes prefer to use my e-reader. It’s more compact and the e-ink is more comfortable to read, especially outside. But I find PDFs a bit awkward to use on an e-reader so it would be better to have the reviews in a e-reader format like EPUB.&lt;/p&gt;
&lt;p&gt;In my experience, this is the best strategy to get a review in EPUB format:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Check if available on PubMed Central.&lt;/li&gt;
&lt;li&gt;If not, download HTML page and convert with Pandoc.
&lt;ul&gt;
&lt;li&gt;If &lt;em&gt;Nature Reviews&lt;/em&gt; or &lt;em&gt;Annual Reviews&lt;/em&gt;, clean up the HTML file before conversion.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For &lt;em&gt;Nature Reviews&lt;/em&gt; and &lt;em&gt;Annual Reviews&lt;/em&gt;, the script I wrote can also merge several reviews into one EPUB ebook.&lt;/p&gt;
&lt;div id=&#34;first-check-on-pubmed-central&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First, check on PubMed Central&lt;/h2&gt;
&lt;p&gt;In the top-right corner of the article page there is a &lt;em&gt;ePub&lt;/em&gt; option (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3612533/&#34;&gt;example&lt;/a&gt;). This feature has been in &lt;em&gt;beta&lt;/em&gt; version for years but the EPUB files are really good.&lt;/p&gt;
&lt;p&gt;Unfortunately, many articles/reviews are not available through PMC, including the majority of reviews from dedicated journals like &lt;a href=&#34;https://www.nature.com/nrg/&#34;&gt;Nature Reviews Genetics&lt;/a&gt; and &lt;a href=&#34;https://www.annualreviews.org/journal/genet&#34;&gt;Annual Review of Genetics&lt;/a&gt;. For example, there are more than a thousand reviews from Nature Reviews Genetics on PubMed, but only &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/?term=%22nat+rev+genet%22%5BJournal%5D&#34;&gt;200-300 available on PubMed Central&lt;/a&gt;. Same for Annual Review of Genetics which has &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/?term=%22annual+review+of+genetics%22%5BJournal%5D&#34;&gt;~70 reviews available on PMC&lt;/a&gt; but almost 1K indexed on PubMed.&lt;/p&gt;
&lt;p&gt;If it’s not available in PMC (and the journal doesn’t provide an EPUB file), no choice but to manually convert to EPUB.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;convert-the-html-page-to-epub&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Convert the HTML page to EPUB&lt;/h2&gt;
&lt;p&gt;Rather than trying to convert the PDF, I found it easier to convert the HTML page. EPUB is a XML-based format which is quite close to the HTML anyway so it should be the way to go.&lt;/p&gt;
&lt;p&gt;After saving the webpage locally, the HTML file can be converted with &lt;a href=&#34;http://pandoc.org/index.html&#34;&gt;Pandoc&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;pandoc webpage-i-manually-downloaded.html -o webpage-i-manually-downloaded.epub&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Usually, the result is &lt;strong&gt;readable but not very practical&lt;/strong&gt; because the interface of the website is polluting the ebook, many links are external (pointing at webpages), and content is sometimes missing. It’s annoying not being able to click on the reference/figure links (or clicking inadvertently and opening a web browser), having to skip dozens of pages to get to the content, or missing information because they needed to be “expanded” on the website.&lt;/p&gt;
&lt;p&gt;There are exceptions. For example the &lt;strong&gt;“&lt;em&gt;Opportunities and obstacles for deep learning in biology and medicine&lt;/em&gt;”&lt;/strong&gt;, a cool (and long) review which was published in &lt;a href=&#34;http://rsif.royalsocietypublishing.org/content/15/141/20170387&#34;&gt;the Journal of the Royal Society Interface&lt;/a&gt;, is also formatted in &lt;a href=&#34;https://greenelab.github.io/deep-review/&#34;&gt;a GitHub HTML page&lt;/a&gt;. The manuscript is actually written and build using Markdown/GitHub (I want to learn how to do that at some point). Anyway, the GitHub webpage was straightforward to convert with Pandoc and produced a perfect EPUB version of the review.&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;wget -p https://greenelab.github.io/deep-review/
cd greenelab.github.io/deep-review
pandoc index.html -o DeepLearningBioMed.epub&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;clean-up-the-html-before-conversion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Clean up the HTML before conversion&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;For Nature Reviews and Annual Reviews&lt;/strong&gt;, I wrote a small R script that downloads a HTML page and:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Keeps only the article content (remove the rest of the webpage).&lt;/li&gt;
&lt;li&gt;Fixes the table of content.&lt;/li&gt;
&lt;li&gt;Fixes links to reference/figure/glossary in the text.&lt;/li&gt;
&lt;li&gt;Makes the figures not clickable.&lt;/li&gt;
&lt;li&gt;Removes external links around references and images.&lt;/li&gt;
&lt;li&gt;Simplify complex tables to allow for EPUB display.&lt;/li&gt;
&lt;li&gt;Shows the content of a &lt;em&gt;box&lt;/em&gt; even if hidden in the webpage.&lt;/li&gt;
&lt;li&gt;Replaces low-resolution figure with high-resolution (for Annual Reviews).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I put the &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/R/epubifyReviews&#34;&gt;two R scripts on GitHub&lt;/a&gt;. Using the URL of the review, run this to clean up the HTML and call Pandoc:&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;Rscript epubify-annualreviews.R -i https://www.annualreviews.org/doi/full/10.1146/annurev-genet-120215-034854
## or
Rscript epubify-naturereviews.R -i https://www.nature.com/articles/nrg.2015.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;The scripts rely on the &lt;a href=&#34;https://github.com/hadley/rvest&#34;&gt;rvest package&lt;/a&gt; (&lt;code&gt;install.packages(&#39;rvest&#39;)&lt;/code&gt; to install in &lt;code&gt;R&lt;/code&gt;) and the &lt;a href=&#34;https://yihui.name/knitr/&#34;&gt;knitr package&lt;/a&gt; (&lt;code&gt;install.packages(&#39;knitr&#39;)&lt;/code&gt; to install in &lt;code&gt;R&lt;/code&gt;).&lt;/em&gt; &lt;em&gt;It also assumes that &lt;code&gt;pandoc&lt;/code&gt; is installed.&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;compiling-several-reviews-into-one-epub-document&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Compiling several reviews into one EPUB document&lt;/h3&gt;
&lt;p&gt;Some reviews or articles are part of collections, like the “Points of significance” serie in Nature Methods. It would be nice to convert these articles into one EPUB.&lt;/p&gt;
&lt;p&gt;To do this both scripts can loop over URLs in a list and produce one EPUB. The &lt;code&gt;-i&lt;/code&gt; argument should be a text file with one URL per line, and the &lt;code&gt;-list&lt;/code&gt; argument should be added to switch on the “list” mode. Optional, you can specify a title using the &lt;code&gt;-title&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;I don’t think I’m allowed to share publicly the &lt;strong&gt;“Points of Significance” EPUB&lt;/strong&gt; but I can share the commands I used (see &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/R/epubifyReviews&#34;&gt;instructions on GitHub&lt;/a&gt;). There are also commands to download &lt;strong&gt;collections&lt;/strong&gt; of Nature Reviews (e.g. Genome Editing or Computational Tools) or search results for Annual Reviews (e.g. Microbiome &amp;amp; Sequencing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vpn-paywall-and-pandoc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;VPN, paywall and Pandoc&lt;/h3&gt;
&lt;p&gt;The script and Pandoc will try to download the text/images so &lt;strong&gt;they should be used behind the university’s VPN (or at the university).&lt;/strong&gt; For Nature Reviews, the page can also be downloaded locally and used instead of the URL argument. That might be useful if the articles are accessed by logging in through the web browser (e.g. McGill’s &lt;a href=&#34;http://www.mcgill.ca/library/services/connect&#34;&gt;EZproxy system&lt;/a&gt;). For Annual Reviews however, the Pandoc command will try to download high-res figures so it’s better to run with a VPN.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Limitations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Tables are “simplified” which makes them uglier but compatible with EPUB. For example, a multi-rows label is repeated in each row.&lt;/li&gt;
&lt;li&gt;If/when the websites change, the scripts will need to be adapted.&lt;/li&gt;
&lt;li&gt;This is &lt;a href=&#34;https://togelius.blogspot.ca/2016/04/the-differences-between-tinkering-and.html&#34;&gt;tinkering&lt;/a&gt; so it’s possible that some pages won’t work properly. The ones I tried worked but I didn’t test that many.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;methods&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Methods&lt;/h3&gt;
&lt;p&gt;The scripts use functions from the &lt;a href=&#34;https://github.com/hadley/rvest&#34;&gt;&lt;em&gt;rvest&lt;/em&gt;&lt;/a&gt; package to download the HTML code of a webpage. Then they use three different strategies to clean up the HTML code. Sometimes &lt;em&gt;rvest&lt;/em&gt;’s functions can directly select the relevant parts. Many times, the HTML code is modified using &lt;code&gt;gsub&lt;/code&gt; and regular expressions. A few times the script writes new HTML code based on information retrieved using &lt;em&gt;rvest&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Tables are converted into &lt;em&gt;data.frames&lt;/em&gt; with &lt;code&gt;html_table&lt;/code&gt;, then converted back to HTML usint &lt;a href=&#34;https://yihui.name/knitr/&#34;&gt;&lt;em&gt;knitr&lt;/em&gt;&lt;/a&gt;’s &lt;code&gt;kable&lt;/code&gt; function. In &lt;em&gt;list&lt;/em&gt; mode, the script loops through URLs from the input file and concatenate the cleaned HTML code. At the end, the final HTML code is written in a file which is converted to EPUB by &lt;a href=&#34;http://pandoc.org/index.html&#34;&gt;Pandoc&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;other-epub-resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other EPUB resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Books&lt;/strong&gt; from the &lt;a href=&#34;https://link.springer.com/bookseries/7651&#34;&gt;Methods in Molecular Biology&lt;/a&gt; series can be downloaded in the EPUB format.&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;http://collections.plos.org/translational-bioinformatics&#34;&gt;Translational Bioinformatics collection&lt;/a&gt; in PLoS Computational Biology has &lt;a href=&#34;http://www.ploscollections.org/downloads/TranslationalBioinformatics.epub&#34;&gt;an ePub option&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Additional checks for a LaTeX manuscript</title>
          <link>/Hippocamplus/2018/04/18/check-latex-pub/</link>
          <pubDate>Wed, 18 Apr 2018 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2018/04/18/check-latex-pub/</guid>
          <description>&lt;p&gt;To continue on the series of &lt;em&gt;“Things I did instead of writing my thesis to help me write my thesis”&lt;/em&gt;, another Python script that reads a LaTeX manuscript and helps check that everything is fine. More specifically, the &lt;code&gt;checkLatex.py&lt;/code&gt; script (&lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/python/checkLatex&#34;&gt;on GitHub&lt;/a&gt;) will:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;List missing references.&lt;/li&gt;
&lt;li&gt;List multi-references to reorder.&lt;/li&gt;
&lt;li&gt;List duplicated labels.&lt;/li&gt;
&lt;li&gt;List labels that don’t start by &lt;code&gt;fig:&lt;/code&gt; or &lt;code&gt;tab:&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;List figures/tables that are not in order.&lt;/li&gt;
&lt;li&gt;List &lt;em&gt;??&lt;/em&gt;, &lt;em&gt;REF&lt;/em&gt; or &lt;em&gt;XX&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;List acronyms in italic (for gene names).&lt;/li&gt;
&lt;li&gt;List acronyms in serif (for method names).&lt;/li&gt;
&lt;li&gt;List acronyms not in italic nor in serif.&lt;/li&gt;
&lt;li&gt;Shows the first usage of each acronym (not in italic/serif).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This was particularly useful for my thesis because I combined three manuscripts and a general intro. I had to make sure that the labels, acronyms, references were all correct and consistent throughout the thesis. I might still use this again on smaller documents like research manuscripts.&lt;/p&gt;
&lt;div id=&#34;why-this-output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why this output?&lt;/h2&gt;
&lt;p&gt;“&lt;em&gt;List missing references&lt;/em&gt;” because &lt;code&gt;bibtex&lt;/code&gt; output was sandwiched between long latex logs and it was easy to do. “&lt;em&gt;List multi-references to reorder&lt;/em&gt;” is to transform “something&lt;sup&gt;19,3,12&lt;/sup&gt;” into “something&lt;sup&gt;3,12,19&lt;/sup&gt;”. Not a big deal but I prefer when it’s ordered…&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;List duplicated labels&lt;/em&gt;” helped merge manuscripts in the thesis but won’t be very useful in general. “&lt;em&gt;List labels that don’t start by &lt;code&gt;fig:&lt;/code&gt; or &lt;code&gt;tab:&lt;/code&gt;&lt;/em&gt;” to make sure that figures and tables have labels starting with &lt;code&gt;fig:&lt;/code&gt; or &lt;code&gt;tab:&lt;/code&gt; (it helps for the next check). “&lt;em&gt;List figures/tables that are not in order&lt;/em&gt;” to make sure the figure/table numbers are in ascending order in the text. It checks for the order of labels in each file separately. That way if the supplementary material is in a separate file (using &lt;code&gt;\input&lt;/code&gt;), the supp figs are considered separately from other figures. It’s not perfect though, because the script doesn’t “understand” sub-figures.&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;List ??, REF or XX&lt;/em&gt;” because that’s what I use when I’m writing and missing a number or reference.&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;List acronyms in italic (for gene names)&lt;/em&gt;” to make sure that acronyms in italic are gene names. “&lt;em&gt;List acronyms in serif (for method names)&lt;/em&gt;” to make sure that acronyms in serif are methods names. “&lt;em&gt;List acronyms not in italic nor in serif&lt;/em&gt;” to check if I forgot to put a gene name in italic or a method in serif. It also helped listing the abbreviations at the beginning of the thesis. “&lt;em&gt;Shows the first usage of an acronym (not in italic/serif)&lt;/em&gt;” to make sure acronyms are defined properly.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;practical-details&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Practical details&lt;/h2&gt;
&lt;p&gt;The script &lt;strong&gt;assumes that the document is compiled&lt;/strong&gt;. For example, it will use the &lt;code&gt;.bbl&lt;/code&gt; file for the checks on the references.&lt;/p&gt;
&lt;p&gt;It will follow &lt;strong&gt;one level of &lt;code&gt;\input{}&lt;/code&gt;&lt;/strong&gt;. It was enough for my thesis: I had one &lt;code&gt;main.tex&lt;/code&gt; file with &lt;code&gt;\input&lt;/code&gt; commands calling the different chapters. It should be enough for a manuscript in general.&lt;/p&gt;
&lt;p&gt;Acronyms are defined by the regular expression &lt;code&gt;[A-Za-z0-9]*[A-Z]{2}[A-Za-z0-9]*&lt;/code&gt;, i.e. at least two consecutive uppercase letters and any letter/number around.&lt;/p&gt;
&lt;p&gt;Some arguments to switch on/off the acronym mode and internal references as explained in the help output:&lt;/p&gt;
&lt;pre class=&#34;txt&#34;&gt;&lt;code&gt;&amp;gt; python checkLatex.py -h
usage: checkLatex.py [-h] -i TEX [-inrefs] [-noacro]

Check for problems in a LaTeX manuscript.

optional arguments:
  -h, --help  show this help message and exit
  -i TEX      the input tex file
  -inrefs     list non-fig/table internal refs
  -noacro     don&amp;#39;t list acronyms&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;final-check&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Final check&lt;/h2&gt;
&lt;p&gt;I used &lt;code&gt;pdfgrep&lt;/code&gt; to check the final PDF for quotation marks that could result from missing reference/figure/table.&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;pdfgrep &amp;#39;\?&amp;#39; main.pdf&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Checking text similarity between two documents</title>
          <link>/Hippocamplus/2018/04/16/text-similarity/</link>
          <pubDate>Mon, 16 Apr 2018 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2018/04/16/text-similarity/</guid>
          <description>&lt;p&gt;To start the series of &lt;em&gt;“Things I did instead of writing my thesis to help me write my thesis”&lt;/em&gt;, a small Python script that compares two text documents and output similar parts. I did that to avoid auto-plagiarism of my manuscripts’ introduction in the main thesis introduction.&lt;/p&gt;
&lt;p&gt;It’s a very naive approach but sped up the checking process (&lt;a href=&#34;https://xkcd.com/1319/&#34;&gt;maybe worth the time&lt;/a&gt;). It first looks for short exact matches between the two documents, then extends these exact matches and uses the &lt;a href=&#34;https://docs.python.org/2/library/difflib.html&#34;&gt;difflib&lt;/a&gt; module to keep text with a minimum similarity score (default 80%).&lt;/p&gt;
&lt;p&gt;I put the &lt;code&gt;simText.py&lt;/code&gt; Python script &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/python/simText&#34;&gt;on GitHub here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;usage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;Basic command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python simText.py -1 text1.txt -2 text2.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The help page:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python simText.py -h
usage: simText.py [-h] -1 D1 -2 D2 [-k K] [-e EXT] [-s MINSIM] [-tex]

Find similar text between two documents.

optional arguments:
  -h, --help  show this help message and exit
  -1 D1       Text document 1
  -2 D2       Text document 2
  -k K        The number of char for 1st pass. Default 20
  -e EXT      The number of additional char. Default 70
  -s MINSIM   The minimum similarity to define a match. Default 0.8
  -tex        Skip LaTeX header and lines starting with %&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;latex-documents&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;LaTeX documents&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;-tex&lt;/code&gt; option skips the header in LaTeX documents and lines starting with a &lt;code&gt;%&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python simText.py -1 text1.tex -2 text2.tex -tex&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I implemented this because the header and commented lines were annoying me in the output. More would be needed to have a good LaTeX mode but I submitted my thesis already so it will be for another time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;playing-with-the-stringency&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Playing with the stringency&lt;/h3&gt;
&lt;p&gt;By default, the script outputs text that are &lt;strong&gt;at least 80% similar&lt;/strong&gt; (change with &lt;code&gt;-s&lt;/code&gt; argument). To run more or less stringent checks, I play with &lt;code&gt;-e&lt;/code&gt; which controls how long the 80% match must be.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Output&lt;/h2&gt;
&lt;p&gt;The output contains a paragraph for each match. Each paragraph has three lines with the similarity score, the text in the first document, the text in the second document, respectively. For example (with &lt;code&gt;-e 50&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;txt&#34;&gt;&lt;code&gt;S:0.87
T1: tions of a genomic region, which affect DNA copy number, are collectively known as copy number varia
T2: eletions and duplications, which affect DNA copy number, are collectively known as copy number varia&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        </item>
      
    

  </channel>
</rss>
