<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pub on </title>
    <link>/Hippocamplus/tags/pub/</link>
    <description>Recent content in Pub on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 22 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/Hippocamplus/tags/pub/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Syncing Mendeley and PDFs across devices</title>
      <link>/Hippocamplus/2018/09/22/sync-mendeley/</link>
      <pubDate>Sat, 22 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/Hippocamplus/2018/09/22/sync-mendeley/</guid>
      <description>Recently, I’ve been setting up new computers from scratch as I moved from Montreal to Santa Cruz. Like for spring cleaning, it might be a good idea to clarify the system I’ve been using to manage bibliography and PDF annotation.
Briefly I use Mendeley Desktop and also put all PDF files in a Google Drive. Both are synced with my Android tablet. On the tablet, I use the Mendeley app to get information, search etc, but I read/annotate the PDFs from the Google Drive.</description>
    </item>
    
    <item>
      <title>Mental health crisis in science...but careful with nonresponse bias</title>
      <link>/Hippocamplus/2018/07/08/mental-health-crisis-science/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/Hippocamplus/2018/07/08/mental-health-crisis-science/</guid>
      <description>A few month ago, a short paper was published in Nature Biotechnology1 about the mental health crisis in science. It attracted a bit of attention on the news and social media, which is good because it’s an important matter. The article was very good at putting the subject on the table and proposing some solutions, but it picked my curiosity about nonresponse bias.
Issues with the Nature Biotech article The numbers are based on an email survey so one issue is the nonresponse bias: the individuals that responded might not be representative of the population.</description>
    </item>
    
    <item>
      <title>Converting scientific reviews to EPUB</title>
      <link>/Hippocamplus/2018/05/07/epub-reviews/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/Hippocamplus/2018/05/07/epub-reviews/</guid>
      <description>First, check on PubMed Central Convert the HTML page to EPUB Clean up the HTML before conversion Compiling several reviews into one EPUB document VPN, paywall and Pandoc Limitations Methods  Other EPUB resources   Third post on the series of “Things I did instead of writing my thesis to help me write my thesis”: how to find/convert reviews in the EPUB format to read in an ebook reader.</description>
    </item>
    
    <item>
      <title>Additional checks for a LaTeX manuscript</title>
      <link>/Hippocamplus/2018/04/18/check-latex-pub/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/Hippocamplus/2018/04/18/check-latex-pub/</guid>
      <description>To continue on the series of “Things I did instead of writing my thesis to help me write my thesis”, another Python script that reads a LaTeX manuscript and helps check that everything is fine. More specifically, the checkLatex.py script (on GitHub) will:
List missing references. List multi-references to reorder. List duplicated labels. List labels that don’t start by fig: or tab:. List figures/tables that are not in order. List ?</description>
    </item>
    
    <item>
      <title>Checking text similarity between two documents</title>
      <link>/Hippocamplus/2018/04/16/text-similarity/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/Hippocamplus/2018/04/16/text-similarity/</guid>
      <description>To start the series of “Things I did instead of writing my thesis to help me write my thesis”, a small Python script that compares two text documents and output similar parts. I did that to avoid auto-plagiarism of my manuscripts’ introduction in the main thesis introduction.
It’s a very naive approach but sped up the checking process (maybe worth the time). It first looks for short exact matches between the two documents, then extends these exact matches and uses the difflib module to keep text with a minimum similarity score (default 80%).</description>
    </item>
    
    <item>
      <title>Journal comparison</title>
      <link>/Hippocamplus/2018/02/23/journals-comparison/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/Hippocamplus/2018/02/23/journals-comparison/</guid>
      <description>Edit Feb 24: Added variance graph and some examples of suspiciously fast publications.
Edit Feb 25: Added script and data to GitHub.
Some info about journals in my field.
Summary table   Journal Co. IF OA APC Other fees Pub/year Received-to-accepted in days. median (75th perc.)    F1000Research - 1.2 Y 1000 USD -    PeerJ - 2.2 Y 1095 USD - ~1290 ~88 (139)  eLife - 7.</description>
    </item>
    
  </channel>
</rss>