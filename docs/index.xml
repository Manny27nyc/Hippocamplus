<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> </title>
    <link>/Hippocamplus/</link>
    <language>en-us</language>
    <author>Mark Otto</author>
    <rights>(C) 2018</rights>
    <updated>2018-11-12 00:00:00 &#43;0000 UTC</updated>

    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        <item>
          <title>The Formation of the Scientific Mind, Gaston Bachelard - part 1</title>
          <link>/Hippocamplus/2018/11/12/bachelard-formation-esprit-scientifique-part1/</link>
          <pubDate>Mon, 12 Nov 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/11/12/bachelard-formation-esprit-scientifique-part1/</guid>
          <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#quotes-about-science&#34;&gt;Quotes about science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-concept-of-epistemological-obstacle&#34;&gt;The concept of epistemological obstacle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-first-obstacle-the-primary-experiment&#34;&gt;The first obstacle: the primary experiment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#general-knowledge-as-an-obstacle&#34;&gt;General knowledge as an obstacle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#an-example-of-verbal-obstacle-the-sponge&#34;&gt;An example of verbal obstacle: the &lt;em&gt;sponge&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aside-on-education&#34;&gt;Aside on education&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sick-burns&#34;&gt;Sick burns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;These are notes from my reading of &lt;a href=&#34;https://fr.wikipedia.org/wiki/La_Formation_de_l%27esprit_scientifique&#34;&gt;&lt;em&gt;La formation de l’esprit scientifique&lt;/em&gt;&lt;/a&gt; by &lt;a href=&#34;https://en.wikipedia.org/wiki/Gaston_Bachelard&#34;&gt;Gaston Bachelard&lt;/a&gt;. I hesitated a bit but finally decided to write the notes in English. In the end this blog is as much a place to save things I want to remember as a place to practice writing in English and share with other people. There are lots of quotes that I liked. I tried to translate them as best I could.&lt;/p&gt;
&lt;p&gt;This is “part 1” which covers the concept of epistemological obstacle and the first chapters about the primary experiment, images and generalization as obstacles.&lt;/p&gt;
&lt;div id=&#34;quotes-about-science&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quotes about science&lt;/h2&gt;
&lt;p&gt;Let’s warm up with some positive quotes from the opening chapter before focusing on the obstacles.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;La connaissance du réel est une lumière qui projette toujours quelque part des ombres.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Real-world knowledge is a light that always throws shadows somewhere.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;En résumé, l’homme animé par l’esprit scientifique désire sans doute savoir, mais c’est aussitôt pour mieux interroger.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“In summary, the individual moved by the scientific mind surely wants to know, but it’s to better question immediately after.” &lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;En fait, l’histoire des mathématiques est une merveille de régularité. Elle connaît des périodes d’arrêt. Elle ne connaît pas des périodes d’erreurs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“In reality, history of mathematics is a marvel of regularity. It knows some interruption periods. It doesn’t know any error periods.”&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-concept-of-epistemological-obstacle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The concept of epistemological obstacle&lt;/h2&gt;
&lt;p&gt;This is the central concept of this work. The obstacle is not external, it is not caused by observed phenomenon that are too mysterious or complex, or by technological limitations. The epistemological obstacle is internal and ideological. When ideas stagnate or regress, we are facing an epistemological obstacle.&lt;/p&gt;
&lt;p&gt;The epistemological obstacle is studied in two settings: the development of scientific thinking throughout history and in the educational practice.&lt;/p&gt;
&lt;p&gt;The difference between a historian and an epistemologist is that the historian takes ideas as fact, while the epistemologist takes fact as ideas and place them in a system of thoughts. Through the notion of epistemological obstacle, the history of scientific thinking gains a spiritual value.&lt;/p&gt;
&lt;p&gt;The first experiment/observation is the first epistemological obstacle. It looks easy to understand or to generalize, seducing us into believing that we understand the beauty of nature. It usually comes with a sense of marvel as it’s the first time it’s observed or “understood”. We think we understand and that’s the obstacle.&lt;/p&gt;
&lt;p&gt;The second obstacle is to follow hasty generalizations like the ones that emerge from the primary experiment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Comme le dit si bien d’Alembert, on généralise ses premières remarques, l’instant d’après qu’on ne remarquait rien.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Like d’Alembert nicely stated, we generalize our first observations, the moment after we didn’t observe anything.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Other obstacles in no particular order (that will be covered in other posts):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using the unity of Nature as an explanation.&lt;/li&gt;
&lt;li&gt;Using the utility of natural phenomenon as an explanation.&lt;/li&gt;
&lt;li&gt;The verbal obstacle that uses explanatory words.&lt;/li&gt;
&lt;li&gt;Substantialism/realism.&lt;/li&gt;
&lt;li&gt;“The animist obstacle in physical sciences”.&lt;/li&gt;
&lt;li&gt;False geometrization and rigor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the opening chapter Bachelard mentions the obstacles of close-mindedness and prior knowledge. Instincts, opinions, as well as education and previous knowledge are obstacles. A researcher must be able to rethink, to make abstraction of what she thinks is true, when battling an epistemological obstacle.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Accéder à la science, c’est, spirituellement rajeunir, c’est accepter une mutation brusque qui doit contredire un passé.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“To access science is to spiritually rejuvenate, it’s accepting an abrupt mutation that must contradict a past.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;On ne peut rien fonder sur l’opinion: il faut d’abord la détruire. Elle est le premier obstacle à surmonter.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“We cannot base anything on opinion: it must be destroyed first. It’s the first obstacle to overcome.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;Les grands hommes sont utiles à la science dans la première moitié de leur vie, nuisibles dans la seconde moitié.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Great men are useful to science in the first half of their life, harmful in the second half.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;[…] l’homme devient une espèce mutante, ou pour mieux dire encore, une espèce qui a besoin de muter, qui souffre de ne pas changer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Man becomes a mutant species, or better said still, a species that needs to mutate, that suffers from not changing.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;Toute culture scientifique doit commencer […] par une catharsis intelectuelle et affective.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Any scientific culture must begin with an intellectual and emotional catharsis.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Yes, catharsis of course…&lt;em&gt;googling&lt;/em&gt;…ah yes, &lt;a href=&#34;https://en.wikipedia.org/wiki/Catharsis&#34;&gt;catharsis&lt;/a&gt;, that makes sense.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-first-obstacle-the-primary-experiment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The first obstacle: the primary experiment&lt;/h2&gt;
&lt;p&gt;The scientific mind must develop &lt;em&gt;against&lt;/em&gt; Nature. During the pre-scientific period (XVIII century), scientific books were not based on peer-reviewed science, it was more about the author’s ideas than accuracy. More importance was given to the “story” or how it explained daily phenomena. Bachelard then describes a few of these books and their (funny) explanations. Although he agrees that these were picked as bad examples, he argues that the science at a particular time is not the science that survives time (especially in the pre-scientific period).&lt;/p&gt;
&lt;p&gt;There is a danger on relying too much on primary experiments, on selected observations and images, and on easy explanations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;On remplace la connaissance par l’admiration, les idées par les images.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“We replace knowledge with admiration, ideas with images.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;Une science qui accepte les images est, plus que toute autre, victime des métaphores. Aussi l’esprit scientifique doit-il sans cesse lutter contre les images, contre les analogies, contre les métaphores.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“A science that accepts images is, more than any other, victim of metaphors. Hence, the scientific mind must continuously fight against images, against analogies, against metaphors.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Coupled with general curiosity, we might end up listing observations and their independent explanations without digging deeper or testing variation of the experiments. These easy solutions satisfy our primal curiosity but destroy the sense of &lt;em&gt;problem&lt;/em&gt; that is vital for progress.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Elle cherche non pas la variation, mais la variété.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“It’s not looking for variation, but for variety.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;He gives the example of electricity, its “easy” explanations at the beginning and its entertaining experiments (people were fascinated by &lt;a href=&#34;https://www.youtube.com/watch?v=xjW-isgOijs&#34;&gt;Leyden jars&lt;/a&gt;).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Il est si doux à la paresse intellectuelle d’être cantonnée dans l’empirisme, d’appeler un fait un fait et d’interdire la recherche d’une loi!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“It is so attractive to intellectual laziness to keep to empiricism, to call a fact a fact and forbid the search of a law!”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;With these experiments, the answers are clearer than the questions. They promote some sort of &lt;em&gt;subconscious of the scientific mind&lt;/em&gt; that is difficult to get rid of. I imagine this as all these experiments/observations, all independent, all subconsciously accepted, with no clear link or structure, floating around and clouding the scientific mind. He quotes M. Édouard Le Roy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;La connaissance commune est inconscience de soi.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Common knowledge is unconsciousness of oneself”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Bachelard concludes this chapter with the example of alchemy. With its strong images and symbols, alchemy seems to touch us deep within our subconscious and represented a formidable epistemological obstacle.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;En vérité, l’amour d’une Chimère est le plus fidèle des amours.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“The truth is: love for a Chimera is the most faithful love.”&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;general-knowledge-as-an-obstacle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;General knowledge as an obstacle&lt;/h2&gt;
&lt;p&gt;We have to go beyond the primary experiment and its images. Doing so the scientist faces another obstacle which is to generalize too quickly or too far.&lt;/p&gt;
&lt;p&gt;Quoting Marcel Boll on what characterizes the modern scientist:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;C’est l’objectivité et non pas l’universalisme: la pensée doit être objective, elle ne sera universelle que si elle le peut, que si la réalité l’y autorise.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“It’s objectivity and not universalism: the mind must be objective, it will be universal only if it can, if reality allows it to be.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Beyond being sometimes false, general rules tend to stop the scientific endeavor. A general rule is sometimes satisfying enough that the scientist might not feel the need to explore further. Other times it is just difficult to “attack” what’s left of the problem, to find the right angle to study further.&lt;/p&gt;
&lt;p&gt;A general rule tend to rely on the meaning of its words which are often vague or subjective. The more useful rule uses objective terms and describes precisely the conditions in which it applies. Sometimes these conditions are more interesting than the rule.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ce qui limite une connaissance est souvent plus important, pour les progrès de la pensée, que ce qui étend vaguement la connaissance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“What limits a principle is often more important, to advance our understanding, than something that vaguely extends knowledge”&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Une connaissance générale est presque fatalement une connaissance vague.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“A general knowledge is almost inevitably a vague knowledge.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;General rules seem good in the short term as they rebuke older theories, but they are also stopping further characterization in the long term.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Autour d’une connaissance trop générale, la zone d’inconnu ne se résout pas en problèmes précis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Around a knowledge that is too general, the area of unknown is not formed of precise problems.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;He gives the example of the following statement: &lt;em&gt;everything falls&lt;/em&gt;. Although more accurate than older theories (like the ancient Greeks and their heavy vs light objects), it’s difficult to go further. Experiments in vacuums show that everything falls. Case closed, what do we do now? The rule seems sufficient to explain the observations but often it is not the most important concept that is put forward. In the example above, the movement/speed might be what’s usually described but acceleration is at the root of the law.&lt;/p&gt;
&lt;p&gt;In the second part of this chapter, Bachelard gives two examples of over-generalization: fermentation and coagulation. Basically, at some point many phenomena were grouped together and assumed to involve the same general mechanism. At this time, coagulation explained blood coagulation but also milk curdling, metal solidification, water freezing, or ocean froth. Similar story for fermentation that also explained digestion, metal formation, or electricity.&lt;/p&gt;
&lt;p&gt;Once general concepts explained that many things, it was frowned upon to go the other way. Why try to differentiate phenomena if we can explain everything with coagulation?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Cette méfiance des variations, cette paresse de la distinction, voilà précisément des marques du concept sclérosé !&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“This distrust for variations, this laziness for distinction, this is precisely the signs of the sclerosed concept!”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Echoing the previous obstacle, general concepts often gave birth to higher-level symbols and philosophy. For example, the source the fermentation that was everywhere obtained a new value, the started/pre-ferment became a symbol.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[…] toute trace de valorisation est un mauvais signe pour une connaissance qui vise l’objectivité.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Any trace of valorization is a bad sign for a knowledge that aspires for objectivity.”&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-of-verbal-obstacle-the-sponge&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An example of verbal obstacle: the &lt;em&gt;sponge&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Here, Bachelard presents a special case of the obstacles described above. The image of the &lt;em&gt;sponge&lt;/em&gt; was used extensively to explain many phenomena in a typical example of over-generalization. This word was so useful that it infiltrated different fields and later hindered correct explanations. The &lt;em&gt;sponge&lt;/em&gt; described phenomena so elegantly that they believed it explained it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ces phénomènes, on les exprime: on croit donc les expliquer. On les reconnaît: on croit donc les connaître.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“These phenomena, we express them: hence we think we explain them. We recognize them: hence we think we know them.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Essentially, verbal habits constrains scientific thinking, so we should be wary of the words and expressions we use when thinking about science. In science, we should use images and analogies only &lt;em&gt;after&lt;/em&gt; establishing the theory. In contrast, the image of the &lt;em&gt;sponge&lt;/em&gt; actually made people come up with new explanations or theories.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Voilà la preuve d’un mouvement purement et simplement linguistique qui, en associant, à un mot concret, un mot abstrait, croit avoir fait avancer la pensée.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Here is the proof of a movement purely and simply linguistic which, by associating an abstract word to a concrete word, thinks it has advanced our understanding.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Once a word like the &lt;em&gt;sponge&lt;/em&gt; had been attached to a phenomenon, it was difficult to get rid of it. Even if some details didn’t match the image, people kept using the &lt;em&gt;sponge&lt;/em&gt; because it elegantly explained the rest.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Le doute général est plus facile que le doute particulier.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“The general doubt is easier than the particular doubt.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Descartes fell for it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;La métaphysique de l’espace chez Descartes est la métaphysique de l’éponge.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“For Descartes, the metaphysics of space is the metaphysics of the sponge.”&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;aside-on-education&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aside on education&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;In the introduction, Bachelard also talks about education. &lt;/em&gt; &lt;em&gt;I don’t think there is a chapter on that particular subject so here it is.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Little effort has been directed toward the study of the psychology of ignorance and error. People think it’s just a matter of giving a lesson, repeating it until it’s grasped by the student, often using the same approach each time (e.g. retaking the class). The problem is that the student already has previous knowledge that impedes the understanding of the “lesson”. So the teacher needs first to break down these obstacles, that come from the student’s previous observations, in order to efficiently teach the new concepts. We spend too much effort on adding new concepts that will not always sort themselves out nicely in the student’s mind. We should spend more time guiding this conceptual readjustments when teaching science.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Les professeurs de sciences, plus encore que les autres si c’est possible, ne comprennent pas qu’on ne comprenne pas.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Science teachers, even more than others if that is possible, don’t understand that one doesn’t understand.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;Un éducateur n’a pas le sens de l’échec précisément parce qu’il se croit un maître.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“A teacher doesn’t have a sense of failure precisely because he believes himself to be a master.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;When performing experiments in class, the teacher should switch as fast as possible from experiment to abstract concepts, going back and forth between experiment and theory. Otherwise, the students will remember the most colorful and impressive experiments but not for the right reason. Sure they’ll remember when the tube exploded but not why or in which context.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Mieux vaudrait une ignorance complète qu’une connaissance privée de son principe fondamental.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“Complete ignorance would be better than knowledge deprived of its fundamental principle.”&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sick-burns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sick burns&lt;/h2&gt;
&lt;p&gt;About Carra’s explanation of bipedal walking that involve centrifugal force from earth rotation and electricity in the atmosphere:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;On imagine assez facilement qu’un enfant de huit ans, à la seule condition d’avoir à sa disposition un vocabulaire pédant, pourrait développer de telles billevesées.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“We can imagine quite easily that an eight years old child, if only he had a pedantic vocabulary at his disposal, would develop similar nonsense.”&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/xUPGcoUeohKhIesT5K/giphy.gif&#34; /&gt;

&lt;/div&gt;
&lt;hr /&gt;
&lt;p&gt;Philosophers vs scientists:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;E. Mach ne manquait pas de malice quand il répondait à l’affirmation de W. James «Tout savant a sa philosophie» par la constatation réciproque «Tout philosophe a sa science à lui».&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“E. Mach playfully responded to W. James’s statement that «Every scientist has his own philosophy» by the reciprocal «Every philosopher has his own science».”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;About Réaumur’s explanation of air as a &lt;em&gt;sponge&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Nous sentons le besoin de nous excuser auprès du lecteur d’avoir cité cette page interminable, cette page si mal écrite, d’un auteur célèbre.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“We feel we must apologize to the reader that we quoted this never-ending page, this page so badly written, from a famous author.”&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;P. de Lozeran won the Academy price with his explanation of thunder as a chemical reaction of gun powder-like ingredients in the air. Bachelard quotes the Academy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;L’Académie qui n’avait pu discerner le prix l’année précédente se félicite d’avoir attendu un si beau mémoire.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;“The Academy which hadn’t been able to give a prize the year before congratulate itself for having waited for such a beautiful memoir.”&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Peer-review opportunities for early career researchers</title>
          <link>/Hippocamplus/2018/11/07/ecr-peerreview/</link>
          <pubDate>Wed, 07 Nov 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/11/07/ecr-peerreview/</guid>
          <description>&lt;p&gt;Some notes from &lt;a href=&#34;https://uspa.ucsc.edu/2018/10/31/peer-review-workshop-117-12-pm-in-biomed-200/&#34;&gt;today’s workshop organized by USPA&lt;/a&gt; with bio-protocol and eLife ambassadors.&lt;/p&gt;
&lt;div id=&#34;bio-protocol&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bio-protocol&lt;/h2&gt;
&lt;p&gt;Data is uploaded to databases, code to repos like GitHub but protocols are still just in the &lt;em&gt;Methods&lt;/em&gt; section of papers.
And the &lt;em&gt;Methods&lt;/em&gt; of a paper often omits many details which makes it difficult to reuse the experiment or reproduce results.&lt;/p&gt;
&lt;p&gt;Dennis Bua introduced &lt;a href=&#34;https://bio-protocol.org/&#34;&gt;bio-protocol&lt;/a&gt;, a platform to peer-review protocols.
Here the goal is to make sure all the information is provided to reproduce an experiment.
Videos can also be uploaded to better show the manipulations.
There is no access or publication fee in bio-protocol, and reviewers are early-careers researchers.&lt;/p&gt;
&lt;p&gt;Currently it’s mostly used for wet lab experiments but Dennis said it was mostly because of a lack of expertise in the current pool of reviewers.
At first, it doesn’t feel as essential for dry lab experiments because we can already put the code in repos.
It’s also easier (in theory) to ask for assistance with code problems to the authors or in online forums.
That covers the situation when someone wants to use the code but not specifically to reproduce the results of the primary article.
So most of the time the code linked to a paper is still not really peer-reviewed (I think).
And we’ve all seen examples where the “code” is just a bunch of scripts with no comprehensive instructions or README.&lt;/p&gt;
&lt;p&gt;Dennis mentioned the &lt;a href=&#34;https://en.wikipedia.org/wiki/Curse_of_knowledge&#34;&gt;curse of knowledge&lt;/a&gt; which is when we can’t imagine that other people don’t know what we know.
It sounds like the kind of flaw we easily imagine others having but not to us.
I’m sure it happens in bioinformatics too.
Some scripts are simple or self-explanatory IF the user has the same knowledge (tools, favorite command lines, programming language, organization habits) as the original author.&lt;/p&gt;
&lt;p&gt;Another step that is often left aside it the data preparation.
The main method is often described in more detail because it’s usually novel.
How the data was downloaded or preprocessed is sometimes just mentioned in the method section.&lt;/p&gt;
&lt;p&gt;The more I think about it, the more I think bio-protocol could be useful to &lt;em&gt;vet&lt;/em&gt; a bioinformatics analysis.&lt;/p&gt;
&lt;p&gt;I’ve tried to make an effort to provide usable scripts to reproduce the results in my papers.
At least I (will) try to comment the scripts, even “trivial” commands to limit the &lt;em&gt;curse of knowledge&lt;/em&gt;.
For figures/numbers, I found that R-Markdown reports were pretty good because they show the code next to the output so it’s easier to find the code for a particular result.
Having the analysis as a &lt;em&gt;protocol&lt;/em&gt; would be an extra step but I feel like it wouldn’t be that much of an effort.
Just a reformatting of a comprehensive README/tutorial.
The benefit would be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;having someone external having a second look at the code and instructions.&lt;/li&gt;
&lt;li&gt;making the methods accessible to a larger audience hence making it more likely to be used.&lt;/li&gt;
&lt;li&gt;getting something official (a “publication”) out of the reproducibility effort.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;elife&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;eLife&lt;/h2&gt;
&lt;p&gt;Jason Fernandez and Jordan Ward, two of the three eLife ambassadors at UCSC with Daniel Kim, talked about eLife.
I was already quite familiar with eLife and really like the idea of not just a more efficient peer-reviewing but also a better one.
Especially better for authors because there is a discussion between reviewers that helps get more useful reviews.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/3pjXfgeOCho&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt; &lt;/p&gt;
&lt;p&gt;eLife is also very active (YouTube videos, podcasts, blogs, innovations) and the ambassadors mentioned &lt;a href=&#34;https://elifesciences.org/inside-elife/ae2cc6b5/early-career-researcher-travel-grants-2018-open-for-applications&#34;&gt;travel grants&lt;/a&gt; for authors and &lt;a href=&#34;https://elifesciences.org/inside-elife/31a5173b/elife-promotes-early-career-involvement-in-peer-review&#34;&gt;review opportunities for early-careers researchers&lt;/a&gt;.
Although it might look &lt;em&gt;closed&lt;/em&gt; on the website, they recommended to contact eLife anyway.
To have a chance to be included in the pool of reviewers, we should submit a letter of support from a supervisor and a few representative publications.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-resources-mentioned-during-the-workshop&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other resources mentioned during the workshop&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://masterclasses.nature.com/users/4925-claire-hodge/posts/20006-free-online-course-on-peer-review&#34;&gt;Course on peer review from Nature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;“&lt;a href=&#34;https://www.nature.com/articles/d41586-018-06991-0&#34;&gt;How to write a thorough peer review&lt;/a&gt;” by Matthew Stiller-Reeve explaining his three reading methods.&lt;/li&gt;
&lt;li&gt;“&lt;a href=&#34;https://jbiol.biomedcentral.com/articles/10.1186/jbiol125&#34;&gt;Are we training pit bulls to review our manuscripts?&lt;/a&gt;” by Virginia Walbot.&lt;/li&gt;
&lt;li&gt;“&lt;a href=&#34;http://blogs.nature.com/ofschemesandmemes/2017/12/21/are-you-aware-of-gender-bias-in-peer-review&#34;&gt;Are you aware of gender bias in peer review?&lt;/a&gt;” by Elizabeth Moylan and Elisa de Ranieri.&lt;/li&gt;
&lt;li&gt;“&lt;a href=&#34;https://peerj.com/blog/post/73296165864/how-to-become-good-at-peer-review/&#34;&gt;How To Become Good At Peer-Review&lt;/a&gt;” on PeerJ blog.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.prereview.org/users/8850/articles/198235-welcome-to-prereview&#34;&gt;PREreview&lt;/a&gt; reviews preprints. Part of the &lt;a href=&#34;http://asapbio.org/&#34;&gt;ASAPbio&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://publons.com/home/&#34;&gt;Publons Academy&lt;/a&gt; to learn how to peer review and connect with journal editors&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/218452887&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Syncing Mendeley and PDFs across devices</title>
          <link>/Hippocamplus/2018/09/22/sync-mendeley/</link>
          <pubDate>Sat, 22 Sep 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/09/22/sync-mendeley/</guid>
          <description>&lt;p&gt;Recently, I’ve been setting up new computers from scratch as I moved from Montreal to Santa Cruz. Like for spring cleaning, it might be a good idea to clarify the system I’ve been using to manage bibliography and PDF annotation.&lt;/p&gt;
&lt;p&gt;Briefly I use Mendeley Desktop and also put all PDF files in a Google Drive. Both are synced with my Android tablet. On the tablet, I use the Mendeley app to get information, search etc, but I read/annotate the PDFs from the Google Drive. On a computer I use a custom Python script to update the PDFs if necessary.&lt;/p&gt;
&lt;div id=&#34;the-updatemendeley.py-script&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The &lt;code&gt;updateMendeley.py&lt;/code&gt; script&lt;/h2&gt;
&lt;p&gt;I wrote a Python script that checks the Google Drive folder and Mendeley’s local folder, matches PDF files and syncs them. The &lt;code&gt;updateMendeley.py&lt;/code&gt; script is on &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/python/updateMendeley&#34;&gt;the GitHub repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I needed something slightly better than a &lt;code&gt;rsync&lt;/code&gt; because it’s possible that the filenames are not the same between the two folders. This might not be a big problem for new files but at some point Mendeley Desktop and the app I used on the tablet produced slightly different file names for the same article. I don’t use the Android app to download PDFs anymore but I still have old PDFs that I didn’t take the time to rename.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;matching&lt;/em&gt; part of the script compares each file name in the Google Drive with the file names in the local Mendeley folder. It uses the &lt;em&gt;SequenceMatcher&lt;/em&gt; function from the &lt;a href=&#34;https://docs.python.org/2/library/difflib.html&#34;&gt;difflib&lt;/a&gt; module. If two file names have more than 90% match, it assumes that it’s the same article. The result of the matching step is saved locally in a “cache” file to speed up future runs.&lt;/p&gt;
&lt;p&gt;Then it’s just a question of copying the new articles to the Google Drive or updating the local Mendeley folder (if files have different sizes).&lt;/p&gt;
&lt;p&gt;In practice, I run the following command when I feel a sync is needed (first a dry run, then without the &lt;code&gt;-dry&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;python updateMendeley.py -local PATH/TO/MendeleyDesktop -remote PATH/TO/GoogleDrive/ArticlesPDF -dry&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;why-mendeley&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why Mendeley?&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;That’s what I started using a while ago (before Elsevier acquired it).&lt;/li&gt;
&lt;li&gt;It has an Android app (I have an Android tablet).&lt;/li&gt;
&lt;li&gt;It does what I need: tagging system, export to BibTeX, search in PDFs, online portal.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Maybe I could find a good system with EndNote or Zotero but that would take some time and work. The idea of Zotero is appealing and I would prefer an open-source software (not owned by Elsevier). I tried to make the switch but it froze when importing my entire library. I should try again. There is still the problem of the Android app: I don’t know what they are worth for Zotero. There are two unofficial apps. Maybe I could pay the $2 and test them.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-not-use-the-pdf-syncing-mechanism-from-mendeley&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why not use the PDF syncing mechanism from Mendeley?&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Google Drive is more user-friendly: quickly access from different devices, easy to share PDF with others.&lt;/li&gt;
&lt;li&gt;Control over the files.&lt;/li&gt;
&lt;li&gt;Easy to update PDFs annotated on the tablet. Useful because I prefer to use a separate Android application to annotate PDFs (RepliGo).&lt;/li&gt;
&lt;li&gt;Bad experience this summer with &lt;a href=&#34;https://blog.mendeley.com/2018/06/01/support-update-pdfs-missing-from-desktop-and-web-library/&#34;&gt;a bug in Mendeley&lt;/a&gt; (blocked for more than a month and lost many PDFs, some of which were annotated).&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;syncing-the-google-drive-folder&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Syncing the Google Drive folder&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;On Android I use &lt;a href=&#34;https://play.google.com/store/apps/details?id=dk.tacit.android.foldersync.lite&amp;amp;hl=en_US&#34;&gt;FolderSync&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On Ubuntu I use &lt;a href=&#34;./internet#sync-a-specific-google-drive-folder-on-ubuntu&#34;&gt;grive&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On OSX I use the official Google Drive app: &lt;a href=&#34;https://www.google.com/drive/download/&#34;&gt;Backup and Sync&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Mental health crisis in science...but careful with nonresponse bias</title>
          <link>/Hippocamplus/2018/07/08/mental-health-crisis-science/</link>
          <pubDate>Sun, 08 Jul 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/07/08/mental-health-crisis-science/</guid>
          <description>&lt;p&gt;A few month ago, a short paper was published in Nature Biotechnology&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; about the mental health crisis in science. It attracted a bit of attention on the news and social media, which is good because it’s an important matter. The article was very good at putting the subject on the table and proposing some solutions, but it picked my curiosity about nonresponse bias.&lt;/p&gt;
&lt;div id=&#34;issues-with-the-nature-biotech-article&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Issues with the Nature Biotech article&lt;/h2&gt;
&lt;p&gt;The numbers are based on an email survey so &lt;strong&gt;one issue is the nonresponse bias&lt;/strong&gt;: the individuals that responded might not be representative of the population. The authors quickly mention it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Although this is a convenience sample in which respondents who have had a history of anxiety or depression may have been more apt to respond to the survey, the data should prompt both academia and policy makers to consider intervention strategies.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;However, in the next paragraph, this number is directly compared with the population number from a study that used a “nationally representative face-to-face household survey”&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our results show that graduate students are more than six times as likely to experience depression and anxiety as compared to the general population. Forty-one percent of graduate students scored as having moderate to severe anxiety on the GAD07 scale as compared to 6% of the general population, as demonstrated previously.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I find it a bit misleading to put both numbers in the same sentence without explaining that they were derived from different methods.&lt;/p&gt;
&lt;p&gt;On a side note, I was also surprised that the figures are incorrectly described in the text. Saying &lt;em&gt;“56% of students experiencing anxiety have an unhealthy work-life balance”&lt;/em&gt; is different from saying &lt;em&gt;“56% of students with unhealthy work-life balance experience anxiety”&lt;/em&gt;. Still, all the numbers about work-life balance and relationship with mentor are incorrectly described like this… A shame because at least these comparisons shouldn’t be affected by nonresponse bias as much. End of rant.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;better-studies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Better studies&lt;/h2&gt;
&lt;p&gt;Although not cited in the Nature Biotech paper, I found two studies that are quite similar but were more careful with their methods/conclusions.&lt;/p&gt;
&lt;p&gt;The first was published in the American Journal of Orthopsychiatry in 2010&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; and looked at mental health in university students (graduate students included). The PHQ-9 questionnaire was also used to assess depression and ~1,700 graduate students responded to their email survey. In this study, the authors tried to &lt;strong&gt;account for nonresponse bias&lt;/strong&gt; by computing weights based on two types of information:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Demographic and academic representation compared to the university’s registar.&lt;/li&gt;
&lt;li&gt;Results from nonrespondents that were recontacted and given larger incentive to respond.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The proportion of students with depression was significantly higher in the respondents than the non-respondents (&lt;strong&gt;14.1% vs 6.1%&lt;/strong&gt;). After correcting for the nonresponse bias they found that 11.3% of graduate students were positive for a depressive or anxiety disorder.&lt;/p&gt;
&lt;p&gt;The second study was published in Academic Psychiatry in 2014&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. This one is not really saying much about the estimates for the graduate student population but shows &lt;strong&gt;what can (and cannot) be said&lt;/strong&gt; when the nonresponse bias is not controlled. It used the same questionnaire for depression (PHQ-9) and screened ~300 students with an email survey. However, the goal was essentially to find factors that correlate with the questionnaire score. Although they describe the global number in the cohort, most of the study focuses on the association with other factors like substance use and eating problems. The discussion makes it clear too:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Therefore, the results of this study should not be generalized to the entire graduate student population on this campus or to graduate students outside of the study institution. As the goal of the screening was to identify and triage at-risk students into treatment, survey respondents may have represented students with more severe mental health needs who responded to the survey as a means of seeking help.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The 40% number might be a bit over-estimated. &lt;strong&gt;Is that a problem?&lt;/strong&gt; &lt;strong&gt;No&lt;/strong&gt; because mental health is a problem and we should talk about it and try to fix it. I just wanted to cite and put these two good studies somewhere I can remember (and also rant).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Evans, T. M., Bira, L., Gastelum, J. B., Weiss, L. T., &amp;amp; Vanderford, N. L. (2018). Evidence for a mental health crisis in graduate education. &lt;em&gt;Nature Biotechnology&lt;/em&gt;, volume 36, pages 282–284. &lt;a href=&#34;https://www.nature.com/articles/nbt.4089&#34;&gt;Link&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Kocalevent, R. D., Hinz, A., &amp;amp; Brähler, E. (2013). Standardization of the depression screener Patient Health Questionnaire (PHQ-9) in the general population. &lt;em&gt;General Hospital Psychiatry&lt;/em&gt;, 35(5), 551–555. &lt;a href=&#34;https://doi.org/10.1016/j.genhosppsych.2013.04.006&#34;&gt;Link&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Eisenberg, D. , Gollust, S. E., Golberstein, E. and Hefner, J. L. (2007). Prevalence and Correlates of Depression, Anxiety, and Suicidality Among University Students. &lt;em&gt;American Journal of Orthopsychiatry&lt;/em&gt;, 77: 534-542. &lt;a href=&#34;https://doi.org/10.1037/0002-9432.77.4.534&#34;&gt;Link&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Garcia-Williams, A.G., Moffitt, L. &amp;amp; Kaslow, N.J. (2014). Mental Health and Suicidal Behavior Among Graduate Students. &lt;em&gt;Acad Psychiatry&lt;/em&gt;, 38: 554. &lt;a href=&#34;https://doi.org/10.1007/s40596-014-0041-y&#34;&gt;Link&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Converting scientific reviews to EPUB</title>
          <link>/Hippocamplus/2018/05/07/epub-reviews/</link>
          <pubDate>Mon, 07 May 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/05/07/epub-reviews/</guid>
          <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#first-check-on-pubmed-central&#34;&gt;First, check on PubMed Central&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#convert-the-html-page-to-epub&#34;&gt;Convert the HTML page to EPUB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#clean-up-the-html-before-conversion&#34;&gt;Clean up the HTML before conversion&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#compiling-several-reviews-into-one-epub-document&#34;&gt;Compiling several reviews into one EPUB document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vpn-paywall-and-pandoc&#34;&gt;VPN, paywall and Pandoc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limitations&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#methods&#34;&gt;Methods&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-epub-resources&#34;&gt;Other EPUB resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;Third post on the series of &lt;em&gt;“Things I did instead of writing my thesis to help me write my thesis”&lt;/em&gt;: how to find/convert reviews in the EPUB format to read in an ebook reader.&lt;/p&gt;
&lt;p&gt;To motivate myself to write the thesis introduction and get some “style” inspiration, I read a few reviews. Reviews are longer and often more wordy than original research articles so I’d sometimes prefer to use my e-reader. It’s more compact and the e-ink is more comfortable to read, especially outside. But I find PDFs a bit awkward to use on an e-reader so it would be better to have the reviews in a e-reader format like EPUB.&lt;/p&gt;
&lt;p&gt;In my experience, this is the best strategy to get a review in EPUB format:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Check if available on PubMed Central.&lt;/li&gt;
&lt;li&gt;If not, download HTML page and convert with Pandoc.
&lt;ul&gt;
&lt;li&gt;If &lt;em&gt;Nature Reviews&lt;/em&gt; or &lt;em&gt;Annual Reviews&lt;/em&gt;, clean up the HTML file before conversion.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For &lt;em&gt;Nature Reviews&lt;/em&gt; and &lt;em&gt;Annual Reviews&lt;/em&gt;, the script I wrote can also merge several reviews into one EPUB ebook.&lt;/p&gt;
&lt;div id=&#34;first-check-on-pubmed-central&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First, check on PubMed Central&lt;/h2&gt;
&lt;p&gt;In the top-right corner of the article page there is a &lt;em&gt;ePub&lt;/em&gt; option (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3612533/&#34;&gt;example&lt;/a&gt;). This feature has been in &lt;em&gt;beta&lt;/em&gt; version for years but the EPUB files are really good.&lt;/p&gt;
&lt;p&gt;Unfortunately, many articles/reviews are not available through PMC, including the majority of reviews from dedicated journals like &lt;a href=&#34;https://www.nature.com/nrg/&#34;&gt;Nature Reviews Genetics&lt;/a&gt; and &lt;a href=&#34;https://www.annualreviews.org/journal/genet&#34;&gt;Annual Review of Genetics&lt;/a&gt;. For example, there are more than a thousand reviews from Nature Reviews Genetics on PubMed, but only &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/?term=%22nat+rev+genet%22%5BJournal%5D&#34;&gt;200-300 available on PubMed Central&lt;/a&gt;. Same for Annual Review of Genetics which has &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/?term=%22annual+review+of+genetics%22%5BJournal%5D&#34;&gt;~70 reviews available on PMC&lt;/a&gt; but almost 1K indexed on PubMed.&lt;/p&gt;
&lt;p&gt;If it’s not available in PMC (and the journal doesn’t provide an EPUB file), no choice but to manually convert to EPUB.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;convert-the-html-page-to-epub&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Convert the HTML page to EPUB&lt;/h2&gt;
&lt;p&gt;Rather than trying to convert the PDF, I found it easier to convert the HTML page. EPUB is a XML-based format which is quite close to the HTML anyway so it should be the way to go.&lt;/p&gt;
&lt;p&gt;After saving the webpage locally, the HTML file can be converted with &lt;a href=&#34;http://pandoc.org/index.html&#34;&gt;Pandoc&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;pandoc webpage-i-manually-downloaded.html -o webpage-i-manually-downloaded.epub&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Usually, the result is &lt;strong&gt;readable but not very practical&lt;/strong&gt; because the interface of the website is polluting the ebook, many links are external (pointing at webpages), and content is sometimes missing. It’s annoying not being able to click on the reference/figure links (or clicking inadvertently and opening a web browser), having to skip dozens of pages to get to the content, or missing information because they needed to be “expanded” on the website.&lt;/p&gt;
&lt;p&gt;There are exceptions. For example the &lt;strong&gt;“&lt;em&gt;Opportunities and obstacles for deep learning in biology and medicine&lt;/em&gt;”&lt;/strong&gt;, a cool (and long) review which was published in &lt;a href=&#34;http://rsif.royalsocietypublishing.org/content/15/141/20170387&#34;&gt;the Journal of the Royal Society Interface&lt;/a&gt;, is also formatted in &lt;a href=&#34;https://greenelab.github.io/deep-review/&#34;&gt;a GitHub HTML page&lt;/a&gt;. The manuscript is actually written and build using Markdown/GitHub (I want to learn how to do that at some point). Anyway, the GitHub webpage was straightforward to convert with Pandoc and produced a perfect EPUB version of the review.&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;wget -p https://greenelab.github.io/deep-review/
cd greenelab.github.io/deep-review
pandoc index.html -o DeepLearningBioMed.epub&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;clean-up-the-html-before-conversion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Clean up the HTML before conversion&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;For Nature Reviews and Annual Reviews&lt;/strong&gt;, I wrote a small R script that downloads a HTML page and:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Keeps only the article content (remove the rest of the webpage).&lt;/li&gt;
&lt;li&gt;Fixes the table of content.&lt;/li&gt;
&lt;li&gt;Fixes links to reference/figure/glossary in the text.&lt;/li&gt;
&lt;li&gt;Makes the figures not clickable.&lt;/li&gt;
&lt;li&gt;Removes external links around references and images.&lt;/li&gt;
&lt;li&gt;Simplify complex tables to allow for EPUB display.&lt;/li&gt;
&lt;li&gt;Shows the content of a &lt;em&gt;box&lt;/em&gt; even if hidden in the webpage.&lt;/li&gt;
&lt;li&gt;Replaces low-resolution figure with high-resolution (for Annual Reviews).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I put the &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/R/epubifyReviews&#34;&gt;two R scripts on GitHub&lt;/a&gt;. Using the URL of the review, run this to clean up the HTML and call Pandoc:&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;Rscript epubify-annualreviews.R -i https://www.annualreviews.org/doi/full/10.1146/annurev-genet-120215-034854
## or
Rscript epubify-naturereviews.R -i https://www.nature.com/articles/nrg.2015.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;The scripts rely on the &lt;a href=&#34;https://github.com/hadley/rvest&#34;&gt;rvest package&lt;/a&gt; (&lt;code&gt;install.packages(&#39;rvest&#39;)&lt;/code&gt; to install in &lt;code&gt;R&lt;/code&gt;) and the &lt;a href=&#34;https://yihui.name/knitr/&#34;&gt;knitr package&lt;/a&gt; (&lt;code&gt;install.packages(&#39;knitr&#39;)&lt;/code&gt; to install in &lt;code&gt;R&lt;/code&gt;).&lt;/em&gt; &lt;em&gt;It also assumes that &lt;code&gt;pandoc&lt;/code&gt; is installed.&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;compiling-several-reviews-into-one-epub-document&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Compiling several reviews into one EPUB document&lt;/h3&gt;
&lt;p&gt;Some reviews or articles are part of collections, like the “Points of significance” serie in Nature Methods. It would be nice to convert these articles into one EPUB.&lt;/p&gt;
&lt;p&gt;To do this both scripts can loop over URLs in a list and produce one EPUB. The &lt;code&gt;-i&lt;/code&gt; argument should be a text file with one URL per line, and the &lt;code&gt;-list&lt;/code&gt; argument should be added to switch on the “list” mode. Optional, you can specify a title using the &lt;code&gt;-title&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;I don’t think I’m allowed to share publicly the &lt;strong&gt;“Points of Significance” EPUB&lt;/strong&gt; but I can share the commands I used (see &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/R/epubifyReviews&#34;&gt;instructions on GitHub&lt;/a&gt;). There are also commands to download &lt;strong&gt;collections&lt;/strong&gt; of Nature Reviews (e.g. Genome Editing or Computational Tools) or search results for Annual Reviews (e.g. Microbiome &amp;amp; Sequencing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vpn-paywall-and-pandoc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;VPN, paywall and Pandoc&lt;/h3&gt;
&lt;p&gt;The script and Pandoc will try to download the text/images so &lt;strong&gt;they should be used behind the university’s VPN (or at the university).&lt;/strong&gt; For Nature Reviews, the page can also be downloaded locally and used instead of the URL argument. That might be useful if the articles are accessed by logging in through the web browser (e.g. McGill’s &lt;a href=&#34;http://www.mcgill.ca/library/services/connect&#34;&gt;EZproxy system&lt;/a&gt;). For Annual Reviews however, the Pandoc command will try to download high-res figures so it’s better to run with a VPN.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Limitations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Tables are “simplified” which makes them uglier but compatible with EPUB. For example, a multi-rows label is repeated in each row.&lt;/li&gt;
&lt;li&gt;If/when the websites change, the scripts will need to be adapted.&lt;/li&gt;
&lt;li&gt;This is &lt;a href=&#34;https://togelius.blogspot.ca/2016/04/the-differences-between-tinkering-and.html&#34;&gt;tinkering&lt;/a&gt; so it’s possible that some pages won’t work properly. The ones I tried worked but I didn’t test that many.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;methods&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Methods&lt;/h3&gt;
&lt;p&gt;The scripts use functions from the &lt;a href=&#34;https://github.com/hadley/rvest&#34;&gt;&lt;em&gt;rvest&lt;/em&gt;&lt;/a&gt; package to download the HTML code of a webpage. Then they use three different strategies to clean up the HTML code. Sometimes &lt;em&gt;rvest&lt;/em&gt;’s functions can directly select the relevant parts. Many times, the HTML code is modified using &lt;code&gt;gsub&lt;/code&gt; and regular expressions. A few times the script writes new HTML code based on information retrieved using &lt;em&gt;rvest&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Tables are converted into &lt;em&gt;data.frames&lt;/em&gt; with &lt;code&gt;html_table&lt;/code&gt;, then converted back to HTML usint &lt;a href=&#34;https://yihui.name/knitr/&#34;&gt;&lt;em&gt;knitr&lt;/em&gt;&lt;/a&gt;’s &lt;code&gt;kable&lt;/code&gt; function. In &lt;em&gt;list&lt;/em&gt; mode, the script loops through URLs from the input file and concatenate the cleaned HTML code. At the end, the final HTML code is written in a file which is converted to EPUB by &lt;a href=&#34;http://pandoc.org/index.html&#34;&gt;Pandoc&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;other-epub-resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other EPUB resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Books&lt;/strong&gt; from the &lt;a href=&#34;https://link.springer.com/bookseries/7651&#34;&gt;Methods in Molecular Biology&lt;/a&gt; series can be downloaded in the EPUB format.&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;http://collections.plos.org/translational-bioinformatics&#34;&gt;Translational Bioinformatics collection&lt;/a&gt; in PLoS Computational Biology has &lt;a href=&#34;http://www.ploscollections.org/downloads/TranslationalBioinformatics.epub&#34;&gt;an ePub option&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Additional checks for a LaTeX manuscript</title>
          <link>/Hippocamplus/2018/04/18/check-latex-pub/</link>
          <pubDate>Wed, 18 Apr 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/04/18/check-latex-pub/</guid>
          <description>&lt;p&gt;To continue on the series of &lt;em&gt;“Things I did instead of writing my thesis to help me write my thesis”&lt;/em&gt;, another Python script that reads a LaTeX manuscript and helps check that everything is fine. More specifically, the &lt;code&gt;checkLatex.py&lt;/code&gt; script (&lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/python/checkLatex&#34;&gt;on GitHub&lt;/a&gt;) will:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;List missing references.&lt;/li&gt;
&lt;li&gt;List multi-references to reorder.&lt;/li&gt;
&lt;li&gt;List duplicated labels.&lt;/li&gt;
&lt;li&gt;List labels that don’t start by &lt;code&gt;fig:&lt;/code&gt; or &lt;code&gt;tab:&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;List figures/tables that are not in order.&lt;/li&gt;
&lt;li&gt;List &lt;em&gt;??&lt;/em&gt;, &lt;em&gt;REF&lt;/em&gt; or &lt;em&gt;XX&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;List acronyms in italic (for gene names).&lt;/li&gt;
&lt;li&gt;List acronyms in serif (for method names).&lt;/li&gt;
&lt;li&gt;List acronyms not in italic nor in serif.&lt;/li&gt;
&lt;li&gt;Shows the first usage of each acronym (not in italic/serif).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This was particularly useful for my thesis because I combined three manuscripts and a general intro. I had to make sure that the labels, acronyms, references were all correct and consistent throughout the thesis. I might still use this again on smaller documents like research manuscripts.&lt;/p&gt;
&lt;div id=&#34;why-this-output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why this output?&lt;/h2&gt;
&lt;p&gt;“&lt;em&gt;List missing references&lt;/em&gt;” because &lt;code&gt;bibtex&lt;/code&gt; output was sandwiched between long latex logs and it was easy to do. “&lt;em&gt;List multi-references to reorder&lt;/em&gt;” is to transform “something&lt;sup&gt;19,3,12&lt;/sup&gt;” into “something&lt;sup&gt;3,12,19&lt;/sup&gt;”. Not a big deal but I prefer when it’s ordered…&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;List duplicated labels&lt;/em&gt;” helped merge manuscripts in the thesis but won’t be very useful in general. “&lt;em&gt;List labels that don’t start by &lt;code&gt;fig:&lt;/code&gt; or &lt;code&gt;tab:&lt;/code&gt;&lt;/em&gt;” to make sure that figures and tables have labels starting with &lt;code&gt;fig:&lt;/code&gt; or &lt;code&gt;tab:&lt;/code&gt; (it helps for the next check). “&lt;em&gt;List figures/tables that are not in order&lt;/em&gt;” to make sure the figure/table numbers are in ascending order in the text. It checks for the order of labels in each file separately. That way if the supplementary material is in a separate file (using &lt;code&gt;\input&lt;/code&gt;), the supp figs are considered separately from other figures. It’s not perfect though, because the script doesn’t “understand” sub-figures.&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;List ??, REF or XX&lt;/em&gt;” because that’s what I use when I’m writing and missing a number or reference.&lt;/p&gt;
&lt;p&gt;“&lt;em&gt;List acronyms in italic (for gene names)&lt;/em&gt;” to make sure that acronyms in italic are gene names. “&lt;em&gt;List acronyms in serif (for method names)&lt;/em&gt;” to make sure that acronyms in serif are methods names. “&lt;em&gt;List acronyms not in italic nor in serif&lt;/em&gt;” to check if I forgot to put a gene name in italic or a method in serif. It also helped listing the abbreviations at the beginning of the thesis. “&lt;em&gt;Shows the first usage of an acronym (not in italic/serif)&lt;/em&gt;” to make sure acronyms are defined properly.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;practical-details&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Practical details&lt;/h2&gt;
&lt;p&gt;The script &lt;strong&gt;assumes that the document is compiled&lt;/strong&gt;. For example, it will use the &lt;code&gt;.bbl&lt;/code&gt; file for the checks on the references.&lt;/p&gt;
&lt;p&gt;It will follow &lt;strong&gt;one level of &lt;code&gt;\input{}&lt;/code&gt;&lt;/strong&gt;. It was enough for my thesis: I had one &lt;code&gt;main.tex&lt;/code&gt; file with &lt;code&gt;\input&lt;/code&gt; commands calling the different chapters. It should be enough for a manuscript in general.&lt;/p&gt;
&lt;p&gt;Acronyms are defined by the regular expression &lt;code&gt;[A-Za-z0-9]*[A-Z]{2}[A-Za-z0-9]*&lt;/code&gt;, i.e. at least two consecutive uppercase letters and any letter/number around.&lt;/p&gt;
&lt;p&gt;Some arguments to switch on/off the acronym mode and internal references as explained in the help output:&lt;/p&gt;
&lt;pre class=&#34;txt&#34;&gt;&lt;code&gt;&amp;gt; python checkLatex.py -h
usage: checkLatex.py [-h] -i TEX [-inrefs] [-noacro]

Check for problems in a LaTeX manuscript.

optional arguments:
  -h, --help  show this help message and exit
  -i TEX      the input tex file
  -inrefs     list non-fig/table internal refs
  -noacro     don&amp;#39;t list acronyms&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;final-check&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Final check&lt;/h2&gt;
&lt;p&gt;I used &lt;code&gt;pdfgrep&lt;/code&gt; to check the final PDF for quotation marks that could result from missing reference/figure/table.&lt;/p&gt;
&lt;pre class=&#34;sh&#34;&gt;&lt;code&gt;pdfgrep &amp;#39;\?&amp;#39; main.pdf&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Checking text similarity between two documents</title>
          <link>/Hippocamplus/2018/04/16/text-similarity/</link>
          <pubDate>Mon, 16 Apr 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/04/16/text-similarity/</guid>
          <description>&lt;p&gt;To start the series of &lt;em&gt;“Things I did instead of writing my thesis to help me write my thesis”&lt;/em&gt;, a small Python script that compares two text documents and output similar parts. I did that to avoid auto-plagiarism of my manuscripts’ introduction in the main thesis introduction.&lt;/p&gt;
&lt;p&gt;It’s a very naive approach but sped up the checking process (&lt;a href=&#34;https://xkcd.com/1319/&#34;&gt;maybe worth the time&lt;/a&gt;). It first looks for short exact matches between the two documents, then extends these exact matches and uses the &lt;a href=&#34;https://docs.python.org/2/library/difflib.html&#34;&gt;difflib&lt;/a&gt; module to keep text with a minimum similarity score (default 80%).&lt;/p&gt;
&lt;p&gt;I put the &lt;code&gt;simText.py&lt;/code&gt; Python script &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/python/simText&#34;&gt;on GitHub here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;usage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;Basic command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python simText.py -1 text1.txt -2 text2.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The help page:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python simText.py -h
usage: simText.py [-h] -1 D1 -2 D2 [-k K] [-e EXT] [-s MINSIM] [-tex]

Find similar text between two documents.

optional arguments:
  -h, --help  show this help message and exit
  -1 D1       Text document 1
  -2 D2       Text document 2
  -k K        The number of char for 1st pass. Default 20
  -e EXT      The number of additional char. Default 70
  -s MINSIM   The minimum similarity to define a match. Default 0.8
  -tex        Skip LaTeX header and lines starting with %&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;latex-documents&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;LaTeX documents&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;-tex&lt;/code&gt; option skips the header in LaTeX documents and lines starting with a &lt;code&gt;%&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python simText.py -1 text1.tex -2 text2.tex -tex&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I implemented this because the header and commented lines were annoying me in the output. More would be needed to have a good LaTeX mode but I submitted my thesis already so it will be for another time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;playing-with-the-stringency&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Playing with the stringency&lt;/h3&gt;
&lt;p&gt;By default, the script outputs text that are &lt;strong&gt;at least 80% similar&lt;/strong&gt; (change with &lt;code&gt;-s&lt;/code&gt; argument). To run more or less stringent checks, I play with &lt;code&gt;-e&lt;/code&gt; which controls how long the 80% match must be.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Output&lt;/h2&gt;
&lt;p&gt;The output contains a paragraph for each match. Each paragraph has three lines with the similarity score, the text in the first document, the text in the second document, respectively. For example (with &lt;code&gt;-e 50&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;txt&#34;&gt;&lt;code&gt;S:0.87
T1: tions of a genomic region, which affect DNA copy number, are collectively known as copy number varia
T2: eletions and duplications, which affect DNA copy number, are collectively known as copy number varia&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Journal comparison</title>
          <link>/Hippocamplus/2018/02/23/journals-comparison/</link>
          <pubDate>Fri, 23 Feb 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/02/23/journals-comparison/</guid>
          <description>&lt;p&gt;&lt;em&gt;Edit Feb 24: Added variance graph and some examples of suspiciously fast publications.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edit Feb 25: Added &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/R/journalPubTime&#34;&gt;script and data&lt;/a&gt; to GitHub.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Some info about journals in my field.&lt;/p&gt;
&lt;div id=&#34;summary-table&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary table&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Journal&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Co.&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;IF&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;OA&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;APC&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Other fees&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Pub/year&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Received-to-accepted in days. median (75th perc.)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://f1000research.com/for-authors/publish-your-research&#34;&gt;F1000Research&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1000 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://peerj.com/about/author-instructions/&#34;&gt;PeerJ&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1095 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~1290&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~88 (139)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://submit.elifesciences.org/html/elife_author_instructions.html#process&#34;&gt;eLife&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7.8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2500 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1018&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;121 (155)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://academic.oup.com/gigascience/pages/instructions_to_authors&#34;&gt;GigaScience&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OUP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2050 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~50&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~126 (195)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://journals.plos.org/plosone/s/criteria-for-publication&#34;&gt;PLoS One&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2.8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1495 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~22K&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~122 (182)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://journals.plos.org/ploscompbiol/s/journal-information&#34;&gt;PLoS Comp Bio&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2250 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~550&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~159 (217)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://journals.plos.org/plosgenetics/s/journal-information&#34;&gt;PLoS Genetics&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2250 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;644&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;150 (202)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://journals.plos.org/plosbiology/s/journal-information&#34;&gt;PLoS Biology&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;9.8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2900 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~176&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~141 (175)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://bmcbioinformatics.biomedcentral.com/submission-guidelines&#34;&gt;BMC Bioinformatics&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BMC/S&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2.5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2145 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~333&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~169 (231)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://bmcgenomics.biomedcentral.com/submission-guidelines&#34;&gt;BMC Genomics&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BMC/S&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2145 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~985&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~138 (190)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://bmcbiol.biomedcentral.com/submission-guidelines&#34;&gt;BMC Biology&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BMC/S&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6.8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2785 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~85&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~70 (108)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://genomebiology.biomedcentral.com/submission-guidelines&#34;&gt;Genome Biology&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BMC/S&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11.9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2975 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~156&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~106 (143)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://www.cell.com/cell-reports/authors&#34;&gt;Cell Reports&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Els&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;8.3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5000 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~1005&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~168 (241)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.nature.com/srep/publish/guidelines&#34;&gt;Scientific Reports&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1760 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~20K&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~104 (151)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.nature.com/ncomms/submit/guide-to-authors&#34;&gt;Nature Communications&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5200 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~3519&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~168 (228)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://academic.oup.com/nar/pages/Policies&#34;&gt;NAR&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OUP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Y&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2770 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pp9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~1359&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~82 (131)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://www.genetics.org/content/prep-manuscript&#34;&gt;Genetics&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12m/+&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2000 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pp/pf/psf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~374&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~104 (163)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://www.cell.com/ajhg/authors&#34;&gt;AJHG&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Els&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;9.0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6m/+&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5000 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;850 USD + pf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;237&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;89 (121)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://www.pnas.org/page/authors/submission&#34;&gt;PNAS&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;HWP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;9.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6m/+&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1450 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1700 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://genome.cshlp.org/site/misc/ifora.xhtml&#34;&gt;Genome Research&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CSH&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11.9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6m/+&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2500 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2500 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~179&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~188 (242)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://www.cell.com/cell/authors&#34;&gt;Cell&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Els&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;30.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;(12m/+)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5000 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~351&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~149 (193)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://www.thelancet.com/lancet/information-for-authors&#34;&gt;Lancet&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Els&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;47.8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6m/+&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5000 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://www.sciencemag.org/authors/science-journals-editorial-policies&#34;&gt;Science&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AAAS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;37.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12m&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;surprise&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~720&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~112 (162)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://academic.oup.com/bioinformatics/pages/instructions_for_authors&#34;&gt;Bioinformatics&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;OUP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7.3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;+&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3000 USD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pp7/pf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~868&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~126 (180)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;New England Journal Of Medicine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;72.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6m&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.nature.com/nmeth/for-authors&#34;&gt;Nature Methods&lt;/a&gt;_&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;25.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;N&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~130&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~146 (187)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.nature.com/ng/for-authors&#34;&gt;Nature Genetics&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28.0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;N&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;202&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;147 (203)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.nature.com/nbt/for-authors&#34;&gt;Nature Biotech&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;N&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pp5/pf&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;202 (262)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.nature.com/nature/for-authors&#34;&gt;Nature&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Spr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;40.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;N&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~855&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;~175 (246)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Open Access (OA) journal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Y&lt;/code&gt;: Yes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;+&lt;/code&gt;: Authors can pay additional Article Processing Charges (column APC) to make it accessible immediately upon publication.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;12m&lt;/code&gt;: Articles are accessible after 12 months, either from the journal or &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/&#34;&gt;PubMed Central&lt;/a&gt;/&lt;/li&gt;
&lt;li&gt;&lt;code&gt;6m&lt;/code&gt;: Articles are accessible after 6 months, either from the journal or &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/&#34;&gt;PubMed Central&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;()&lt;/code&gt;: Depending on the funding agencies.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;N&lt;/code&gt;: No.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fees:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pp&lt;/code&gt;: Per page.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ppX&lt;/code&gt;: Per pages in excess of X (if more than X pages).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pf&lt;/code&gt;: Per figure.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;psf&lt;/code&gt;: Per supplementary file.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;sources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Impact Factor for 2016/2017 from &lt;a href=&#34;http://www.bioxbio.com/if/&#34;&gt;bioxbio&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;APC from &lt;a href=&#34;https://doaj.org/&#34;&gt;Directory of Open Access Journals&lt;/a&gt;, or the journal.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Received-to-accepted time&lt;/em&gt; and &lt;em&gt;Pub/year&lt;/em&gt; are based on articles published in 2016. After a PubMed search, the publication web-page was crawled to get the article type and dates of reception/acceptance. I considered research articles/letters/methods/reports but not reviews/editorial/perspective/erratum/opinion. Sometimes the DOI was not present in the PubMed results or there was a lot of publications to crawl so I analyzed a subset and extrapolated the numbers (&lt;code&gt;~&lt;/code&gt; marks approximated numbers). I still see some suspicious numbers (articles with very short/negative acceptance time). Hopefully the medians are still close to reality but these numbers should be taken with a grain of salt.&lt;/p&gt;
&lt;p&gt;Some data has been produced, now it’s graph time !&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;median-time-to-acceptancepublication&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Median time to acceptance/publication&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-10-15-JournalComparison_files/figure-html/time-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;median-time-to-acceptancepublication-vs-number-of-article-published&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Median time to acceptance/publication vs number of article published&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-10-15-JournalComparison_files/figure-html/timenb-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;median-time-to-acceptancepublication-vs-impact-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Median time to acceptance/publication vs impact factor&lt;/h2&gt;
&lt;p&gt;I’m curious to see if it takes more time in some cases because a journal is more “picky” ?&lt;/p&gt;
&lt;p&gt;The impact factor is not a good indicator of research impact but maybe it can be a proxy for a journal’s pickiness. Looking at the correlation with the impact factor, there’s a trend (with or without the first tier journals). Still, the journals are quite spread out.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-10-15-JournalComparison_files/figure-html/timeif-1.png&#34; width=&#34;960&#34; /&gt;&lt;img src=&#34;./post/2017-10-15-JournalComparison_files/figure-html/timeif-2.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-in-time-to-acceptance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variance in time to acceptance&lt;/h2&gt;
&lt;p&gt;The ranking using the 75th percentile is not so different than the one using the median.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-10-15-JournalComparison_files/figure-html/timevar-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see some publications with suspiciously short received-to-accepted times…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;suspiciously-short-received-to-accepted-times&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Suspiciously short received-to-accepted times&lt;/h2&gt;
&lt;p&gt;I’m not sure how each journal defines &lt;em&gt;“received”&lt;/em&gt;. Some publications have acceptance times too short to be the peer-review time.&lt;/p&gt;
&lt;p&gt;I even found two papers that have negative received-to-accepted times… In both the webpage and the PDFs, these papers were &lt;strong&gt;published 3 months before they were submitted&lt;/strong&gt;: &lt;a href=&#34;http://www.genetics.org/content/203/3/1249.article-info&#34;&gt;10.1534/genetics.115.183194&lt;/a&gt; and &lt;a href=&#34;http://www.genetics.org/content/203/3/1425.article-info&#34;&gt;10.1534/genetics.115.185181&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, looking at a few examples for each journal, some of the “fast” publications are about &lt;strong&gt;resources (databases, portal, websites)&lt;/strong&gt; which makes sense, others look like research that would require peer-review longer than a few days…&lt;/p&gt;
&lt;p&gt;For example, the “fastest” publications for each journal (among the publications I considered):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;Days to acceptance&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Journal&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Title&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Genome Biology&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1186/s13059-016-0929-9&#34;&gt;OncoNEM: inferring tumor evolution from single-cell sequencing data.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS Genet.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1371/journal.pgen.1006521&#34;&gt;Tbx5 Buffers Inherent Left/Right Asymmetry Ensuring Symmetric Forelimb Formation.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;eLife&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.7554/eLife.21635&#34;&gt;Lysosomal membrane glycoproteins bind cholesterol and contribute to lysosomal cholesterol export.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PeerJ&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.7717/peerj.1969&#34;&gt;Ectopic expression of Jatropha curcas APETALA1 (JcAP1) caused early flowering in Arabidopsis, but not in Jatropha.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Genetics&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1534/genetics.115.183137&#34;&gt;Identifying Regulators of Morphogenesis Common to Vertebrate Neural Tube Closure and Caenorhabditis elegans Gastrulation.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NAR&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1093/nar/gkv1047&#34;&gt;PDBe: improved accessibility of macromolecular structure data from PDB and EMDB.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GigaScience&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1186/s13742-016-0143-4&#34;&gt;RES-Scanner: a software package for genome-wide identification of RNA-editing sites.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS ONE&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1371/journal.pone.0149986&#34;&gt;Time-Resolved Visualisation of Nearly-Native Influenza A Virus Progeny Ribonucleoproteins and Their Individual Components in Live Infected Cells.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS Biology&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1371/journal.pbio.1002480&#34;&gt;The DEAD-box Protein Rok1 Orchestrates 40S and 60S Ribosome Assembly by Promoting the Release of Rrp5 from Pre-40S Ribosomes to Allow for 60S Maturation.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BMC Biology&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1186/s12915-016-0253-6&#34;&gt;Nuclear fallout provides a new link between aPKC and polarized cell trafficking.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Bioinformatics&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1093/bioinformatics/btv604&#34;&gt;iEnhancer-2L: a two-layer predictor for identifying enhancers and their strength by pseudo k-tuple nucleotide composition.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Science&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1126/science.aaf1835&#34;&gt;Selective conversion of syngas to light olefins.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Am J Hum Genet.&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1016/j.ajhg.2016.07.014&#34;&gt;The Power of Human Protective Modifiers: PLS3 and CORO1C Unravel Impaired Endocytosis in Spinal Muscular Atrophy and Rescue SMA Phenotype.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Cell Reports&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1016/j.celrep.2016.08.091&#34;&gt;Structures of NS5 Methyltransferase from Zika Virus.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;22&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PLoS Comput Biol&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1371/journal.pcbi.1005041&#34;&gt;Direct Correlation between Motile Behavior and Protein Abundance in Single Cells.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;22&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Nature Communications&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1038/ncomms10745&#34;&gt;Switchable friction enabled by nanoscale self-assembly on graphene.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Scientific Reports&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1038/srep28849&#34;&gt;Aero-Thermo-Dynamic Mass Analysis.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Nature&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1038/nature16536&#34;&gt;Non-classical correlations between single photons and phonons from a mechanical oscillator.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Cell&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1016/j.cell.2016.11.014&#34;&gt;Atomic Structure of the Cystic Fibrosis Transmembrane Conductance Regulator.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;28&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Nature Methods&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1038/nmeth.4031&#34;&gt;ATAC-see reveals the accessible genome by transposase-mediated imaging and sequencing.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BMC Genomics&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1186/s12864-016-2393-z&#34;&gt;Suboptimal culture conditions induce more deviations in gene expression in male than female bovine blastocysts.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Nature Genetics&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1038/ng.3611&#34;&gt;Genomic analysis of 6,000-year-old cultivated grain illuminates the domestication history of barley.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;BMC Bioinformatics&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1186/s12859-016-0931-y&#34;&gt;ksRepo: a generalized platform for computational drug repositioning.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;59&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Nature Biotech&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1038/nbt.3663&#34;&gt;Blood pressure regulation by CD4(+) lymphocytes expressing choline acetyltransferase.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Genome Research&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://doi.org/10.1101/gr.215293.116&#34;&gt;Large-scale reduction of the Bacillus subtilis genome: consequences for the transcriptional network, resource allocation, and metabolism.&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;script-and-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Script and data&lt;/h2&gt;
&lt;p&gt;I someone wants to do the same for other journals, I put my script &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/R/journalPubTime&#34;&gt;there&lt;/a&gt;. The data I used is also there in a &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/raw/config/R/journalPubTime/journalPubTime.tsv&#34;&gt;TSV file&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;good-journals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;“Good” journals&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://elifesciences.org/&#34;&gt;eLife&lt;/a&gt; is non-profit, open and modern.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.plos.org/which-journal-is-right-for-me&#34;&gt;PLOS&lt;/a&gt; the pioneer in open-access.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biomedcentral.com/p/the-bmc-series-journals#journallist&#34;&gt;BMC&lt;/a&gt;, although it’s owned by Springer Nature publishing group.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://f1000research.com/&#34;&gt;F1000&lt;/a&gt; where the manuscript is “published” right away and then transparently peer-reviewed. Once peer-reviewed, it is indexed in PubMed etc.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://peerj.com/&#34;&gt;PeerJ&lt;/a&gt; is about open-access and cost-efficient publishing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;evil-publishing-companies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;“Evil” publishing companies&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Elsevier.&lt;/li&gt;
&lt;li&gt;Springer Nature.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;further-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.nature.com/news/does-it-take-too-long-to-publish-research-1.19320&#34;&gt;Does it take too long to publish research? (Nature News Feature)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.talyarkoni.org/blog/2016/12/12/why-i-still-wont-review-for-or-publish-with-elsevier-and-think-you-shouldnt-either/&#34;&gt;“Why I still won’t review for or publish with Elsevier–and think you shouldn’t either” by Tal Yarkoni&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>tSNE and clustering</title>
          <link>/Hippocamplus/2018/02/13/tsne-and-clustering/</link>
          <pubDate>Tue, 13 Feb 2018 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2018/02/13/tsne-and-clustering/</guid>
          <description>&lt;p&gt;tSNE can give really nice results when we want to visualize many groups of multi-dimensional points. Once the 2D graph is done we might want to identify which points cluster in the tSNE blobs.&lt;/p&gt;
&lt;p&gt;Using simulated and real data, I’ll try different methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hierarchical clustering&lt;/li&gt;
&lt;li&gt;K-means&lt;/li&gt;
&lt;li&gt;Gaussian mixture&lt;/li&gt;
&lt;li&gt;Density-based clustering&lt;/li&gt;
&lt;li&gt;Louvain community detection.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; If &amp;lt;30K points, hierarchical clustering is robust, easy to use and with reasonable computing time. KNN + Louvain is fast and works well in general.&lt;/p&gt;
&lt;hr /&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr)
library(magrittr)
library(ggrepel)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;div id=&#34;normally-distributed-points&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Normally distributed points&lt;/h3&gt;
&lt;p&gt;First, I’ll simulate an easy situation with 10 different groups. 5,000 points are distributed following Gaussian distributions in 100 dimensions. Points are randomly assigned a group. For each group, 3 dimensions are randomly selected and the points shifted.&lt;/p&gt;
&lt;p&gt;Because there are 10 groups that differ in different dimensions, a PCA shouldn’t be able to separate all the groups with the first two components. That’s when the tSNE comes in to do its magic (easily).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123456)
N = 5000
D = 100
data.norm = matrix(rnorm(N * D, 2), N)
groups.probs = runif(10)
groups = sample(1:10, N, TRUE, groups.probs/sum(groups.probs))
for (gp in unique(groups)) {
    dev = rep(1, D)
    dev[sample.int(D, 3)] = runif(3, -10, 10)
    data.norm[which(groups == gp), ] = data.norm[which(groups == 
        gp), ] %*% diag(dev)
}
info.norm = tibble(truth = factor(groups))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The PCA and tSNE look like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pca.norm = prcomp(data.norm)
info.norm %&amp;lt;&amp;gt;% cbind(pca.norm$x[, 1:4])
ggplot(info.norm, aes(x = PC1, y = PC2, colour = truth)) + 
    geom_point(alpha = 0.3) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/pcatsne-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(info.norm, aes(x = PC3, y = PC4, colour = truth)) + 
    geom_point(alpha = 0.3) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/pcatsne-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see something but it’s not so clear, let’s run the tSNE.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Rtsne)
tsne.norm = Rtsne(pca.norm$x, pca = FALSE)
info.norm %&amp;lt;&amp;gt;% mutate(tsne1 = tsne.norm$Y[, 1], tsne2 = tsne.norm$Y[, 
    2])
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = truth)) + 
    geom_point(alpha = 0.3) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/tsne-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Time for this code chunk: 83.76 s&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;real-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Real data&lt;/h3&gt;
&lt;p&gt;As a real-life example, I use the data that motivated this exploration. It contains a bit more than 26K points and the tSNE looks like that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tsne.real = read.csv(&amp;quot;https://docs.google.com/uc?id=1KArwfOd5smzuCsrpgW9Xpf9I06VOW4ga&amp;amp;export=download&amp;quot;)
info.real = tsne.real
ggplot(tsne.real, aes(x = tsne1, y = tsne2)) + geom_point(alpha = 0.1) + 
    theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/real-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-clustering&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hierarchical clustering&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;+&lt;/strong&gt; Once built, it’s fast to try different number clusters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;+&lt;/strong&gt; Different linkage criteria to match the behavior we want.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-&lt;/strong&gt; Doesn’t scale well. High memory usage and computation time when &amp;gt;30K.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hc.norm = hclust(dist(tsne.norm$Y))
info.norm$hclust = factor(cutree(hc.norm, 9))
hc.norm.cent = info.norm %&amp;gt;% group_by(hclust) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = hclust)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = hclust), 
    data = hc.norm.cent) + guides(colour = FALSE) + 
    ggtitle(&amp;quot;Linkage criterion: Complete&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/hcnorm-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hc.norm = hclust(dist(tsne.norm$Y), method = &amp;quot;ward.D&amp;quot;)
info.norm$hclust = factor(cutree(hc.norm, 9))
hc.norm.cent = info.norm %&amp;gt;% group_by(hclust) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = hclust)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = hclust), 
    data = hc.norm.cent) + guides(colour = FALSE) + 
    ggtitle(&amp;quot;Linkage criterion: Ward&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/hcnorm-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now on real data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hc.real = hclust(dist(tsne.real))
info.real$hclust = factor(cutree(hc.real, 18))
hc.real.cent = info.real %&amp;gt;% group_by(hclust) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = hclust)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = hclust), 
    data = hc.real.cent) + guides(colour = FALSE) + 
    ggtitle(&amp;quot;Linkage criterion: Complete&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/hcreal-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hc.real = hclust(dist(tsne.real), method = &amp;quot;ward.D&amp;quot;)
info.real$hclust = factor(cutree(hc.real, 18))
hc.real.cent = info.real %&amp;gt;% group_by(hclust) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = hclust)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = hclust), 
    data = hc.real.cent) + guides(colour = FALSE) + 
    ggtitle(&amp;quot;Linkage criterion: Ward&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/hcreal2-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Time for this code chunk: 38.01 s&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For both data, Ward gives the best clusters. For example it splits the top-left clusters better in the real data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;kmeans&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Kmeans&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;+&lt;/strong&gt; Very fast.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-&lt;/strong&gt; Simple.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;km.norm = kmeans(tsne.norm$Y, 9, nstart = 100)
info.norm$kmeans = factor(km.norm$cluster)
km.cent = info.norm %&amp;gt;% group_by(kmeans) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = kmeans)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = kmeans), 
    data = km.cent) + guides(colour = FALSE) + ggtitle(&amp;quot;9 clusters&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/kmnorm-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;km.norm = kmeans(tsne.norm$Y, 10, nstart = 100)
info.norm$kmeans = factor(km.norm$cluster)
km.cent = info.norm %&amp;gt;% group_by(kmeans) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = kmeans)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = kmeans), 
    data = km.cent) + guides(colour = FALSE) + ggtitle(&amp;quot;10 clusters&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/kmnorm-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Because it’s not working well for cluster that are not “round”, we need to ask for more clusters. In practice we’ll need to merge back together the clusters that were fragmented.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123456)
km.real = kmeans(tsne.real, 24, nstart = 200, iter.max = 100)
info.real$kmeans = factor(km.real$cluster)
km.cent = info.real %&amp;gt;% group_by(kmeans) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = kmeans)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = kmeans), 
    data = km.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/kmreal-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not perfect in the middle-left big cluster: cluster 11 is grabbing points from the bottom blob. Maybe increasing the number of clusters could fix this?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123456)
km.real = kmeans(tsne.real, 25, nstart = 200, iter.max = 100)
info.real$kmeans = factor(km.real$cluster)
km.cent = info.real %&amp;gt;% group_by(kmeans) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = kmeans)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = kmeans), 
    data = km.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/kmrealmore-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Time for this code chunk: 15.48 s&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Better. Same as with the other methods: we need to manually tweak the parameters to obtain the clustering we want…&lt;/p&gt;
&lt;p&gt;Note: using several starting points help getting more robust results (&lt;code&gt;nstart=&lt;/code&gt;). Increasing the number of iterations helps too (&lt;code&gt;iter.max=&lt;/code&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mclust&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mclust&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;+&lt;/strong&gt; Better clusters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;+&lt;/strong&gt; Can find the best K (number of clusters (although slowly).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-&lt;/strong&gt; Slow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-&lt;/strong&gt; Need to be recomputed for each choice of K (number of clusters).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mclust)
mc.norm = Mclust(tsne.norm$Y, 9)
info.norm$mclust = factor(mc.norm$classification)
mc.cent = info.norm %&amp;gt;% group_by(mclust) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = mclust)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = mclust), 
    data = mc.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/mcnorm-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Even the elongated cluster is nicely identified and we don’t need to split it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123456)
mc.real = Mclust(tsne.real, 20, initialization = list(subset = sample.int(nrow(tsne.real), 
    1000)))
info.real$mclust = factor(mc.real$classification)
mc.cent = info.real %&amp;gt;% group_by(mclust) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = mclust)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = mclust), 
    data = mc.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/mcreal-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Sometimes the results are a bit surprising. For example, points are assigned to cluster far away or there is another cluster in between (e.g. clusters 6 and 17). As usual changing the number of clusters helps.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123456)
mc.real = Mclust(tsne.real, 24, initialization = list(subset = sample.int(nrow(tsne.real), 
    1000)))
info.real$mclust = factor(mc.real$classification)
mc.cent = info.real %&amp;gt;% group_by(mclust) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = mclust)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = mclust), 
    data = mc.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/mcreal2-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Time for this code chunk: 90.61 s&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Note: I had to use the sub-sampling trick to speed up the process, otherwise it was taking too long. Using &lt;code&gt;initialization=list(subset=sample.int(nrow(tsne.real), 1000))&lt;/code&gt;, only a thousand points are used for the EM (but all the points are assigned to a cluster at the end).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;density-based-clustering&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density-based clustering&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;+&lt;/strong&gt; Can find clusters with different “shapes”.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-&lt;/strong&gt; Bad on real/noisy data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-&lt;/strong&gt; Slow when many points.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(fpc)
ds.norm = dbscan(tsne.norm$Y, 2)
info.norm$density = factor(ds.norm$cluster)
ds.cent = info.norm %&amp;gt;% group_by(density) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = density)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = density), 
    data = ds.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/densnorm-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Woah, it found the small cluster !&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ds.real = dbscan(tsne.real, 1)
info.real$density = factor(ds.real$cluster)
ds.cent = info.real %&amp;gt;% group_by(density) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = density)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = density), 
    data = ds.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/densreal-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Time for this code chunk: 100.98 s&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ouch…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;knn-graph-and-louvain-community-detection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;KNN graph and Louvain community detection&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(igraph)
library(FNN)
k = 100
knn.norm = get.knn(as.matrix(tsne.norm$Y), k = k)
knn.norm = data.frame(from = rep(1:nrow(knn.norm$nn.index), 
    k), to = as.vector(knn.norm$nn.index), weight = 1/(1 + 
    as.vector(knn.norm$nn.dist)))
nw.norm = graph_from_data_frame(knn.norm, directed = FALSE)
nw.norm = simplify(nw.norm)
lc.norm = cluster_louvain(nw.norm)
info.norm$louvain = as.factor(membership(lc.norm))
lc.cent = info.norm %&amp;gt;% group_by(louvain) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = louvain)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = louvain), 
    data = lc.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/louvnorm-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Playing with the resolution parameter we can get more/less communities. For &lt;code&gt;gamma=.3&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lc.norm = cluster_louvain(nw.norm, gamma = 0.3)
info.norm$louvain = as.factor(membership(lc.norm))
lc.cent = info.norm %&amp;gt;% group_by(louvain) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.norm, aes(x = tsne1, y = tsne2, colour = louvain)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = louvain), 
    data = lc.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/gamma-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;On real data and using &lt;code&gt;gamma=.1&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k = 100
knn.real = get.knn(as.matrix(tsne.real), k = k)
knn.real = data.frame(from = rep(1:nrow(knn.real$nn.index), 
    k), to = as.vector(knn.real$nn.index), weight = 1/(1 + 
    as.vector(knn.real$nn.dist)))
nw.real = graph_from_data_frame(knn.real, directed = FALSE)
nw.real = simplify(nw.real)
lc.real = cluster_louvain(nw.real, gamma = 0.1)
info.real$louvain = as.factor(membership(lc.real))
lc.cent = info.real %&amp;gt;% group_by(louvain) %&amp;gt;% select(tsne1, 
    tsne2) %&amp;gt;% summarize_all(mean)
ggplot(info.real, aes(x = tsne1, y = tsne2, colour = louvain)) + 
    geom_point(alpha = 0.3) + theme_bw() + geom_label_repel(aes(label = louvain), 
    data = lc.cent) + guides(colour = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-01-tSNEclustering_files/figure-html/louvreal-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Time for this code chunk: 18.86 s&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Pretty good.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PS:&lt;/em&gt; I added the resolution parameter &lt;code&gt;gamma&lt;/code&gt; in the &lt;em&gt;igraph&lt;/em&gt; function for the Louvain clustering. While it was easy to change in the C code, compiling &lt;em&gt;igraph&lt;/em&gt; from source was a pain. I couldn’t get it to work on OSX but I managed to install this modified version of igraph on Linux (see &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/tree/config/R/rigraph_gammalouvain&#34;&gt;instructions&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;If not too many points or too many groups, &lt;strong&gt;hierarchical clustering&lt;/strong&gt; might be enough. Especially with the Ward criterion, it worked well for both simulated and real data. Once the hierarchy is built, it’s fast to try different values for the number of clusters. Also, in the real data, I could get satisfactory results using a lower number of clusters than for the K-means (18 vs 25).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If there are too many points&lt;/strong&gt; (e.g. &amp;gt;30K), hierarchical clustering might be too demanding and I would fall back to &lt;strong&gt;KNN+Louvain&lt;/strong&gt;. It’s fast enough and the results are pretty good.&lt;/p&gt;
&lt;p&gt;The more advanced methods are good to keep in mind if the points ever form diverse or unusual shapes.&lt;/p&gt;
&lt;p&gt;I learned two &lt;strong&gt;tricks to improve the performance&lt;/strong&gt; of the methods: increasing the number of iterations and starting points for the K-means, and sub-sampling for the EM clustering.&lt;/p&gt;
&lt;p&gt;Clustering points from the tSNE is good to explore the groups that we visually see in the tSNE but &lt;strong&gt;if we want more meaningful clusters&lt;/strong&gt; we could run these methods &lt;strong&gt;in the PC space directly&lt;/strong&gt;. The KNN + Louvain community clustering, for example, is used in single cell sequencing analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Bibliography style for AJHG</title>
          <link>/Hippocamplus/2017/10/04/bibliography-style-for-ajhg/</link>
          <pubDate>Wed, 04 Oct 2017 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2017/10/04/bibliography-style-for-ajhg/</guid>
          <description>&lt;p&gt;I couldn’t find an up-to-date/working &lt;strong&gt;LaTeX bibliography style for the American Journal of Human Genetics (AJHG)&lt;/strong&gt;. The output from &lt;code&gt;unsrtnat&lt;/code&gt; (my goto style) was also quite different from what the journal wanted.&lt;/p&gt;
&lt;p&gt;I found a bibliography style for &lt;em&gt;Cell&lt;/em&gt; which is almost what AJHG wants, but I also wanted the references to be &lt;strong&gt;ordered by their appearance in the text&lt;/strong&gt; (like for &lt;code&gt;unsrtnat&lt;/code&gt;) and not alphabetically. So I downloaded both &lt;code&gt;cell.bst&lt;/code&gt; (&lt;a href=&#34;https://www.ctan.org/tex-archive/macros/latex/contrib/cell&#34;&gt;here&lt;/a&gt;) and &lt;code&gt;unsrtnat.bst&lt;/code&gt; (&lt;a href=&#34;https://www.ctan.org/tex-archive/macros/latex/contrib/natbib/&#34;&gt;here&lt;/a&gt;) files and merged them. I don’t understand all the details but after some trial-and-errors it seems to work.&lt;/p&gt;
&lt;p&gt;After merging, I removed the &lt;em&gt;emphasis&lt;/em&gt; on the Journal/Book name which was the only difference I could see between the Cell and AJHG styles.&lt;/p&gt;
&lt;p&gt;I also added some code to &lt;strong&gt;automatically compress long author lists&lt;/strong&gt; into “&lt;em&gt;et al.&lt;/em&gt;”. In the code, the line with &lt;code&gt;max.num.names.before.forced.et.al&lt;/code&gt; specifies the maximum number of authors before switching to “&lt;em&gt;et al.&lt;/em&gt;”. The line with &lt;code&gt;num.names.shown.with.forced.et.al&lt;/code&gt; specifies how many authors to show when using &lt;em&gt;et al.&lt;/em&gt;. They are both set at 10, following AJHG guidelines.&lt;/p&gt;
&lt;p&gt;The final &lt;code&gt;ajhg.bst&lt;/code&gt; file can be found &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/blob/config/LaTeX/ajhg.bst&#34;&gt;here&lt;/a&gt;. I used it with &lt;code&gt;\usepackage[comma,super]{natbib}&lt;/code&gt;.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>MUMmerplots with ggplot2</title>
          <link>/Hippocamplus/2017/09/19/mummerplots-with-ggplot2/</link>
          <pubDate>Tue, 19 Sep 2017 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2017/09/19/mummerplots-with-ggplot2/</guid>
          <description>&lt;p&gt;&lt;em&gt;Update Oct 28 2018: added reference id (rid) to be able to visualize multiple reference regions. Also uploaded the example data somewhere.&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(magrittr)
library(GenomicRanges)
library(knitr)
library(ggplot2)
library(tidyr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;mummer-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MUMmer plot&lt;/h2&gt;
&lt;p&gt;The MUMmer plot that I want to reproduce showed three contigs overlapping a region of chr 14. I had filtered the delta file with &lt;code&gt;delta-filter -l 10000 -q -r&lt;/code&gt; to get only the contigs with the best alignments. I had used &lt;code&gt;mummerplot&lt;/code&gt; with the &lt;code&gt;-l&lt;/code&gt; layout option to reorder and orient the sequences to have a nice diagonal.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./imgs/mumplot-example.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;delta-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Delta file&lt;/h2&gt;
&lt;p&gt;The delta file is the default output of the &lt;a href=&#34;http://mummer.sourceforge.net/manual/#nucmer&#34;&gt;NUCmer alignment script&lt;/a&gt;. The format of the delta file is described more &lt;a href=&#34;http://mummer.sourceforge.net/manual/#nucmeroutput&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The delta file used in this post can be downloaded &lt;a href=&#34;https://www.dropbox.com/s/3zscsbbex6rgemo/mumplot-example.delta?dl=0&#34;&gt;here&lt;/a&gt;. Otherwise, in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(!file.exists(&amp;#39;mumplot-example.delta&amp;#39;)){
    download.file(&amp;#39;https://dl.dropboxusercontent.com/s/3zscsbbex6rgemo/mumplot-example.delta?dl0&amp;#39;,
                  &amp;#39;mumplot-example.delta&amp;#39;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;read-a-delta-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Read a delta file&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;readDelta &amp;lt;- function(deltafile){
  lines = scan(deltafile, &amp;#39;a&amp;#39;, sep=&amp;#39;\n&amp;#39;, quiet=TRUE)
  lines = lines[-1]
  lines.l = strsplit(lines, &amp;#39; &amp;#39;)
  lines.len = lapply(lines.l, length) %&amp;gt;% as.numeric
  lines.l = lines.l[lines.len != 1]
  lines.len = lines.len[lines.len != 1]
  head.pos = which(lines.len == 4)
  head.id = rep(head.pos, c(head.pos[-1], length(lines.l)+1)-head.pos)
  mat = matrix(as.numeric(unlist(lines.l[lines.len==7])), 7)
  res = as.data.frame(t(mat[1:5,]))
  colnames(res) = c(&amp;#39;rs&amp;#39;,&amp;#39;re&amp;#39;,&amp;#39;qs&amp;#39;,&amp;#39;qe&amp;#39;,&amp;#39;error&amp;#39;)
  res$qid = unlist(lapply(lines.l[head.id[lines.len==7]], &amp;#39;[&amp;#39;, 2))
  res$rid = unlist(lapply(lines.l[head.id[lines.len==7]], &amp;#39;[&amp;#39;, 1)) %&amp;gt;% gsub(&amp;#39;^&amp;gt;&amp;#39;, &amp;#39;&amp;#39;, .)
  res$strand = ifelse(res$qe-res$qs &amp;gt; 0, &amp;#39;+&amp;#39;, &amp;#39;-&amp;#39;)
  res
}

mumgp = readDelta(&amp;quot;mumplot-example.delta&amp;quot;)

mumgp %&amp;gt;% head %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;rs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;re&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qe&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;error&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;qid&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;rid&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;strand&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;265577&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;265842&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;108520&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;108254&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;46&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;265577&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;265842&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;106438&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;106172&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;46&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;306695&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;306968&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;138241&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;138515&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1016956&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1017364&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27806&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27394&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1723715&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1723990&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34123&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33845&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1767531&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1767813&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33842&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34123&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;+&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-contigs-with-poor-alignments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Filter contigs with poor alignments&lt;/h2&gt;
&lt;p&gt;For now, I filter contigs simply based on the size of the aligned segment. I keep only contigs with at least one aligned segment larger than a minimum size. Smaller alignment in these contigs are kept if in the same range as the large aligned segments. Eventually, I could also filter segment based on the number/proportion of errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filterMum &amp;lt;- function(df, minl=1000, flanks=1e4){
    coord = df %&amp;gt;% filter(abs(re-rs)&amp;gt;minl) %&amp;gt;% group_by(qid, rid) %&amp;gt;%
        summarize(qsL=min(qs)-flanks, qeL=max(qe)+flanks, rs=median(rs)) %&amp;gt;%
        ungroup %&amp;gt;% arrange(desc(rs)) %&amp;gt;%
        mutate(qid=factor(qid, levels=unique(qid))) %&amp;gt;% select(-rs)
    merge(df, coord) %&amp;gt;% filter(qs&amp;gt;qsL, qe&amp;lt;qeL) %&amp;gt;%
        mutate(qid=factor(qid, levels=levels(coord$qid))) %&amp;gt;% select(-qsL, -qeL)
}

mumgp.filt = filterMum(mumgp, minl=1e4)
mumgp.filt %&amp;gt;% head %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;qid&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;rid&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;rs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;re&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qe&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;error&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;strand&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1663946&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1665485&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;331648&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;330113&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;171&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1662200&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1684396&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;126037&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;103837&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;234&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1581333&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1582738&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;244635&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;243233&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;87&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1597381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1610746&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;145948&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;132626&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;157&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1610278&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1623358&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130561&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;117468&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chr14:105095800-107043718&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1616542&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1618080&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;331648&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;330113&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;146&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graph&lt;/h2&gt;
&lt;p&gt;I’m going for the same style as &lt;code&gt;mummerplot&lt;/code&gt; to compare.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mumgp.filt, aes(x=rs, xend=re, y=qs, yend=qe, colour=strand)) + geom_segment() +
    geom_point(alpha=.5) + facet_grid(qid~., scales=&amp;#39;free&amp;#39;, space=&amp;#39;free&amp;#39;, switch=&amp;#39;y&amp;#39;) +
    theme_bw() + theme(strip.text.y=element_text(angle=180, size=5),
                       legend.position=c(.99,.01), legend.justification=c(1,0),
                       strip.background=element_blank(),
                       axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;assembly&amp;#39;) + scale_colour_brewer(palette=&amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/graph-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not bad but it would look nicer if we flipped the contigs to have more or less a diagonal.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;diagonalize&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Diagonalize&lt;/h2&gt;
&lt;p&gt;For each contig, I compute the major strand (strand with most bases aligned) and flip if necessary. The contigs are also ordered based on the reference region with most bases and the weighted means of the start position in this matched reference region.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diagMum &amp;lt;- function(df){
    ## Find best qid order
    rid.o = df %&amp;gt;% group_by(qid, rid) %&amp;gt;% summarize(base=sum(abs(qe-qs)),
                                                    rs=weighted.mean(rs, abs(qe-qs))) %&amp;gt;%
        ungroup %&amp;gt;% arrange(desc(base)) %&amp;gt;% group_by(qid) %&amp;gt;% do(head(., 1)) %&amp;gt;%
        ungroup %&amp;gt;% arrange(desc(rid), desc(rs)) %&amp;gt;%
        mutate(qid=factor(qid, levels=unique(qid)))
    ## Find best qid strand
    major.strand = df %&amp;gt;% group_by(qid) %&amp;gt;%
        summarize(major.strand=ifelse(sum(sign(qe-qs)*abs(qe-qs))&amp;gt;0, &amp;#39;+&amp;#39;, &amp;#39;-&amp;#39;),
                  maxQ=max(c(qe, qs)))
    merge(df, major.strand) %&amp;gt;% mutate(qs=ifelse(major.strand==&amp;#39;-&amp;#39;, maxQ-qs, qs),
                                       qe=ifelse(major.strand==&amp;#39;-&amp;#39;, maxQ-qe, qe),
                                       qid=factor(qid, levels=levels(rid.o$qid)))
}

mumgp.filt.diag = diagMum(mumgp.filt)

ggplot(mumgp.filt.diag, aes(x=rs, xend=re, y=qs, yend=qe, colour=strand)) +
    geom_segment() + geom_point(alpha=.5) + theme_bw() + 
    facet_grid(qid~., scales=&amp;#39;free&amp;#39;, space=&amp;#39;free&amp;#39;, switch=&amp;#39;y&amp;#39;) +
    theme(strip.text.y=element_text(angle=180, size=5), strip.background=element_blank(),
          legend.position=c(.99,.01), legend.justification=c(1,0),
          axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;assembly&amp;#39;) + scale_colour_brewer(palette=&amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/diag-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What we were aiming at:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./imgs/mumplot-example.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Pretty good.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;To also represent multiple reference regions in separate facets, change the &lt;em&gt;facet_grid&lt;/em&gt; commands. Here we have only one reference region but the command would be:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mumgp.filt.diag, aes(x=rs, xend=re, y=qs, yend=qe, colour=strand)) +
    geom_segment() + geom_point(alpha=.5) + theme_bw() + 
    facet_grid(qid~rid, scales=&amp;#39;free&amp;#39;, space=&amp;#39;free&amp;#39;, switch=&amp;#39;y&amp;#39;) +
    theme(strip.text.y=element_text(angle=180, size=5), strip.background=element_blank(),
          legend.position=c(.99,.01), legend.justification=c(1,0),
          axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
    xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;assembly&amp;#39;) + scale_colour_brewer(palette=&amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/rid-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;See also &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/issues/2&#34;&gt;this GitHub issue&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;percent-identity-and-coverage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Percent identity and coverage&lt;/h2&gt;
&lt;p&gt;Another useful MUMmerplot represents the position of each aligned segment and its percent similarity.&lt;/p&gt;
&lt;p&gt;This graph could be useful to decide which size/similarity threshold to use when filtering low alignments.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mumgp %&amp;lt;&amp;gt;% mutate(similarity=1-error/abs(qe-qs))
mumgp.filt %&amp;lt;&amp;gt;% mutate(similarity=1-error/abs(qe-qs))

ggplot(mumgp, aes(x=rs, xend=re, y=similarity, yend=similarity)) + geom_segment() +
    theme_bw() + xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;similarity&amp;#39;) + ggtitle(&amp;#39;All contigs&amp;#39;) +
    ylim(0,1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simgraph-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mumgp.filt, aes(x=rs, xend=re, y=similarity, yend=similarity)) + geom_segment() +
    theme_bw() + xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;similarity&amp;#39;) +
    ggtitle(&amp;#39;At least 10 Kbp aligned&amp;#39;) + ylim(0,1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simgraph-2.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To better highlighted which region in the reference is covered, I annotate each base of the reference with the maximum similarity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;maxSimilarityDisjoin &amp;lt;- function(df){
  ref.ir = GRanges(&amp;#39;X&amp;#39;, IRanges(df$rs, df$re), similarity=df$similarity)
  ## Efficient clean up of low similarity within high similarity
  step = 1
  while(step&amp;gt;0){
    largealign = ref.ir[head(order(rank(-ref.ir$similarity), rank(-width(ref.ir))),step*1000)]
    ol = findOverlaps(ref.ir, largealign, type=&amp;#39;within&amp;#39;) %&amp;gt;% as.data.frame %&amp;gt;%
        mutate(simW=ref.ir$similarity[queryHits],
               simL=largealign$similarity[subjectHits]) %&amp;gt;% filter(simW&amp;lt;simL)
    if(length(largealign) == length(ref.ir)){
      step = 0
    } else {
      step = step + 1
    }
    ref.ir = ref.ir[-ol$queryHits]
  }
  ## Disjoin and annotate with the max similarity
  ref.dj = disjoin(c(ref.ir, GRanges(&amp;#39;X&amp;#39;, IRanges(min(df$rs), max(df$rs)), similarity=0)))
  ol = findOverlaps(ref.ir, ref.dj) %&amp;gt;% as.data.frame %&amp;gt;%
      mutate(similarity=ref.ir$similarity[queryHits]) %&amp;gt;%
      group_by(subjectHits) %&amp;gt;% summarize(similarity=max(similarity))
  ref.dj$similarity = 0
  ref.dj$similarity[ol$subjectHits] = ol$similarity
  as.data.frame(ref.dj)
}

mumgp.sim = maxSimilarityDisjoin(mumgp)

mumgp.sim %&amp;gt;% select(similarity, start, end) %&amp;gt;% gather(end, pos, 2:3) %&amp;gt;%
    ggplot() + geom_line(aes(x=pos, y=similarity), alpha=.5, color=&amp;#39;red&amp;#39;) + theme_bw() +
    xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;similarity&amp;#39;) + ggtitle(&amp;#39;All contigs&amp;#39;) + ylim(0,1) +
    geom_segment(aes(x=rs, xend=re, y=similarity, yend=similarity), data=mumgp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcov-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mumgp.sim) + geom_segment(aes(x=start, xend=end, yend=similarity, y=similarity),
                                 color=&amp;#39;red&amp;#39;, size=2) +
    theme_bw() + xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;similarity&amp;#39;) + ylim(0,1) +
    geom_segment(aes(x=rs, xend=re, y=similarity, yend=similarity), data=mumgp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcov-2.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With this graph we could compare different assemblies or before/after filtering:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mumgp.filt.sim = maxSimilarityDisjoin(mumgp.filt)

mumgp.filt.m = rbind(mumgp.sim %&amp;gt;% mutate(filter=&amp;#39;before&amp;#39;),
                     mumgp.filt.sim %&amp;gt;% mutate(filter=&amp;#39;after&amp;#39;))

mumgp.filt.m %&amp;gt;% select(similarity, start, end, filter) %&amp;gt;% gather(end, pos, 2:3) %&amp;gt;%
    ggplot(aes(x=pos, y=similarity, colour=filter)) + geom_line(alpha=.8) + theme_bw() +
    xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;similarity&amp;#39;) + ylim(0,1) +
    scale_colour_brewer(palette=&amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcovcomp-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not so pretty but we see that a few region are not covered any more after our filtering. Maybe something like this instead :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mumgp.filt.m %&amp;gt;% filter(similarity==0) %&amp;gt;%
    ggplot(aes(x=start, xend=end, y=filter, yend=filter)) + geom_segment(size=10) +
    theme_bw() + xlab(&amp;#39;reference sequence&amp;#39;) + ylab(&amp;#39;filter&amp;#39;) +
    scale_colour_brewer(palette=&amp;#39;Set1&amp;#39;) + ggtitle(&amp;#39;Reference regions not covered&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcovcomptrack-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Regression sandbox</title>
          <link>/Hippocamplus/2017/09/16/regression-sandbox/</link>
          <pubDate>Sat, 16 Sep 2017 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2017/09/16/regression-sandbox/</guid>
          <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(broom)
library(magrittr)
library(dplyr)
library(knitr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;logistic-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic regression&lt;/h2&gt;
&lt;div id=&#34;one-way-or-another&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;a href=&#34;https://youtu.be/4kg9LasvLFE&#34;&gt;One way or another&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If we have two binary variables and we want to see if they are associated we could use a logistic regression. How do we decide which variable to be the predictor and which variable to observed variable ?&lt;/p&gt;
&lt;p&gt;In theory there shouldn’t be any differences but let’s check with a dummy example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df = data.frame(x = sample(c(FALSE, TRUE), 100, TRUE))
df$y = df$x
df$y[1:70] = sample(c(FALSE, TRUE), 70, TRUE)

glm(y ~ x, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2336149&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3070802&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7607617&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4467994&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1745982&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4256623&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.7594604&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0057897&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm(x ~ y, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4054651&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3227486&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.256288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2090117&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;yTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1745982&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4256624&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.759460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0057897&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df$z = runif(100)
glm(y ~ x + z, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5930811&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5436028&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.0910191&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2752645&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.2012521&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4293265&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.7979921&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0051421&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;z&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6601875&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8199692&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8051369&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4207407&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm(x ~ y + z, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1246648&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5141828&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2424523&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8084297&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;yTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1996170&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4291206&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.7955243&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0051816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;z&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5586854&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8023449&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6963157&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4862311&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Adding another predictor doesn’t change the estimates either.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interpretation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Interpretation&lt;/h3&gt;
&lt;p&gt;Just to make sure I understand the estimates correctly. It represents the log odds ratio change for each “unit” of the predictor. In the case of a binary variable, the log odds ratio between the two groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm(y ~ x, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2336149&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3070802&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7607617&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4467994&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1745982&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4256623&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.7594604&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0057897&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;odds.y.ifx = mean(subset(df, x)$y)/mean(!subset(df, 
    x)$y)
odds.y.ifnotx = mean(subset(df, !x)$y)/mean(!subset(df, 
    !x)$y)
log(odds.y.ifx/odds.y.ifnotx)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.174598&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;extreme-cases&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extreme cases&lt;/h3&gt;
&lt;p&gt;How efficient is the logistic regression when there is an imbalance between different types of observations ? For example if just a few genomic regions overlap an interesting annotation and I want to test is the overlap is significant.&lt;/p&gt;
&lt;p&gt;Let’s look at the worst cases when there are only 1 observation for a particular class.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df = data.frame(y = sample(c(FALSE, TRUE), 100, TRUE))
df$x = 1:nrow(df) %in% sample.int(nrow(df), 1)
glm(y ~ x, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1010961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2012644&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5023050&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6154530&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15.4649721&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1455.3975462&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0106259&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9915219&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Although the significance is low, the estimate seems quite high. I’ll repeat this process a bunch of time and with different number of supporting observations to have an idea of the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ext.df = lapply(1:500, function(ii) {
    res = lapply(1:10, function(ssi) {
        df$x = 1:nrow(df) %in% sample.int(nrow(df), 
            ssi)
        glm(y ~ x, data = df, family = binomial()) %&amp;gt;% 
            tidy %&amp;gt;% mutate(rep = ii, ss = ssi)
    })
    do.call(rbind, res)
})
ext.df = do.call(rbind, ext.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ext.df %&amp;gt;% filter(term == &amp;quot;xTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate)) + 
    geom_density(fill = &amp;quot;grey50&amp;quot;) + facet_grid(ss ~ 
    ., scales = &amp;quot;free&amp;quot;) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/lrextsimgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It seems like the estimate “inflation” is problematic mostly when there are only 1 or 2 supporting observations. If there are more than 5 supporting observations the estimate is correctly centered in 0.&lt;/p&gt;
&lt;p&gt;This problem is in fact called the &lt;a href=&#34;https://en.wikipedia.org/wiki/Separation_(statistics)&#34;&gt;problem of separation&lt;/a&gt;. There are two approaches to deal with it:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Firth logistic regression.&lt;/li&gt;
&lt;li&gt;Exact logistic regression.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/rms/index.html&#34;&gt;&lt;code&gt;rms&lt;/code&gt; package&lt;/a&gt; from &lt;a href=&#34;http://www.fharrell.com/2017/01/introduction.html&#34;&gt;Frank Harell&lt;/a&gt;. It implements a penalized maximum likelihood estimation of the model coefficients through the &lt;code&gt;lrm&lt;/code&gt; function which has a &lt;code&gt;penalty=&lt;/code&gt; parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rms)
extrms.df = lapply(1:200, function(ii) {
    res = lapply(1:10, function(ssi) {
        res = lapply(c(1, 3, 5), function(pen) {
            df$x = 1:nrow(df) %in% sample.int(nrow(df), 
                ssi)
            cc = lrm(y ~ x, data = df, penalty = pen)$coefficient
            data.frame(term = names(cc), estimate = cc, 
                rep = ii, ss = ssi, penalty = pen, 
                stringsAsFactors = FALSE)
        })
        do.call(rbind, res)
    })
    do.call(rbind, res)
})
extrms.df = do.call(rbind, extrms.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extrms.df %&amp;gt;% filter(term == &amp;quot;x&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate)) + 
    geom_density(fill = &amp;quot;grey50&amp;quot;) + facet_grid(ss ~ 
    penalty, scales = &amp;quot;free&amp;quot;) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/lrmsgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It definitely helps: the estimates are now much closer to 0. I don’t see much difference between penalties 1, 3 or 5.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/logistf/index.html&#34;&gt;&lt;code&gt;logistf&lt;/code&gt; package&lt;/a&gt;. It implements Firth’s bias reduction method with its &lt;code&gt;logistf&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(logistf)
extstf.df = lapply(1:200, function(ii) {
    res = lapply(1:10, function(ssi) {
        df$x = 1:nrow(df) %in% sample.int(nrow(df), 
            ssi)
        cc = logistf(y ~ x, data = df)$coefficient
        data.frame(term = names(cc), estimate = cc, 
            rep = ii, ss = ssi, stringsAsFactors = FALSE)
    })
    do.call(rbind, res)
})
extstf.df = do.call(rbind, extstf.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extstf.df %&amp;gt;% filter(term == &amp;quot;xTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate)) + 
    geom_density(fill = &amp;quot;grey50&amp;quot;) + facet_grid(ss ~ 
    ., scales = &amp;quot;free&amp;quot;) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/lrreggraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This works well too.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;more-advanced-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More advanced models&lt;/h2&gt;
&lt;p&gt;A dummy example with some code for Generalized Additive Models, LOESS and SVM.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nb.samp = 1000
df = data.frame(x = runif(nb.samp, 0, 100))
df$y = rnorm(nb.samp, 0, 5) + abs(df$x - 25)
df$y = ifelse(df$x &amp;gt; 40, rnorm(nb.samp, 0, 5) - df$x * 
    df$x/300 + 20, df$y)
ggplot(df, aes(x = x, y = y)) + geom_point(alpha = 0.5) + 
    theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/blm-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm.o = glm(y ~ x, data = df)
loess.o = loess(y ~ x, data = df)
library(mgcv)
gam.o = gam(y ~ s(x, bs = &amp;quot;cs&amp;quot;), data = df)
library(e1071)
svm.o = svm(y ~ x, data = df)

pred.df = rbind(df %&amp;gt;% mutate(y = predict(glm.o), model = &amp;quot;glm&amp;quot;), 
    df %&amp;gt;% mutate(y = predict(gam.o), model = &amp;quot;gam&amp;quot;), 
    df %&amp;gt;% mutate(y = predict(loess.o), model = &amp;quot;LOESS&amp;quot;), 
    df %&amp;gt;% mutate(y = predict(svm.o), model = &amp;quot;SVM&amp;quot;))

ggplot(df, aes(x = x, y = y)) + geom_point(alpha = 0.2) + 
    geom_line(aes(colour = model), size = 2, alpha = 0.9, 
        data = pred.df) + theme_bw() + scale_colour_brewer(palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/blmmodels-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Enrichment between genomic regions</title>
          <link>/Hippocamplus/2017/09/05/enrichment-between-genomic-regions/</link>
          <pubDate>Tue, 05 Sep 2017 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2017/09/05/enrichment-between-genomic-regions/</guid>
          <description>&lt;p&gt;Testing if two sets of genomic regions overlap significantly is not straightforward. In the simple situation of regions of 1 bp (e.g. SNVs) we could use a hypergeometric test. When the regions are small enough and there are not too many, the hypergeometric test might also be a fair approximation.&lt;/p&gt;
&lt;p&gt;But when we manipulate many regions of variable size covering the entire genome it’s not as straightforward. The gene annotation is an example. The repeat annotation is even worse as it covers almost 50% of the genome and contains different families with very different size/location profiles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr)
library(magrittr)
library(broom)
library(knitr)
library(tidyr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;simulated-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulated data&lt;/h2&gt;
&lt;p&gt;In a very simple scenario of having only one chromosome of size 250 Mbp.&lt;/p&gt;
&lt;p&gt;First let’s create a function that draw random regions (ranges) in this chromosome.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(IRanges)
randRegions &amp;lt;- function(sizes, max.pos = 2.5e+08, max.iter = 10) {
    gr = IRanges(runif(length(sizes), 0, max.pos - 
        sizes), width = sizes)
    dup = which(countOverlaps(gr, gr) &amp;gt; 1)
    iter = 1
    while (iter &amp;lt;= max.iter &amp;amp; length(dup) &amp;gt; 0) {
        gr[dup] = IRanges(runif(length(dup), 0, max.pos - 
            sizes[dup]), width = sizes[dup])
        dup = which(countOverlaps(gr, gr) &amp;gt; 1)
    }
    return(gr)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now some regions will be our “repeats”: 10,000 regions from size 10 bp to 6 Kbp.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rep.r = randRegions(runif(10000, 10, 6000))
sum(width(rep.r))/2.5e+08&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1196666&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They cover 11.97% of the chromosome.&lt;/p&gt;
&lt;p&gt;Now if we have another set of regions and we want to know how much they overlap with the repeats we could use the hypergeometric test. With this test we assume that we are sampling bases in the genome and testing if it’s covered by a repeat. In that sense, we expect 11.97% of our regions to overlap a repeat. If we compare random regions there shouldn’t be a significant overlap and the distribution of the P-value should be flat.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testHG &amp;lt;- function(feat.r, nb = 1000, size = 1, nb.test = 3000, 
    total.b = 2.5e+08) {
    exp.b = sum(width(feat.r))
    sapply(1:nb.test, function(ii) {
        reg.r = randRegions(rep(size, nb))
        obs.ol = sum(overlapsAny(reg.r, feat.r))
        phyper(obs.ol, exp.b, total.b - exp.b, length(reg.r), 
            lower.tail = FALSE)
    })
}

ht.sim = rbind(data.frame(nb = 1000, size = 1, pv = testHG(rep.r, 
    1000, 1)), data.frame(nb = 1000, size = 1000, pv = testHG(rep.r, 
    1000, 1000)), data.frame(nb = 100, size = 1000, 
    pv = testHG(rep.r, 100, 1000)), data.frame(nb = 1000, 
    size = 100, pv = testHG(rep.r, 1000, 100)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ht.sim %&amp;gt;% mutate(nbsize = paste0(nb, &amp;quot; x &amp;quot;, size, 
    &amp;quot;bp&amp;quot;)) %&amp;gt;% group_by(nbsize) %&amp;gt;% arrange(pv) %&amp;gt;% 
    mutate(cumprop = (1:n())/n()) %&amp;gt;% ggplot(aes(x = pv, 
    y = cumprop, color = nbsize)) + geom_line() + theme_bw() + 
    geom_abline(linetype = 2) + ylab(&amp;quot;cumulative proportion&amp;quot;) + 
    xlab(&amp;quot;P-value&amp;quot;) + scale_color_brewer(palette = &amp;quot;Set1&amp;quot;, 
    name = &amp;quot;regions&amp;quot;) + theme(legend.justification = c(1, 
    0), legend.position = c(0.99, 0.01))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/testhggraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the hypergeometric test works well for region of 1 bp. Otherwise the distribution of the P-values is biased. The larger the regions the stronger the bias. To a lower extent, more regions also means more bias.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-control-regions-with-similar-features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using control regions with similar features&lt;/h2&gt;
&lt;p&gt;We want to control for the size distribution and the total number of regions tested. Instead of the hypergeometric test, we can get control regions and compare their overlap with the actual regions, using a logistic regression for example. The control regions must be randomly distributed in the genome but have the same size distribution as our original regions. In the logistic regression we compare the two binary variables: overlapping a repeat or not, being an original region or a control region.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testLR &amp;lt;- function(feat.r, nb = 1000, size = 1, nb.test = 3000) {
    sapply(1:nb.test, function(ii) {
        reg.r = randRegions(rep(size, nb))
        cont.r = randRegions(width(reg.r))
        df = rbind(data.frame(region = TRUE, ol = overlapsAny(reg.r, 
            feat.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
            feat.r)))
        pvs = glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
            tidy %&amp;gt;% .$p.value
        pvs[2]
    })
}

lr.sim = rbind(data.frame(nb = 1000, size = 1, pv = testLR(rep.r, 
    1000, 1)), data.frame(nb = 1000, size = 1000, pv = testLR(rep.r, 
    1000, 1000)), data.frame(nb = 100, size = 1000, 
    pv = testLR(rep.r, 100, 1000)), data.frame(nb = 1000, 
    size = 100, pv = testLR(rep.r, 1000, 100)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lr.sim %&amp;gt;% mutate(nbsize = paste0(nb, &amp;quot; x &amp;quot;, size, 
    &amp;quot;bp&amp;quot;)) %&amp;gt;% group_by(nbsize) %&amp;gt;% arrange(pv) %&amp;gt;% 
    mutate(cumprop = (1:n())/n()) %&amp;gt;% ggplot(aes(x = pv, 
    y = cumprop, color = nbsize)) + geom_line() + theme_bw() + 
    geom_abline(linetype = 2) + ylab(&amp;quot;cumulative proportion&amp;quot;) + 
    xlab(&amp;quot;P-value&amp;quot;) + scale_color_brewer(palette = &amp;quot;Set1&amp;quot;, 
    name = &amp;quot;regions&amp;quot;) + theme(legend.justification = c(1, 
    0), legend.position = c(0.99, 0.01))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/contreggraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The distribution of the P-values is much better.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;controlling-for-correlated-features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Controlling for correlated features&lt;/h2&gt;
&lt;p&gt;In the genome, the distribution of genes, repeats, functional regions, and others is not random. Different types of elements tend to be found together while others don’t. For example some repeats are located in GC-rich regions and others in AT-rich regions. Transposable elements don’t overlap exonic regions much. Their are hotspots of segmental duplications.&lt;/p&gt;
&lt;p&gt;Sometimes we want to control for the overlap with one (or more) genomic features to test the independent association of another. For example, we known copy number variants (CNVs) are enriched in segmental duplications and transposable elements are also enriched in segmental duplications. We might want to test if CNVs are independently enriched in regions with transposable elements, controlling for the overlap with segmental duplications.&lt;/p&gt;
&lt;p&gt;I tried to simulate a first set of regions that significantly overlaps our repeats and another one that significantly overlaps the first set. That way we should see a significant overlap with repeat when we test them separately, but the second one should be significant when we control for the first one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corRegions &amp;lt;- function(sizes, feat.r, or = 2, max.iter = 10, 
    max.pos = 2.5e+08) {
    reg.r = randRegions(sizes)
    for (ii in 1:or) {
        reg.r = c(reg.r[overlapsAny(reg.r, feat.r)], 
            randRegions(sizes))
    }
    dup = which(countOverlaps(reg.r, reg.r) &amp;gt; 1)
    sizes = width(reg.r)
    iter = 1
    while (iter &amp;lt;= max.iter &amp;amp; length(dup) &amp;gt; 0) {
        reg.r[dup] = IRanges(runif(length(dup), 0, 
            max.pos - sizes[dup]), width = sizes[dup])
        dup = which(countOverlaps(reg.r, reg.r) &amp;gt; 1)
    }
    reg.r
}

## First set of regions
repcor.r = corRegions(rep(10000, 1000), rep.r)
cont.r = randRegions(width(repcor.r))
df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcor.r, 
    rep.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
    rep.r)))
glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2375323&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0464770&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.11075&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3e-07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8549335&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0670786&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.74525&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Second set of regions
seed.r = randRegions(rep(10000, 6000))
seed.ol = overlapsAny(seed.r, repcor.r)
repcorcor.r = c(seed.r[seed.ol], seed.r[head(which(!seed.ol), 
    sum(!seed.ol) * 0.05)])
cont.r = randRegions(width(repcorcor.r))
df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcorcor.r, 
    rep.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
    rep.r)))
glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2231436&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0590620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.778125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0001580&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2214209&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0832684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.659123&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0078344&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;extending-the-logistic-regression-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extending the logistic regression model&lt;/h3&gt;
&lt;p&gt;One strategy is to add a variable in the model that represents the effect we want to control for.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcorcor.r, 
    rep.r), repcor = overlapsAny(repcorcor.r, repcor.r)), 
    data.frame(region = FALSE, ol = overlapsAny(cont.r, 
        rep.r), repcor = overlapsAny(cont.r, repcor.r)))
glm(ol ~ region + repcor, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2817899&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0612109&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.6035936&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0452678&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1093757&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4138742&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6789663&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;repcorTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4156934&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1096425&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.7913531&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0001498&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As expected, adding a variable in the model controls for this.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;better-control-regions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Better control regions&lt;/h3&gt;
&lt;p&gt;Another approach is to control the specific overlap in the control regions. We want to force our control regions to overlap as much with the feature as the original regions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;randRegionsCons &amp;lt;- function(reg.r, feat.r, nb.seed = 1e+06) {
    seed.r = randRegions(rep(1, nb.seed))
    dist.df = distanceToNearest(seed.r, feat.r) %&amp;gt;% 
        as.data.frame
    reg.ol = overlapsAny(reg.r, feat.r)
    res.r = lapply(unique(width(reg.r)), function(size) {
        size.ii = which(width(reg.r) == size)
        res.r = IRanges()
        if (sum(reg.ol[size.ii]) &amp;gt; 0) {
            seed.ii = dist.df %&amp;gt;% filter(distance &amp;lt; 
                size/2) %&amp;gt;% .$queryHits %&amp;gt;% sample(sum(reg.ol[size.ii]))
            res.r = c(res.r, resize(seed.r[seed.ii], 
                size, fix = &amp;quot;center&amp;quot;))
        }
        if (sum(!reg.ol[size.ii]) &amp;gt; 0) {
            seed.ii = dist.df %&amp;gt;% filter(distance &amp;gt; 
                size/2) %&amp;gt;% .$queryHits %&amp;gt;% sample(sum(!reg.ol[size.ii]))
            res.r = c(res.r, resize(seed.r[seed.ii], 
                size, fix = &amp;quot;center&amp;quot;))
        }
        res.r
    })
    do.call(c, res.r)
}

contSize.r = randRegionsCons(repcorcor.r, repcor.r)
df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcorcor.r, 
    rep.r), repcor = overlapsAny(repcorcor.r, repcor.r)), 
    data.frame(region = FALSE, ol = overlapsAny(contSize.r, 
        rep.r), repcor = overlapsAny(contSize.r, repcor.r)))
glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1709578&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0589111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.901961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0037083&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1726805&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0831615&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.076448&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0378526&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It works too. One benefit of this approach is its interpretability: we can directly compare summary metrics using the control regions, e.g. like the proportion of regions overlapping repeats.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(repcorcor.r, repcor.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7812231&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(cont.r, repcor.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1395349&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(contSize.r, repcor.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7812231&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This could be useful in situation with extreme overlap distribution. If only a few regions overlap the feature in the simple control regions, the regression might not correct for it as well as if forcing the control regions to be similar. Maybe there would some differences in power in those cases ?&lt;/p&gt;
&lt;p&gt;However building these control regions can become computationally intense, especially if the sizes of the regions vary and several features need to be controlled.&lt;/p&gt;
&lt;p&gt;In practice I would do both: include the variable in the regression model and use regions with controlled overlap.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparing-different-sets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparing different sets&lt;/h2&gt;
&lt;p&gt;What if we need to compare sets of regions &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; with a third one &lt;em&gt;C&lt;/em&gt;. If the &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; are comparable in term of size and total number we could directly compare the overlap or an enrichment estimate (e.g. model estimate). If &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; have different size distribution or just total number of regions, these estimates may not be directly comparable. If they both overlap significantly with &lt;em&gt;C&lt;/em&gt;, the previous test (control regions + logistic regression) should test them significant. Even the P-value might be affected by the difference in size/number between the two sets. But how should we compared them ? Which interpretable metric could we use to compare enrichment of two different sets or regions ?&lt;/p&gt;
&lt;p&gt;A practical example would be two catalogs of CNVs, say from two different methods, that we want to compare to a functional annotation. If one catalogs has more CNVs, or has larger CNVs, how can we say which one overlaps better with the functional annotation ?&lt;/p&gt;
&lt;p&gt;I simulate this scenario and compare a few metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The fold-change in overlap proportion: proportion overlapping / proportion overlapping in control regions.&lt;/li&gt;
&lt;li&gt;The diff-change in overlap proportion: proportion overlapping - proportion overlapping in control regions.&lt;/li&gt;
&lt;li&gt;The logistic regression estimate which are log odds ratio.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, the main question was how should I simulate this. I ended up simulating two sets with similar odds ratio so we already know which metric will work better… One of the value of simulation is to force us to define the question. Or at least think about it. In this example, forcing two different sets to have similar odds ratio seemed more natural than trying to double the proportion for example. The odds ratio seems more fair to me and might avoid the situation where we are more likely to observe a large effect size just because the regions are rarer/smaller.&lt;/p&gt;
&lt;p&gt;Using a set of functional regions, I will try to compare a set of small CNVs and large CNVs. We expect more of the large CNVs to overlap the functional regions by chance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fun.r = randRegions(rep(10, 30000))
cnv.sm = randRegions(rep(1000, 1000))
cnv.lg = randRegions(rep(10000, 1000))
mean(overlapsAny(cnv.sm, fun.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.112&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(cnv.lg, fun.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.688&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testLR &amp;lt;- function(reg.r, feat.r) {
    cont.r = randRegions(width(reg.r))
    df.sm = rbind(data.frame(region = TRUE, ol = overlapsAny(reg.r, 
        feat.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
        feat.r)))
    rbind(data.frame(term = &amp;quot;fold-change&amp;quot;, estimate = mean(overlapsAny(reg.r, 
        feat.r))/mean(overlapsAny(cont.r, feat.r)), 
        p.value = NA), data.frame(term = &amp;quot;diff-change&amp;quot;, 
        estimate = mean(overlapsAny(reg.r, feat.r)) - 
            mean(overlapsAny(cont.r, feat.r)), p.value = NA), 
        glm(ol ~ region, data = df.sm, family = binomial()) %&amp;gt;% 
            tidy %&amp;gt;% select(term, estimate, p.value))
}

metrics.df = rbind(testLR(cnv.sm, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.sm&amp;quot;), 
    testLR(cnv.lg, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.lg&amp;quot;))
metrics.df %&amp;gt;% filter(term != &amp;quot;(Intercept)&amp;quot;) %&amp;gt;% select(region, 
    term, estimate) %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;region&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.sm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;fold-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0566038&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.sm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;diff-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0060000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.sm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0617938&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.lg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;fold-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9745042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.lg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;diff-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0180000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.lg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0852498&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;no-association&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;No association&lt;/h3&gt;
&lt;p&gt;If the CNVs are not enriched in the functional regions, how do the three metrics compare ?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df = lapply(1:1000, function(ii) {
    cnv.sm = randRegions(rep(1000, 1000))
    cnv.lg = randRegions(rep(10000, 1000))
    rbind(testLR(cnv.sm, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.sm&amp;quot;, 
        rep = ii), testLR(cnv.lg, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.lg&amp;quot;, 
        rep = ii))
})
null.df = do.call(rbind, null.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df %&amp;gt;% filter(term == &amp;quot;regionTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;log odds ratio&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvnoassocgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df %&amp;gt;% filter(term == &amp;quot;fold-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 1) + ggtitle(&amp;quot;fold-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvnoassocgraph-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df %&amp;gt;% filter(term == &amp;quot;diff-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;diff-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvnoassocgraph-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The three metrics are centered in 0 but the variance of the fold-change metric is much higher for the small CNVs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;association&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Association&lt;/h3&gt;
&lt;p&gt;If the odds of overlapping the functional regions are doubled.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df = lapply(1:1000, function(ii) {
    cnv.sm = randRegions(rep(1000, 1000))
    cnv.lg = randRegions(rep(10000, 1000))
    cnv.sm = c(cnv.sm[overlapsAny(cnv.sm, fun.r)], 
        randRegions(rep(1000, 1000)))
    cnv.lg = c(cnv.lg[overlapsAny(cnv.lg, fun.r)], 
        randRegions(rep(10000, 1000)))
    rbind(testLR(cnv.sm, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.sm&amp;quot;, 
        rep = ii), testLR(cnv.lg, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.lg&amp;quot;, 
        rep = ii))
})
asso.df = do.call(rbind, asso.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df %&amp;gt;% filter(term == &amp;quot;regionTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;log odds ratio&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvassocgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df %&amp;gt;% filter(term == &amp;quot;fold-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 1) + ggtitle(&amp;quot;fold-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvassocgraph-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df %&amp;gt;% filter(term == &amp;quot;diff-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;diff-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvassocgraph-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected by construction, only the logistic regression estimate are similar. If we used the fold-change metric it would look like the small CNVs are more enriched; with the diff-change metric the large CNVs would.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Segmental duplication exploration</title>
          <link>/Hippocamplus/2016/10/20/segmental-duplication-exploration/</link>
          <pubDate>Thu, 20 Oct 2016 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2016/10/20/segmental-duplication-exploration/</guid>
          <description>&lt;div id=&#34;segmental-duplications-sd&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Segmental Duplications (SD)&lt;/h2&gt;
&lt;p&gt;I downloaded the segmental duplication annotation for hg19 from &lt;a href=&#34;http://hgdownload.soe.ucsc.edu/goldenPath/hg19/database/genomicSuperDups.txt.gz&#34;&gt;UCSC&lt;/a&gt;. There are 51599 annotated SD. They are defined as regions larger than 1 Kbp with at least 90% similarity with another region in the genome.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;segmental-duplication-regions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Segmental duplication regions&lt;/h2&gt;
&lt;p&gt;Many SD are nested of located next to each other. I merge overlapping SDs (or located at &amp;lt;10 bp) to create &lt;em&gt;SD regions&lt;/em&gt;, i.e. longer stretch of the genome overlapping SDs.&lt;/p&gt;
&lt;p&gt;There are 7620 SD regions, that account for 166.1 Mbp of the genome.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;size-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Size distribution&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-10-20-SegDupExploration_files/figure-html/size-1.png&#34; width=&#34;768&#34; /&gt;&lt;img src=&#34;./post/2016-10-20-SegDupExploration_files/figure-html/size-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;similarity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Similarity&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-10-20-SegDupExploration_files/figure-html/sim-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;chromosome-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Chromosome distribution&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-10-20-SegDupExploration_files/figure-html/chr-1.png&#34; width=&#34;768&#34; /&gt;&lt;img src=&#34;./post/2016-10-20-SegDupExploration_files/figure-html/chr-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A few chromosomes are more enriched in SD. Some have long stretches of SD, e.g. chr 9 or chr Y. These peaks are mostly created with very recent/similar SDs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;distance-to-the-other-segment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distance to the other segment&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;otherSeg&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;segdup&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;segdup.prop&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;different chr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32740&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.635&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;same chr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18859&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.365&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-10-20-SegDupExploration_files/figure-html/dist-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the majority of SDs, the similar region is in a different chromosome. For the others the majority are far from each other.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gene-content&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gene content&lt;/h2&gt;
&lt;p&gt;I downloaded Gencode v19 at &lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&#34;&gt;&lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&#34; class=&#34;uri&#34;&gt;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Around a thousand protein-coding genes are completely within SD regions.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;gene_type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;gene&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;pseudogene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3968&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;958&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lincRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;641&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;miRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;301&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;antisense&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;181&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;snRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;179&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;IG_V_pseudogene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;97&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;misc_RNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;IG_V_gene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;86&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;rRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;processed_transcript&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sense_intronic&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TR_V_gene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;snoRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;IG_D_gene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;IG_C_gene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;polymorphic_pseudogene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TR_V_pseudogene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TR_J_gene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sense_overlapping&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;IG_C_pseudogene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;IG_J_gene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TR_C_gene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;gene-families&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Gene families&lt;/h3&gt;
&lt;p&gt;A naive way of looking for gene families is to cluster the gene names. I also remove any trailing numbers in the gene name.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;example&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PRAMEF&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;USP17L&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;ZNF&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;GOLGA8I&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;NBPF&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CT47B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;POTEF&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;OR2T&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;gene-ontology&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Gene Ontology&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GeneRatio&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qvalue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0050907&#34; class=&#34;uri&#34;&gt;GO:0050907&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;detection of chemical stimulus involved in sensory perception&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0009593&#34; class=&#34;uri&#34;&gt;GO:0009593&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;detection of chemical stimulus&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;58/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0007606&#34; class=&#34;uri&#34;&gt;GO:0007606&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;sensory perception of chemical stimulus&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;59/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0007608&#34; class=&#34;uri&#34;&gt;GO:0007608&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;sensory perception of smell&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;53/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0050911&#34; class=&#34;uri&#34;&gt;GO:0050911&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;detection of chemical stimulus involved in sensory perception of smell&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;51/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0050906&#34; class=&#34;uri&#34;&gt;GO:0050906&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;detection of stimulus involved in sensory perception&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0042742&#34; class=&#34;uri&#34;&gt;GO:0042742&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;defense response to bacterium&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;23/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002887&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0098542&#34; class=&#34;uri&#34;&gt;GO:0098542&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;defense response to other organism&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;35/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002887&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0071346&#34; class=&#34;uri&#34;&gt;GO:0071346&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cellular response to interferon-gamma&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;17/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002992&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0006805&#34; class=&#34;uri&#34;&gt;GO:0006805&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;xenobiotic metabolic process&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002992&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0071466&#34; class=&#34;uri&#34;&gt;GO:0071466&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cellular response to xenobiotic stimulus&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0004487&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0033141&#34; class=&#34;uri&#34;&gt;GO:0033141&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;positive regulation of peptidyl-serine phosphorylation of STAT protein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0004487&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0002323&#34; class=&#34;uri&#34;&gt;GO:0002323&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;natural killer cell activation involved in immune response&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;8/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0005222&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0033139&#34; class=&#34;uri&#34;&gt;GO:0033139&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;regulation of peptidyl-serine phosphorylation of STAT protein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0005486&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0009410&#34; class=&#34;uri&#34;&gt;GO:0009410&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;response to xenobiotic stimulus&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0007752&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0034341&#34; class=&#34;uri&#34;&gt;GO:0034341&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;response to interferon-gamma&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;17/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0012694&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0006749&#34; class=&#34;uri&#34;&gt;GO:0006749&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;glutathione metabolic process&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0014056&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0042501&#34; class=&#34;uri&#34;&gt;GO:0042501&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;serine phosphorylation of STAT protein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0019334&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0016579&#34; class=&#34;uri&#34;&gt;GO:0016579&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein deubiquitination&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0035460&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0060337&#34; class=&#34;uri&#34;&gt;GO:0060337&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;type I interferon signaling pathway&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0040381&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0071357&#34; class=&#34;uri&#34;&gt;GO:0071357&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cellular response to type I interferon&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0040381&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0006342&#34; class=&#34;uri&#34;&gt;GO:0006342&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chromatin silencing&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;13/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0046589&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0034340&#34; class=&#34;uri&#34;&gt;GO:0034340&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;response to type I interferon&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0058697&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0030101&#34; class=&#34;uri&#34;&gt;GO:0030101&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;natural killer cell activation&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0090640&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0070646&#34; class=&#34;uri&#34;&gt;GO:0070646&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein modification by small protein removal&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0114298&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0009812&#34; class=&#34;uri&#34;&gt;GO:0009812&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;flavonoid metabolic process&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0138310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0033559&#34; class=&#34;uri&#34;&gt;GO:0033559&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;unsaturated fatty acid metabolic process&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0138310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0000042&#34; class=&#34;uri&#34;&gt;GO:0000042&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein targeting to Golgi&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0138310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0019373&#34; class=&#34;uri&#34;&gt;GO:0019373&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;epoxygenase P450 pathway&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0138310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0045814&#34; class=&#34;uri&#34;&gt;GO:0045814&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;negative regulation of gene expression, epigenetic&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;13/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0138310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0060338&#34; class=&#34;uri&#34;&gt;GO:0060338&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;regulation of type I interferon-mediated signaling pathway&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0139433&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0006690&#34; class=&#34;uri&#34;&gt;GO:0006690&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;icosanoid metabolic process&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0144589&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0009813&#34; class=&#34;uri&#34;&gt;GO:0009813&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;flavonoid biosynthetic process&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0165692&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0006959&#34; class=&#34;uri&#34;&gt;GO:0006959&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;humoral immune response&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;15/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0202359&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0002228&#34; class=&#34;uri&#34;&gt;GO:0002228&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;natural killer cell mediated immunity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;8/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0226821&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0006334&#34; class=&#34;uri&#34;&gt;GO:0006334&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;nucleosome assembly&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;13/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0227629&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0006968&#34; class=&#34;uri&#34;&gt;GO:0006968&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cellular defense response&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;8/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0232698&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0052696&#34; class=&#34;uri&#34;&gt;GO:0052696&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;flavonoid glucuronidation&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0232698&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0072600&#34; class=&#34;uri&#34;&gt;GO:0072600&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;establishment of protein localization to Golgi&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0232698&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0043330&#34; class=&#34;uri&#34;&gt;GO:0043330&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;response to exogenous dsRNA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0234523&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0001906&#34; class=&#34;uri&#34;&gt;GO:0001906&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cell killing&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0249099&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0001580&#34; class=&#34;uri&#34;&gt;GO:0001580&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;detection of chemical stimulus involved in sensory perception of bitter taste&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0322850&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0052695&#34; class=&#34;uri&#34;&gt;GO:0052695&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cellular glucuronidation&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0331023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0042737&#34; class=&#34;uri&#34;&gt;GO:0042737&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;drug catabolic process&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0378567&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0000301&#34; class=&#34;uri&#34;&gt;GO:0000301&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;retrograde transport, vesicle recycling within Golgi&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0389140&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0031497&#34; class=&#34;uri&#34;&gt;GO:0031497&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chromatin assembly&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;13/509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0483266&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GeneRatio&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qvalue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0004984&#34; class=&#34;uri&#34;&gt;GO:0004984&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;olfactory receptor activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;51/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0016712&#34; class=&#34;uri&#34;&gt;GO:0016712&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;oxidoreductase activity, acting on paired donors, with incorporation or reduction of molecular oxygen, reduced flavin or flavoprotein as one donor, and incorporation of one atom of oxygen&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;8/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000499&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0005132&#34; class=&#34;uri&#34;&gt;GO:0005132&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;type I interferon receptor binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000499&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0008391&#34; class=&#34;uri&#34;&gt;GO:0008391&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;arachidonic acid monooxygenase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002238&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0008392&#34; class=&#34;uri&#34;&gt;GO:0008392&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;arachidonic acid epoxygenase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002238&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0036459&#34; class=&#34;uri&#34;&gt;GO:0036459&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;thiol-dependent ubiquitinyl hydrolase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002238&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0101005&#34; class=&#34;uri&#34;&gt;GO:0101005&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ubiquitinyl hydrolase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002238&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0008395&#34; class=&#34;uri&#34;&gt;GO:0008395&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;steroid hydroxylase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;8/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002715&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0019825&#34; class=&#34;uri&#34;&gt;GO:0019825&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;oxygen binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;9/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0004195&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0019783&#34; class=&#34;uri&#34;&gt;GO:0019783&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ubiquitin-like protein-specific protease activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0005119&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0003823&#34; class=&#34;uri&#34;&gt;GO:0003823&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;antigen binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0007524&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0004497&#34; class=&#34;uri&#34;&gt;GO:0004497&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;monooxygenase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0008659&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0070330&#34; class=&#34;uri&#34;&gt;GO:0070330&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;aromatase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0009112&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0020037&#34; class=&#34;uri&#34;&gt;GO:0020037&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;heme binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;13/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0029793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0048020&#34; class=&#34;uri&#34;&gt;GO:0048020&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CCR chemokine receptor binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0030635&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0019864&#34; class=&#34;uri&#34;&gt;GO:0019864&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;IgG binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0038146&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0046906&#34; class=&#34;uri&#34;&gt;GO:0046906&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;tetrapyrrole binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;13/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0050261&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0042605&#34; class=&#34;uri&#34;&gt;GO:0042605&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;peptide antigen binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0078319&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0005506&#34; class=&#34;uri&#34;&gt;GO:0005506&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;iron ion binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;13/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0176137&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0004364&#34; class=&#34;uri&#34;&gt;GO:0004364&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;glutathione transferase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0236924&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0005125&#34; class=&#34;uri&#34;&gt;GO:0005125&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cytokine activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0236924&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0008234&#34; class=&#34;uri&#34;&gt;GO:0008234&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cysteine-type peptidase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0236924&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0042379&#34; class=&#34;uri&#34;&gt;GO:0042379&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chemokine receptor binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0364788&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0015020&#34; class=&#34;uri&#34;&gt;GO:0015020&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;glucuronosyltransferase activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0364788&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0016705&#34; class=&#34;uri&#34;&gt;GO:0016705&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;oxidoreductase activity, acting on paired donors, with incorporation or reduction of molecular oxygen&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0364788&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0019865&#34; class=&#34;uri&#34;&gt;GO:0019865&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;immunoglobulin binding&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0422110&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0008009&#34; class=&#34;uri&#34;&gt;GO:0008009&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;chemokine activity&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0435900&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GeneRatio&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qvalue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0045095&#34; class=&#34;uri&#34;&gt;GO:0045095&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;keratin filament&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000242&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0005882&#34; class=&#34;uri&#34;&gt;GO:0005882&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;intermediate filament&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;19/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0042923&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0042611&#34; class=&#34;uri&#34;&gt;GO:0042611&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;MHC protein complex&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0057256&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0071556&#34; class=&#34;uri&#34;&gt;GO:0071556&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integral component of lumenal side of endoplasmic reticulum membrane&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0074647&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0098553&#34; class=&#34;uri&#34;&gt;GO:0098553&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;lumenal side of endoplasmic reticulum membrane&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0074647&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0045111&#34; class=&#34;uri&#34;&gt;GO:0045111&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;intermediate filament cytoskeleton&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;19/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0171090&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0000786&#34; class=&#34;uri&#34;&gt;GO:0000786&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;nucleosome&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0178803&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0044815&#34; class=&#34;uri&#34;&gt;GO:0044815&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DNA packaging complex&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0258667&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0012507&#34; class=&#34;uri&#34;&gt;GO:0012507&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ER to Golgi transport vesicle membrane&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0434286&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;GO:0072562&#34; class=&#34;uri&#34;&gt;GO:0072562&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;blood microparticle&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11/589&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0438412&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Summary epigenetic mark tracks</title>
          <link>/Hippocamplus/2016/09/06/summary-epigenetic-mark-tracks/</link>
          <pubDate>Tue, 06 Sep 2016 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2016/09/06/summary-epigenetic-mark-tracks/</guid>
          <description>&lt;p&gt;To assess the potential impact of variants (SNV, SVs) we might want to use some of the public epigentic datasets. The amount and heterogeneity of this data is a bit overwhelming. I would like to get a summary of which regions of the genome are the most functionally important.&lt;/p&gt;
&lt;p&gt;The plan is to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get annotated &lt;strong&gt;peaks&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;for the 6 &lt;strong&gt;typical histone marks&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;in &lt;strong&gt;5-6 tissues&lt;/strong&gt;, merging sub-tissues (e.g. brain subregions)&lt;/li&gt;
&lt;li&gt;keep regions &lt;strong&gt;supported by enough replicates&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Eventually, I could also annotate the regions that are tissue-specific or shared across tissues.&lt;/p&gt;
&lt;p&gt;The R-markdown source code is in the website’s &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/blob/gh-pages/_source/2016-09-06-epigeneticTracks.Rmd&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;annotationhub&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;AnnotationHub&lt;/h2&gt;
&lt;p&gt;I’ll use the &lt;a href=&#34;http://bioconductor.org/packages/release/bioc/html/AnnotationHub.html&#34;&gt;AnnotationHub&lt;/a&gt; package, which links Encode and EpigenomeRoadmap data (and more) directly in R.&lt;/p&gt;
&lt;p&gt;I search for &lt;em&gt;narrowPeak&lt;/em&gt; in &lt;em&gt;hg19&lt;/em&gt; from H3K27ac, H3K27me3, H3K36me3, H3K4me1, H3K4me3 or H3K9me3, in brain, blood, liver, muscle, lung, kidney, skin or heart. I also look for DNase peaks. Let’s see if I can find what I want.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/ahgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Most tissues have more than 3 tracks for each histone mark. I’ll just exclude liver and knidney that don’t. DNase is a bit more rare but there is at least one track per tissue. In total, it represents 360 different tracks, that I want to merge into one track per mark/tissue.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;download-and-merge-tracks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Download and merge tracks&lt;/h2&gt;
&lt;p&gt;For each mark/tissue, I download the available tracks, overlap the peaks into sub-peaks (&lt;em&gt;disjoin&lt;/em&gt;) and keep the pieces supported by more than half the tracks. Finally, these recurrent sub-peaks are stitched (&lt;em&gt;reduce&lt;/em&gt;) if closer than 500 bp.&lt;/p&gt;
&lt;p&gt;Afterwards, the regions for each mark is annotated with the number of tissues with overlapping regions.&lt;/p&gt;
&lt;p&gt;The results were uploaded there: &lt;a href=&#34;https://dl.dropboxusercontent.com/s/8c412u1ug2lwrc2/epiTracks.RData?dl=0&#34;&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/s/8c412u1ug2lwrc2/epiTracks.RData?dl=0&#34; class=&#34;uri&#34;&gt;https://dl.dropboxusercontent.com/s/8c412u1ug2lwrc2/epiTracks.RData?dl=0&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/overview-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/overview-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/overview-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;p&gt;I searched all tracks with keywords &lt;em&gt;&lt;span class=&#34;math&#34;&gt;\(tissue*, *\)&lt;/span&gt;mark&lt;/em&gt; (and &lt;em&gt;narrowPeak&lt;/em&gt;, &lt;em&gt;hg19&lt;/em&gt;). I’m &lt;strong&gt;not completely sure that the different tracks come from different replicates.&lt;/strong&gt; I think I avoided the “bioinformatics” replicates by taking only the &lt;em&gt;narrowPeaks&lt;/em&gt;. And when there are different sub-tissues (e.g. for brain), I decided to keep only regions supported by half the tracks, but then I &lt;strong&gt;might miss the specific a sub-tissue regions&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I also made &lt;strong&gt;some arbitrary choices&lt;/strong&gt;. For example, in for a particular mark/tissue, I stitch together regions that are at 500 bp or less. The main motivation is to reduce the amount of data. Also, I’m interested in large variants (SVs), so this resolution is fine.&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gencode exploration</title>
          <link>/Hippocamplus/2016/06/04/gencode-exploration/</link>
          <pubDate>Sat, 04 Jun 2016 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2016/06/04/gencode-exploration/</guid>
          <description>&lt;div id=&#34;gencode-v19&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gencode v19&lt;/h2&gt;
&lt;p&gt;I downloaded Gencode v19 at &lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&#34;&gt;&lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&#34; class=&#34;uri&#34;&gt;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;genes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Genes&lt;/h2&gt;
&lt;div id=&#34;number&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Number&lt;/h3&gt;
&lt;p&gt;Focusing on autosomes/X/Y, there are 57,783 “genes” of different types:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genetypes-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I merge the rare types into a &lt;em&gt;other&lt;/em&gt; class and some RNAs.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;gene_type.f&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20332&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;pseudogene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13931&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;other&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7417&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lincRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7114&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;RNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5934&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;miRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3055&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;size&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Size&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genesize-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The largest annotated genes span more than 2 Mbp:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.Mbp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CNTNAP2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.304638&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PTPRD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.298478&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chrX&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DMD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.241765&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;LSAMP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.194861&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DLG2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.172912&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The smallest protein-coding annotated genes less than 100 bp:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.bp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC011308.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;59&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr12&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC055736.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PIH1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC012360.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC008914.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;102&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;density&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Density&lt;/h3&gt;
&lt;p&gt;Using non-overlapping windows of 1 Mb the gene density looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genedens-1.png&#34; width=&#34;768&#34; /&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genedens-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chr 19, 17 and 11 have more protein-coding genes than the rest.&lt;/li&gt;
&lt;li&gt;Chr Y has more pseudogene compared to other classes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exons&lt;/h2&gt;
&lt;div id=&#34;number-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Number&lt;/h3&gt;
&lt;p&gt;Focusing on autosomes/X/Y, there are 1,196,256 “exons” from different types of genes:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exontype-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the rest of the analysis, I use only exons from protein-coding genes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;number-per-gene&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Number per gene&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exongene-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;mean.nb.exon&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;median.nb.exon&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;max.nb.exon&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;52.9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1696&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The gene with the most exons is the &lt;a href=&#34;http://www.genecards.org/cgi-bin/carddisp.pl?gene=TTN&#34;&gt;Titin gene&lt;/a&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;exon&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TTN&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1696&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SYNE1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1377&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;NEB&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1225&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CACNA1G&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1139&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CACNA1C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1098&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;size-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Size&lt;/h3&gt;
&lt;p&gt;The average exon size is 232 bp.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exonsize-1.png&#34; width=&#34;768&#34; /&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exonsize-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The first exon seems to be slightly larger than the others. I used genes with at least 10 exons to be sure it’s not due to large single-exon genes.&lt;/p&gt;
&lt;p&gt;The largest annotated exons are more than 20 Kbp long:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.kb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRAPPC9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29.06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;MCC&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27.20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr12&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GRIN2B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr19&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;MUC16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21.69&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ABI2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20.55&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The smallest are just 1 bp !?&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.bp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ALK&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ACAD11&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PPA2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PAM&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GALNT10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Preparing some genomic annotations</title>
          <link>/Hippocamplus/2016/06/03/preparing-some-genomic-annotations/</link>
          <pubDate>Fri, 03 Jun 2016 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2016/06/03/preparing-some-genomic-annotations/</guid>
          <description>&lt;div id=&#34;mappability-track&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mappability track&lt;/h2&gt;
&lt;p&gt;I produced a mappability track from the UCSC track. The &lt;a href=&#34;http://hgdownload.soe.ucsc.edu/gbdb/hg19/bbi/wgEncodeCrgMapabilityAlign100mer.bw&#34;&gt;raw file&lt;/a&gt; contains, for each base in the genome, an estimation of the probability that a read is correctly mapped at this position.&lt;/p&gt;
&lt;p&gt;Using a sliding-window approach, I compute the average mappability in regions of size 1 Kbp. This is a more manageable amount of data and still informative, especially when interested in large regions (e.g. SVs).&lt;/p&gt;
&lt;p&gt;I used a custom Perl script to efficiently parse the bedGraph-transformed original file. See the code on &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/blob/gh-pages/_source/mappabilityBin.pl&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I uploaded the result there: &lt;a href=&#34;https://dl.dropboxusercontent.com/s/i537zjs65dpw34n/map100mer-1kbp.bed.gz?dl=0&#34;&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/s/i537zjs65dpw34n/map100mer-1kbp.bed.gz?dl=0&#34; class=&#34;uri&#34;&gt;https://dl.dropboxusercontent.com/s/i537zjs65dpw34n/map100mer-1kbp.bed.gz?dl=0&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can cut the genome into three mappability classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;unique&lt;/strong&gt; regions with high mappability estimate (&amp;gt;0.95).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;low-map&lt;/strong&gt; regions with a non-null mappability but lower than 0.95.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;no-map&lt;/strong&gt; regions with mappability 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-03-annotationPreparation_files/figure-html/summary-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;map.class&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mb&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;prop&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;unique&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2485.972&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.803&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;low-map&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;375.608&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.121&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;no-map&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;233.228&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.075&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Word Cloud in R</title>
          <link>/Hippocamplus/2016/02/26/word-cloud-in-r/</link>
          <pubDate>Fri, 26 Feb 2016 00:00:00 UTC</pubDate>
          <author>Mark Otto</author>
          <guid>/Hippocamplus/2016/02/26/word-cloud-in-r/</guid>
          <description>&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/wordcloud/index.html&#34;&gt;&lt;code&gt;wordcloud&lt;/code&gt; package&lt;/a&gt; is available on CRAN.&lt;/p&gt;
&lt;div id=&#34;fake-words&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fake words&lt;/h2&gt;
&lt;p&gt;I create fake words to see a bit how the command is working.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wordcloud)
createWords &amp;lt;- function(w.l = 3) paste(sample(letters, 
    w.l, TRUE), collapse = &amp;quot;&amp;quot;)
words = sapply(1:200, function(e) createWords(runif(1, 
    3, 10)))
freq = c(sample(1:30, 190, T), sample(30:150, 10, T))
freq = freq/sum(freq)
wordcloud(words, freq)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Big words in the center
wordcloud(words, freq, random.order = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Max word number
wordcloud(words, freq, max.words = 50)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Rotation: proportion of 90 degree
wordcloud(words, freq, rot.per = 0.01)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Color the most frequent words
wordcloud(words, freq, colors = c(&amp;quot;black&amp;quot;, &amp;quot;blue&amp;quot;, 
    &amp;quot;red&amp;quot;), random.order = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Color for each word
wordcloud(words, freq, colors = sample(c(&amp;quot;black&amp;quot;, &amp;quot;blue&amp;quot;, 
    &amp;quot;red&amp;quot;), length(words), TRUE), random.order = FALSE, 
    ordered.colors = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-6.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;command-history&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Command history&lt;/h2&gt;
&lt;p&gt;I retrieved the commands from my &lt;code&gt;.bash_history&lt;/code&gt; files (laptop and HPCs) and I want to make a word cloud showing the commands I use the most.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(RColorBrewer)
cmds = read.table(&amp;quot;../../data/bash-commands.tsv.gz&amp;quot;, 
    as.is = TRUE)
colnames(cmds) = c(&amp;quot;cmd&amp;quot;, &amp;quot;machine&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;laptop&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Laptop&lt;/h3&gt;
&lt;p&gt;By default the maximum history size was set to 500 commands so I don’t have the full set of commands, just the last 500. (I increased the limit, see you in 10,000 commands.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cmds.s = cmds %&amp;gt;% filter(machine == &amp;quot;laptop&amp;quot;, !grepl(&amp;quot;=&amp;quot;, 
    cmd), !grepl(&amp;quot;\\.&amp;quot;, cmd), !grepl(&amp;quot;/&amp;quot;, cmd)) %&amp;gt;% 
    group_by(cmd) %&amp;gt;% summarize(n = n()) %&amp;gt;% mutate(freq = n/sum(n))
wordcloud(cmds.s$cmd, cmds.s$freq, colors = c(&amp;quot;black&amp;quot;, 
    brewer.pal(8, &amp;quot;Set1&amp;quot;)), random.order = FALSE, scale = c(10, 
    1), title = &amp;quot;All&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/cmdlt-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hpc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;HPC&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cmds.s = cmds %&amp;gt;% filter(machine != &amp;quot;laptop&amp;quot;, !grepl(&amp;quot;=&amp;quot;, 
    cmd), !grepl(&amp;quot;\\.&amp;quot;, cmd), !grepl(&amp;quot;/&amp;quot;, cmd), !grepl(&amp;quot;\\$&amp;quot;, 
    cmd), !grepl(&amp;quot;\\:&amp;quot;, cmd)) %&amp;gt;% group_by(cmd) %&amp;gt;% 
    summarize(n = n()) %&amp;gt;% mutate(freq = n/sum(n))
wordcloud(cmds.s$cmd, cmds.s$freq, colors = c(&amp;quot;black&amp;quot;, 
    brewer.pal(8, &amp;quot;Set1&amp;quot;)), random.order = FALSE, scale = c(10, 
    1), title = &amp;quot;All&amp;quot;, min.freq = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/cmdhpc-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Good see the usual suspects &lt;code&gt;ls&lt;/code&gt; and &lt;code&gt;cd&lt;/code&gt; and their “typo” versions &lt;code&gt;;s&lt;/code&gt;/&lt;code&gt;ks&lt;/code&gt;/&lt;code&gt;ld&lt;/code&gt; and &lt;code&gt;xs&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        </item>
      
    

  </channel>
</rss>
