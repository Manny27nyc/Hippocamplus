<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hippocamplus </title>
    <link>/Hippocamplus/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2017</rights>
    <updated>2017-09-19 00:00:00 &#43;0000 UTC</updated>

    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        <item>
          <title>MUMmerplots with ggplot2</title>
          <link>/Hippocamplus/2017/09/19/mummerplots-with-ggplot2/</link>
          <pubDate>Tue, 19 Sep 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2017/09/19/mummerplots-with-ggplot2/</guid>
          <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(magrittr)
library(GenomicRanges)
library(knitr)
library(ggplot2)
library(tidyr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;mummer-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MUMmer plot&lt;/h2&gt;
&lt;p&gt;The MUMmer plot that I want to reproduce showed three contigs overlapping a region of chr 14. I had filtered the delta file with &lt;code&gt;delta-filter -l 10000 -q -r&lt;/code&gt; to get only the contigs with the best alignments. I had used &lt;code&gt;mummerplot&lt;/code&gt; with the &lt;code&gt;-l&lt;/code&gt; layout option to reorder and orient the sequences to have a nice diagonal.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./imgs/mumplot-example.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;read-a-delta-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Read a delta file&lt;/h2&gt;
&lt;p&gt;The delta file is the default output of the &lt;a href=&#34;http://mummer.sourceforge.net/manual/#nucmer&#34;&gt;NUCmer alignment script&lt;/a&gt;. The format of the delta file is described more &lt;a href=&#34;http://mummer.sourceforge.net/manual/#nucmeroutput&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;readDelta &amp;lt;- function(deltafile) {
    lines = scan(deltafile, &amp;quot;a&amp;quot;, sep = &amp;quot;\n&amp;quot;, quiet = TRUE)
    lines = lines[-1]
    lines.l = strsplit(lines, &amp;quot; &amp;quot;)
    lines.len = lapply(lines.l, length) %&amp;gt;% as.numeric
    lines.l = lines.l[lines.len != 1]
    lines.len = lines.len[lines.len != 1]
    head.pos = which(lines.len == 4)
    head.id = rep(head.pos, c(head.pos[-1], length(lines.l) + 
        1) - head.pos)
    mat = matrix(as.numeric(unlist(lines.l[lines.len == 
        7])), 7)
    res = as.data.frame(t(mat[1:5, ]))
    colnames(res) = c(&amp;quot;rs&amp;quot;, &amp;quot;re&amp;quot;, &amp;quot;qs&amp;quot;, &amp;quot;qe&amp;quot;, &amp;quot;error&amp;quot;)
    res$qid = unlist(lapply(lines.l[head.id[lines.len == 
        7]], &amp;quot;[&amp;quot;, 2))
    res$strand = ifelse(res$qe - res$qs &amp;gt; 0, &amp;quot;+&amp;quot;, &amp;quot;-&amp;quot;)
    res
}

mumgp = readDelta(&amp;quot;../../data/mumplot-example.delta&amp;quot;)

mumgp %&amp;gt;% head %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;rs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;re&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qe&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;error&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;qid&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;strand&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;265577&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;265842&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;108520&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;108254&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;46&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;265577&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;265842&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;106438&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;106172&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;46&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;306695&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;306968&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;138241&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;138515&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1016956&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1017364&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27806&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27394&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1723715&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1723990&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34123&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33845&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1767531&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1767813&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33842&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34123&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Contig0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;+&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-contigs-with-poor-alignments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Filter contigs with poor alignments&lt;/h2&gt;
&lt;p&gt;For now, I filter contigs simply based on the size of the aligned segment. I keep only contigs with at least one aligned segment larger than a minimum size. Smaller alignment in these contigs are kept if in the same range as the large aligned segments. Eventually, I could also filter segment based on the number/proportion of errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filterMum &amp;lt;- function(df, minl = 1000, flanks = 10000) {
    coord = df %&amp;gt;% filter(abs(re - rs) &amp;gt; minl) %&amp;gt;% 
        group_by(qid) %&amp;gt;% summarize(qsL = min(qs) - 
        flanks, qeL = max(qe) + flanks, rs = min(rs)) %&amp;gt;% 
        ungroup %&amp;gt;% arrange(desc(rs)) %&amp;gt;% mutate(qid = factor(qid, 
        levels = unique(qid))) %&amp;gt;% select(-rs)
    merge(df, coord) %&amp;gt;% filter(qs &amp;gt; qsL, qe &amp;lt; qeL) %&amp;gt;% 
        mutate(qid = factor(qid, levels = levels(coord$qid))) %&amp;gt;% 
        select(-qsL, -qeL)
}

mumgp.filt = filterMum(mumgp, minl = 10000)
mumgp.filt %&amp;gt;% head %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;qid&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;rs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;re&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qe&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;error&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;strand&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1663946&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1665485&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;331648&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;330113&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;171&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1662200&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1684396&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;126037&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;103837&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;234&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1581333&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1582738&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;244635&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;243233&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;87&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1597381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1610746&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;145948&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;132626&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;157&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1610278&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1623358&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130561&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;117468&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contig1475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1616542&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1618080&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;331648&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;330113&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;146&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graph&lt;/h2&gt;
&lt;p&gt;I’m going for the same style as &lt;code&gt;mummerplot&lt;/code&gt; to compare.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mumgp.filt, aes(x = rs, xend = re, y = qs, yend = qe, 
    colour = strand)) + geom_segment() + geom_point(alpha = 0.5) + 
    facet_grid(qid ~ ., scales = &amp;quot;free&amp;quot;, space = &amp;quot;free&amp;quot;, 
        switch = &amp;quot;y&amp;quot;) + theme_bw() + theme(strip.text.y = element_text(angle = 180, 
    size = 5), strip.background = element_blank(), 
    legend.position = c(0.99, 0.01), legend.justification = c(1, 
        0), axis.text.y = element_blank(), axis.ticks.y = element_blank()) + 
    xlab(&amp;quot;reference sequence&amp;quot;) + ylab(&amp;quot;assembly&amp;quot;) + 
    scale_colour_brewer(palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/graph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not bad but it would look nicer if we flipped the contigs to have more or less a diagonal.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;diagonalize&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Diagonalize&lt;/h2&gt;
&lt;p&gt;For each contig, I compute the major strand (strand with most bases aligned) and flip if necessary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diagMum &amp;lt;- function(df) {
    major.strand = df %&amp;gt;% group_by(qid) %&amp;gt;% summarize(major.strand = ifelse(sum(sign(qe - 
        qs) * abs(qe - qs)) &amp;gt; 0, &amp;quot;+&amp;quot;, &amp;quot;-&amp;quot;), maxQ = max(c(qe, 
        qs)))
    merge(df, major.strand) %&amp;gt;% mutate(qs2 = ifelse(major.strand == 
        &amp;quot;-&amp;quot;, maxQ - qs, qs), qe2 = ifelse(major.strand == 
        &amp;quot;-&amp;quot;, maxQ - qe, qe), qs = qs2, qe = qe2) %&amp;gt;% 
        select(-qe2, -qs2, maxQ)
}

mumgp.filt.diag = diagMum(mumgp.filt)

ggplot(mumgp.filt.diag, aes(x = rs, xend = re, y = qs, 
    yend = qe, colour = strand)) + geom_segment() + 
    geom_point(alpha = 0.5) + facet_grid(qid ~ ., scales = &amp;quot;free&amp;quot;, 
    space = &amp;quot;free&amp;quot;, switch = &amp;quot;y&amp;quot;) + theme_bw() + theme(strip.text.y = element_text(angle = 180, 
    size = 5), strip.background = element_blank(), 
    legend.position = c(0.99, 0.01), legend.justification = c(1, 
        0), axis.text.y = element_blank(), axis.ticks.y = element_blank()) + 
    xlab(&amp;quot;reference sequence&amp;quot;) + ylab(&amp;quot;assembly&amp;quot;) + 
    scale_colour_brewer(palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./imgs/mumplot-example.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;percent-identity-and-coverage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Percent identity and coverage&lt;/h2&gt;
&lt;p&gt;Another useful MUMmerplot represents the position of each aligned segment and its percent similarity.&lt;/p&gt;
&lt;p&gt;This graph could be useful to decide which size/similarity threshold to use when filtering low alignments.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mumgp %&amp;lt;&amp;gt;% mutate(similarity = 1 - error/abs(qe - qs))
mumgp.filt %&amp;lt;&amp;gt;% mutate(similarity = 1 - error/abs(qe - 
    qs))

ggplot(mumgp, aes(x = rs, xend = re, y = similarity, 
    yend = similarity)) + geom_segment() + theme_bw() + 
    xlab(&amp;quot;reference sequence&amp;quot;) + ylab(&amp;quot;similarity&amp;quot;) + 
    ggtitle(&amp;quot;All contigs&amp;quot;) + ylim(0, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mumgp.filt, aes(x = rs, xend = re, y = similarity, 
    yend = similarity)) + geom_segment() + theme_bw() + 
    xlab(&amp;quot;reference sequence&amp;quot;) + ylab(&amp;quot;similarity&amp;quot;) + 
    ggtitle(&amp;quot;At least 10 Kbp aligned&amp;quot;) + ylim(0, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simgraph-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To better highlighted which region in the reference is covered, I annotate each base of the reference with the maximum similarity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;maxSimilarityDisjoin &amp;lt;- function(df) {
    ref.ir = GRanges(&amp;quot;X&amp;quot;, IRanges(df$rs, df$re), similarity = df$similarity)
    ## Efficient clean up of low similarity within high
    ## similarity
    step = 1
    while (step &amp;gt; 0) {
        largealign = ref.ir[head(order(rank(-ref.ir$similarity), 
            rank(-width(ref.ir))), step * 1000)]
        ol = findOverlaps(ref.ir, largealign, type = &amp;quot;within&amp;quot;) %&amp;gt;% 
            as.data.frame %&amp;gt;% mutate(simW = ref.ir$similarity[queryHits], 
            simL = largealign$similarity[subjectHits]) %&amp;gt;% 
            filter(simW &amp;lt; simL)
        if (length(largealign) == length(ref.ir)) {
            step = 0
        } else {
            step = step + 1
        }
        ref.ir = ref.ir[-ol$queryHits]
    }
    ## Disjoin and annotate with the max similarity
    ref.dj = disjoin(c(ref.ir, GRanges(&amp;quot;X&amp;quot;, IRanges(min(df$rs), 
        max(df$rs)), similarity = 0)))
    ol = findOverlaps(ref.ir, ref.dj) %&amp;gt;% as.data.frame %&amp;gt;% 
        mutate(similarity = ref.ir$similarity[queryHits]) %&amp;gt;% 
        group_by(subjectHits) %&amp;gt;% summarize(similarity = max(similarity))
    ref.dj$similarity = 0
    ref.dj$similarity[ol$subjectHits] = ol$similarity
    as.data.frame(ref.dj)
}

mumgp.sim = maxSimilarityDisjoin(mumgp)

mumgp.sim %&amp;gt;% select(similarity, start, end) %&amp;gt;% gather(end, 
    pos, 2:3) %&amp;gt;% ggplot() + geom_line(aes(x = pos, 
    y = similarity), alpha = 0.5, color = &amp;quot;red&amp;quot;) + 
    theme_bw() + xlab(&amp;quot;reference sequence&amp;quot;) + ylab(&amp;quot;similarity&amp;quot;) + 
    ggtitle(&amp;quot;All contigs&amp;quot;) + ylim(0, 1) + geom_segment(aes(x = rs, 
    xend = re, y = similarity, yend = similarity), 
    data = mumgp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcov-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mumgp.sim) + geom_segment(aes(x = start, xend = end, 
    yend = similarity, y = similarity), color = &amp;quot;red&amp;quot;, 
    size = 2) + theme_bw() + xlab(&amp;quot;reference sequence&amp;quot;) + 
    ylab(&amp;quot;similarity&amp;quot;) + ylim(0, 1) + geom_segment(aes(x = rs, 
    xend = re, y = similarity, yend = similarity), 
    data = mumgp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcov-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With this graph we could compare different assemblies or before/after filtering:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mumgp.filt.sim = maxSimilarityDisjoin(mumgp.filt)

mumgp.filt.m = rbind(mumgp.sim %&amp;gt;% mutate(filter = &amp;quot;before&amp;quot;), 
    mumgp.filt.sim %&amp;gt;% mutate(filter = &amp;quot;after&amp;quot;))

mumgp.filt.m %&amp;gt;% select(similarity, start, end, filter) %&amp;gt;% 
    gather(end, pos, 2:3) %&amp;gt;% ggplot(aes(x = pos, y = similarity, 
    colour = filter)) + geom_line(alpha = 0.8) + theme_bw() + 
    xlab(&amp;quot;reference sequence&amp;quot;) + ylab(&amp;quot;similarity&amp;quot;) + 
    ylim(0, 1) + scale_colour_brewer(palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcovcomp-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not so pretty but we see that a few region are not covered any more after our filtering. Maybe something like this instead :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mumgp.filt.m %&amp;gt;% filter(similarity == 0) %&amp;gt;% ggplot(aes(x = start, 
    xend = end, y = filter, yend = filter)) + geom_segment(size = 10) + 
    theme_bw() + xlab(&amp;quot;reference sequence&amp;quot;) + ylab(&amp;quot;filter&amp;quot;) + 
    scale_colour_brewer(palette = &amp;quot;Set1&amp;quot;) + ggtitle(&amp;quot;Reference regions not covered&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-19-MumplotsWithGgplot2_files/figure-html/simcovcomptrack-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Regression</title>
          <link>/Hippocamplus/2017/09/16/regression/</link>
          <pubDate>Sat, 16 Sep 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2017/09/16/regression/</guid>
          <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(broom)
library(magrittr)
library(dplyr)
library(knitr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;logistic-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic regression&lt;/h2&gt;
&lt;div id=&#34;one-way-or-another&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;a href=&#34;https://youtu.be/4kg9LasvLFE&#34;&gt;One way or another&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If we have two binary variables and we want to see if they are associated we could use a logistic regression. How do we decide which variable to be the predictor and which variable to observed variable ?&lt;/p&gt;
&lt;p&gt;In theory there shouldn’t be any differences but let’s check with a dummy example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df = data.frame(x = sample(c(FALSE, TRUE), 100, TRUE))
df$y = df$x
df$y[1:70] = sample(c(FALSE, TRUE), 70, TRUE)

glm(y ~ x, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3715636&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2906592&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.278348&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2011268&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1543229&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4189918&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.755001&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0058692&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm(x ~ y, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5947071&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3114205&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.909659&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0561771&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;yTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1543229&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4189918&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.755001&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0058692&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df$z = runif(100)
glm(y ~ x + z, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3981922&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4773038&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8342532&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4041383&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1514393&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4209176&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.7355455&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0062277&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;z&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0544962&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7742194&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0703886&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9438844&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm(x ~ y + z, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.9648122&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5104304&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.8901935&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0587321&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;yTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1514965&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4209562&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.7354309&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0062299&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;z&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7202536&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7723051&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9326024&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3510253&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Adding another predictor doesn’t change the estimates either.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interpretation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Interpretation&lt;/h3&gt;
&lt;p&gt;Just to make I understand the estimates correctly. It represents the log odds ratio change for each “unit” of the predictor. In the case of a binary variable, the log odds ratio between the two groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm(y ~ x, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3715636&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2906592&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.278348&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2011268&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1543229&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4189918&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.755001&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0058692&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;odds.y.ifx = mean(subset(df, x)$y)/mean(!subset(df, 
    x)$y)
odds.y.ifnotx = mean(subset(df, !x)$y)/mean(!subset(df, 
    !x)$y)
log(odds.y.ifx/odds.y.ifnotx)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.154323&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;extreme-cases&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extreme cases&lt;/h3&gt;
&lt;p&gt;How efficient is the logistic regression in cases where there is an imbalance between different types of observations ? For example if just a few genomic regions overlap an interesting annotation and I want to test is the overlap is significant.&lt;/p&gt;
&lt;p&gt;Let’s look at the worst cases when there are only 1 observation for a particular class.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df = data.frame(y = sample(c(FALSE, TRUE), 100, TRUE))
df$x = 1:nrow(df) %in% sample.int(nrow(df), 1)
glm(y ~ x, data = df, family = binomial()) %&amp;gt;% tidy %&amp;gt;% 
    kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1010961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2012644&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5023050&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6154530&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;xTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15.4649721&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1455.3975462&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0106259&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9915219&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Although the significance is low, the estimate seems quite high. I’ll repeat this process a bunch of time and with different number of supporting observations to have an idea of the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ext.df = lapply(1:500, function(ii) {
    res = lapply(1:10, function(ssi) {
        df$x = 1:nrow(df) %in% sample.int(nrow(df), 
            ssi)
        glm(y ~ x, data = df, family = binomial()) %&amp;gt;% 
            tidy %&amp;gt;% mutate(rep = ii, ss = ssi)
    })
    do.call(rbind, res)
})
ext.df = do.call(rbind, ext.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ext.df %&amp;gt;% filter(term == &amp;quot;xTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate)) + 
    geom_density(fill = &amp;quot;grey50&amp;quot;) + facet_grid(ss ~ 
    ., scales = &amp;quot;free&amp;quot;) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/lrextsimgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It seems like the estimate “inflation” is problematic mostly when there are only 1 or 2 supporting observations. If there are more than 5 supporting observations the estimate is correctly centered in 0.&lt;/p&gt;
&lt;p&gt;This problem is in fact called the &lt;a href=&#34;https://en.wikipedia.org/wiki/Separation_(statistics)&#34;&gt;problem of separation&lt;/a&gt;. There are two approaches to deal with it:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Firth logistic regression.&lt;/li&gt;
&lt;li&gt;Exact logistic regression.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/rms/index.html&#34;&gt;&lt;code&gt;rms&lt;/code&gt; package&lt;/a&gt; from &lt;a href=&#34;http://www.fharrell.com/2017/01/introduction.html&#34;&gt;Frank Harell&lt;/a&gt;. It implements a penalized maximum likelihood estimation of the model coefficients through the &lt;code&gt;lrm&lt;/code&gt; function which has a &lt;code&gt;penalty=&lt;/code&gt; parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rms)
extrms.df = lapply(1:200, function(ii) {
    res = lapply(1:10, function(ssi) {
        res = lapply(c(1, 3, 5), function(pen) {
            df$x = 1:nrow(df) %in% sample.int(nrow(df), 
                ssi)
            cc = lrm(y ~ x, data = df, penalty = pen)$coefficient
            data.frame(term = names(cc), estimate = cc, 
                rep = ii, ss = ssi, penalty = pen, 
                stringsAsFactors = FALSE)
        })
        do.call(rbind, res)
    })
    do.call(rbind, res)
})
extrms.df = do.call(rbind, extrms.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extrms.df %&amp;gt;% filter(term == &amp;quot;x&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate)) + 
    geom_density(fill = &amp;quot;grey50&amp;quot;) + facet_grid(ss ~ 
    penalty, scales = &amp;quot;free&amp;quot;) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/lrmsgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It definitely helps: the estimates are now much closer to 0. I don’t see much difference between penalties 1, 3 or 5.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/logistf/index.html&#34;&gt;&lt;code&gt;logistf&lt;/code&gt; package&lt;/a&gt;. It implements Firth’s bias reduction method with its &lt;code&gt;logistf&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(logistf)
extstf.df = lapply(1:200, function(ii) {
    res = lapply(1:10, function(ssi) {
        df$x = 1:nrow(df) %in% sample.int(nrow(df), 
            ssi)
        cc = logistf(y ~ x, data = df)$coefficient
        data.frame(term = names(cc), estimate = cc, 
            rep = ii, ss = ssi, stringsAsFactors = FALSE)
    })
    do.call(rbind, res)
})
extstf.df = do.call(rbind, extstf.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extstf.df %&amp;gt;% filter(term == &amp;quot;xTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate)) + 
    geom_density(fill = &amp;quot;grey50&amp;quot;) + facet_grid(ss ~ 
    ., scales = &amp;quot;free&amp;quot;) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/lrreggraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This works well too.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;more-advanced-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More advanced models&lt;/h2&gt;
&lt;p&gt;A dummy example with some code for Generalized Additive Models, LOESS and SVM.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nb.samp = 1000
df = data.frame(x = runif(nb.samp, 0, 100))
df$y = rnorm(nb.samp, 0, 5) + abs(df$x - 25)
df$y = ifelse(df$x &amp;gt; 40, rnorm(nb.samp, 0, 5) - df$x * 
    df$x/300 + 20, df$y)
ggplot(df, aes(x = x, y = y)) + geom_point(alpha = 0.5) + 
    theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/blm-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm.o = glm(y ~ x, data = df)
loess.o = loess(y ~ x, data = df)
library(mgcv)
gam.o = gam(y ~ s(x, bs = &amp;quot;cs&amp;quot;), data = df)
library(e1071)
svm.o = svm(y ~ x, data = df)

pred.df = rbind(df %&amp;gt;% mutate(y = predict(glm.o), model = &amp;quot;glm&amp;quot;), 
    df %&amp;gt;% mutate(y = predict(gam.o), model = &amp;quot;gam&amp;quot;), 
    df %&amp;gt;% mutate(y = predict(loess.o), model = &amp;quot;LOESS&amp;quot;), 
    df %&amp;gt;% mutate(y = predict(svm.o), model = &amp;quot;SVM&amp;quot;))

ggplot(df, aes(x = x, y = y)) + geom_point(alpha = 0.2) + 
    geom_line(aes(colour = model), size = 2, alpha = 0.9, 
        data = pred.df) + theme_bw() + scale_colour_brewer(palette = &amp;quot;Set1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-16-Regression_files/figure-html/blmmodels-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Enrichment between genomic regions</title>
          <link>/Hippocamplus/2017/09/05/enrichment-between-genomic-regions/</link>
          <pubDate>Tue, 05 Sep 2017 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2017/09/05/enrichment-between-genomic-regions/</guid>
          <description>&lt;p&gt;Testing if two sets of genomic regions overlap significantly is not straightforward. In the simple situation of regions of 1 bp (e.g. SNVs) we could use a hypergeometric test. When the regions are small enough and there are not too many, the hypergeometric test might also be a fair approximation.&lt;/p&gt;
&lt;p&gt;But when we manipulate many regions of variable size covering the entire genome it’s not as straightforward. The gene annotation is an example. The repeat annotation is even worse as it covers almost 50% of the genome and contains different families with very different size/location profiles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr)
library(magrittr)
library(broom)
library(knitr)
library(tidyr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;simulated-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulated data&lt;/h2&gt;
&lt;p&gt;In a very simple scenario of having only one chromosome of size 250 Mbp.&lt;/p&gt;
&lt;p&gt;First let’s create a function that draw random regions (ranges) in this chromosome.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(IRanges)
randRegions &amp;lt;- function(sizes, max.pos = 2.5e+08, max.iter = 10) {
    gr = IRanges(runif(length(sizes), 0, max.pos - 
        sizes), width = sizes)
    dup = which(countOverlaps(gr, gr) &amp;gt; 1)
    iter = 1
    while (iter &amp;lt;= max.iter &amp;amp; length(dup) &amp;gt; 0) {
        gr[dup] = IRanges(runif(length(dup), 0, max.pos - 
            sizes[dup]), width = sizes[dup])
        dup = which(countOverlaps(gr, gr) &amp;gt; 1)
    }
    return(gr)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now some regions will be our “repeats”: 10,000 regions from size 10 bp to 6 Kbp.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rep.r = randRegions(runif(10000, 10, 6000))
sum(width(rep.r))/2.5e+08&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1196666&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They cover 11.97% of the chromosome.&lt;/p&gt;
&lt;p&gt;Now if we have another set of regions and we want to know how much they overlap with the repeats we could use the hypergeometric test. With this test we assume that we are sampling bases in the genome and testing if it’s covered by a repeat. In that sense, we expect 11.97% of our regions to overlap a repeat. If we compare random regions there shouldn’t be a significant overlap and the distribution of the P-value should be flat.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testHG &amp;lt;- function(feat.r, nb = 1000, size = 1, nb.test = 3000, 
    total.b = 2.5e+08) {
    exp.b = sum(width(feat.r))
    sapply(1:nb.test, function(ii) {
        reg.r = randRegions(rep(size, nb))
        obs.ol = sum(overlapsAny(reg.r, feat.r))
        phyper(obs.ol, exp.b, total.b - exp.b, length(reg.r), 
            lower.tail = FALSE)
    })
}

ht.sim = rbind(data.frame(nb = 1000, size = 1, pv = testHG(rep.r, 
    1000, 1)), data.frame(nb = 1000, size = 1000, pv = testHG(rep.r, 
    1000, 1000)), data.frame(nb = 100, size = 1000, 
    pv = testHG(rep.r, 100, 1000)), data.frame(nb = 1000, 
    size = 100, pv = testHG(rep.r, 1000, 100)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ht.sim %&amp;gt;% mutate(nbsize = paste0(nb, &amp;quot; x &amp;quot;, size, 
    &amp;quot;bp&amp;quot;)) %&amp;gt;% group_by(nbsize) %&amp;gt;% arrange(pv) %&amp;gt;% 
    mutate(cumprop = (1:n())/n()) %&amp;gt;% ggplot(aes(x = pv, 
    y = cumprop, color = nbsize)) + geom_line() + theme_bw() + 
    geom_abline(linetype = 2) + ylab(&amp;quot;cumulative proportion&amp;quot;) + 
    xlab(&amp;quot;P-value&amp;quot;) + scale_color_brewer(palette = &amp;quot;Set1&amp;quot;, 
    name = &amp;quot;regions&amp;quot;) + theme(legend.justification = c(1, 
    0), legend.position = c(0.99, 0.01))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/testhggraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the hypergeometric test works well for region of 1 bp. Otherwise the distribution of the P-values is biased. The larger the regions the stronger the bias. To a lower extent, more regions also means more bias.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-control-regions-with-similar-features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using control regions with similar features&lt;/h2&gt;
&lt;p&gt;We want to control for the size distribution and the total number of regions tested. Instead of the hypergeometric test, we can get control regions and compare their overlap with the actual regions, using a logistic regression for example. The control regions must be randomly distributed in the genome but have the same size distribution as our original regions. In the logistic regression we compare the two binary variables: overlapping a repeat or not, being an original region or a control region.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testLR &amp;lt;- function(feat.r, nb = 1000, size = 1, nb.test = 3000) {
    sapply(1:nb.test, function(ii) {
        reg.r = randRegions(rep(size, nb))
        cont.r = randRegions(width(reg.r))
        df = rbind(data.frame(region = TRUE, ol = overlapsAny(reg.r, 
            feat.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
            feat.r)))
        pvs = glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
            tidy %&amp;gt;% .$p.value
        pvs[2]
    })
}

lr.sim = rbind(data.frame(nb = 1000, size = 1, pv = testLR(rep.r, 
    1000, 1)), data.frame(nb = 1000, size = 1000, pv = testLR(rep.r, 
    1000, 1000)), data.frame(nb = 100, size = 1000, 
    pv = testLR(rep.r, 100, 1000)), data.frame(nb = 1000, 
    size = 100, pv = testLR(rep.r, 1000, 100)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lr.sim %&amp;gt;% mutate(nbsize = paste0(nb, &amp;quot; x &amp;quot;, size, 
    &amp;quot;bp&amp;quot;)) %&amp;gt;% group_by(nbsize) %&amp;gt;% arrange(pv) %&amp;gt;% 
    mutate(cumprop = (1:n())/n()) %&amp;gt;% ggplot(aes(x = pv, 
    y = cumprop, color = nbsize)) + geom_line() + theme_bw() + 
    geom_abline(linetype = 2) + ylab(&amp;quot;cumulative proportion&amp;quot;) + 
    xlab(&amp;quot;P-value&amp;quot;) + scale_color_brewer(palette = &amp;quot;Set1&amp;quot;, 
    name = &amp;quot;regions&amp;quot;) + theme(legend.justification = c(1, 
    0), legend.position = c(0.99, 0.01))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/contreggraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The distribution of the P-values is much better.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;controlling-for-correlated-features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Controlling for correlated features&lt;/h2&gt;
&lt;p&gt;In the genome, the distribution of genes, repeats, functional regions, and others is not random. Different types of elements tend to be found together while others don’t. For example some repeats are located in GC-rich regions and others in AT-rich regions. Transposable elements don’t overlap exonic regions much. Their are hotspots of segmental duplications.&lt;/p&gt;
&lt;p&gt;Sometimes we want to control for the overlap with one (or more) genomic features to test the independent association of another. For example, we known copy number variants (CNVs) are enriched in segmental duplications and transposable elements are also enriched in segmental duplications. We might want to test if CNVs are independently enriched in regions with transposable elements, controlling for the overlap with segmental duplications.&lt;/p&gt;
&lt;p&gt;I tried to simulate a first set of regions that significantly overlaps our repeats and another one that significantly overlaps the first set. That way we should see a significant overlap with repeat when we test them separately, but the second one should be significant when we control for the first one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corRegions &amp;lt;- function(sizes, feat.r, or = 2, max.iter = 10, 
    max.pos = 2.5e+08) {
    reg.r = randRegions(sizes)
    for (ii in 1:or) {
        reg.r = c(reg.r[overlapsAny(reg.r, feat.r)], 
            randRegions(sizes))
    }
    dup = which(countOverlaps(reg.r, reg.r) &amp;gt; 1)
    sizes = width(reg.r)
    iter = 1
    while (iter &amp;lt;= max.iter &amp;amp; length(dup) &amp;gt; 0) {
        reg.r[dup] = IRanges(runif(length(dup), 0, 
            max.pos - sizes[dup]), width = sizes[dup])
        dup = which(countOverlaps(reg.r, reg.r) &amp;gt; 1)
    }
    reg.r
}

## First set of regions
repcor.r = corRegions(rep(10000, 1000), rep.r)
cont.r = randRegions(width(repcor.r))
df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcor.r, 
    rep.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
    rep.r)))
glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2375323&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0464770&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.11075&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3e-07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8549335&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0670786&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.74525&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Second set of regions
seed.r = randRegions(rep(10000, 6000))
seed.ol = overlapsAny(seed.r, repcor.r)
repcorcor.r = c(seed.r[seed.ol], seed.r[head(which(!seed.ol), 
    sum(!seed.ol) * 0.05)])
cont.r = randRegions(width(repcorcor.r))
df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcorcor.r, 
    rep.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
    rep.r)))
glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2231436&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0590620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.778125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0001580&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2214209&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0832684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.659123&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0078344&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;extending-the-logistic-regression-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extending the logistic regression model&lt;/h3&gt;
&lt;p&gt;One strategy is to add a variable in the model that represents the effect we want to control for.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcorcor.r, 
    rep.r), repcor = overlapsAny(repcorcor.r, repcor.r)), 
    data.frame(region = FALSE, ol = overlapsAny(cont.r, 
        rep.r), repcor = overlapsAny(cont.r, repcor.r)))
glm(ol ~ region + repcor, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2817899&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0612109&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.6035936&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0452678&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1093757&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4138742&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6789663&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;repcorTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4156934&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1096425&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.7913531&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0001498&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As expected, adding a variable in the model controls for this.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;better-control-regions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Better control regions&lt;/h3&gt;
&lt;p&gt;Another approach is to control the specific overlap in the control regions. We want to force our control regions to overlap as much with the feature as the original regions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;randRegionsCons &amp;lt;- function(reg.r, feat.r, nb.seed = 1e+06) {
    seed.r = randRegions(rep(1, nb.seed))
    dist.df = distanceToNearest(seed.r, feat.r) %&amp;gt;% 
        as.data.frame
    reg.ol = overlapsAny(reg.r, feat.r)
    res.r = lapply(unique(width(reg.r)), function(size) {
        size.ii = which(width(reg.r) == size)
        res.r = IRanges()
        if (sum(reg.ol[size.ii]) &amp;gt; 0) {
            seed.ii = dist.df %&amp;gt;% filter(distance &amp;lt; 
                size/2) %&amp;gt;% .$queryHits %&amp;gt;% sample(sum(reg.ol[size.ii]))
            res.r = c(res.r, resize(seed.r[seed.ii], 
                size, fix = &amp;quot;center&amp;quot;))
        }
        if (sum(!reg.ol[size.ii]) &amp;gt; 0) {
            seed.ii = dist.df %&amp;gt;% filter(distance &amp;gt; 
                size/2) %&amp;gt;% .$queryHits %&amp;gt;% sample(sum(!reg.ol[size.ii]))
            res.r = c(res.r, resize(seed.r[seed.ii], 
                size, fix = &amp;quot;center&amp;quot;))
        }
        res.r
    })
    do.call(c, res.r)
}

contSize.r = randRegionsCons(repcorcor.r, repcor.r)
df = rbind(data.frame(region = TRUE, ol = overlapsAny(repcorcor.r, 
    rep.r), repcor = overlapsAny(repcorcor.r, repcor.r)), 
    data.frame(region = FALSE, ol = overlapsAny(contSize.r, 
        rep.r), repcor = overlapsAny(contSize.r, repcor.r)))
glm(ol ~ region, data = df, family = binomial()) %&amp;gt;% 
    tidy %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1709578&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0589111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.901961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0037083&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1726805&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0831615&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.076448&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0378526&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It works too. One benefit of this approach is its interpretability: we can directly compare summary metrics using the control regions, e.g. like the proportion of regions overlapping repeats.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(repcorcor.r, repcor.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7812231&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(cont.r, repcor.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1395349&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(contSize.r, repcor.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7812231&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There might be another benefits in special situation with extreme overlap distribution. If only a few regions overlap the feature in the simple control regions, the regression might not correct for it as well as if forcing the control regions to be similar. Maybe there would some differences in power in those cases ?&lt;/p&gt;
&lt;p&gt;In practice I would do both: include the variable in the regression model and use regions with controlled overlap.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparing-different-sets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparing different sets&lt;/h2&gt;
&lt;p&gt;What if we need to compare sets of regions &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; with a third one &lt;em&gt;C&lt;/em&gt;. If the &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; are comparable in term of size and total number we could directly compare the overlap or an enrichment estimate (e.g. model estimate). If &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; have different size distribution or just total number of regions, these estimates may not be directly comparable. If they both overlap significantly with &lt;em&gt;C&lt;/em&gt;, the previous test (control regions + logistic regression) should test them significant. Even the P-value might be affected by the difference in size/number between the two sets. But how should we compared them ? Which interpretable metric could we use to compare enrichment of two different sets or regions ?&lt;/p&gt;
&lt;p&gt;A practical example would be two catalogs of CNVs, say from two different methods, that we want to compare to a functional annotation. If one catalogs has more CNVs, or has larger CNVs, how can we say which one overlaps better with the functional annotation ?&lt;/p&gt;
&lt;p&gt;I simulate this scenario and compare a few metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The fold-change in overlap proportion: proportion overlapping / proportion overlapping in control regions.&lt;/li&gt;
&lt;li&gt;The diff-change in overlap proportion: proportion overlapping - proportion overlapping in control regions.&lt;/li&gt;
&lt;li&gt;The logistic regression estimate which are log odds ratio.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, the main question was how should I simulate this. I ended up simulating two sets with similar odds ratio so we already know which metric will work better… One of the value of simulation is to force us to define the question. Or at least think about it. In this example, forcing two different sets to have similar odds ratio seemed more natural than trying to double the proportion for example. The odds ratio seems more fair to me and might avoid the situation where we are more likely to observe a large effect size just because the regions are rarer/smaller.&lt;/p&gt;
&lt;p&gt;Using a set of functional regions, I will try to compare a set of small CNVs and large CNVs. We expect more of the large CNVs to overlap the functional regions by chance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fun.r = randRegions(rep(10, 30000))
cnv.sm = randRegions(rep(1000, 1000))
cnv.lg = randRegions(rep(10000, 1000))
mean(overlapsAny(cnv.sm, fun.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.112&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(overlapsAny(cnv.lg, fun.r))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.688&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testLR &amp;lt;- function(reg.r, feat.r) {
    cont.r = randRegions(width(reg.r))
    df.sm = rbind(data.frame(region = TRUE, ol = overlapsAny(reg.r, 
        feat.r)), data.frame(region = FALSE, ol = overlapsAny(cont.r, 
        feat.r)))
    rbind(data.frame(term = &amp;quot;fold-change&amp;quot;, estimate = mean(overlapsAny(reg.r, 
        feat.r))/mean(overlapsAny(cont.r, feat.r)), 
        p.value = NA), data.frame(term = &amp;quot;diff-change&amp;quot;, 
        estimate = mean(overlapsAny(reg.r, feat.r)) - 
            mean(overlapsAny(cont.r, feat.r)), p.value = NA), 
        glm(ol ~ region, data = df.sm, family = binomial()) %&amp;gt;% 
            tidy %&amp;gt;% select(term, estimate, p.value))
}

metrics.df = rbind(testLR(cnv.sm, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.sm&amp;quot;), 
    testLR(cnv.lg, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.lg&amp;quot;))
metrics.df %&amp;gt;% filter(term != &amp;quot;(Intercept)&amp;quot;) %&amp;gt;% select(region, 
    term, estimate) %&amp;gt;% kable&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;region&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.sm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;fold-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0566038&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.sm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;diff-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0060000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.sm&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0617938&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.lg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;fold-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9745042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.lg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;diff-change&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0180000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cnv.lg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;regionTRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0852498&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;no-association&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;No association&lt;/h3&gt;
&lt;p&gt;If the CNVs are not enriched in the functional regions, how do the three metrics compare ?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df = lapply(1:1000, function(ii) {
    cnv.sm = randRegions(rep(1000, 1000))
    cnv.lg = randRegions(rep(10000, 1000))
    rbind(testLR(cnv.sm, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.sm&amp;quot;, 
        rep = ii), testLR(cnv.lg, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.lg&amp;quot;, 
        rep = ii))
})
null.df = do.call(rbind, null.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df %&amp;gt;% filter(term == &amp;quot;regionTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;log odds ratio&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvnoassocgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df %&amp;gt;% filter(term == &amp;quot;fold-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 1) + ggtitle(&amp;quot;fold-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvnoassocgraph-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null.df %&amp;gt;% filter(term == &amp;quot;diff-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;diff-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvnoassocgraph-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The three metrics are centered in 0 but the variance of the fold-change metric is much higher for the small CNVs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;association&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Association&lt;/h3&gt;
&lt;p&gt;If the odds of overlapping the functional regions are doubled.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df = lapply(1:1000, function(ii) {
    cnv.sm = randRegions(rep(1000, 1000))
    cnv.lg = randRegions(rep(10000, 1000))
    cnv.sm = c(cnv.sm[overlapsAny(cnv.sm, fun.r)], 
        randRegions(rep(1000, 1000)))
    cnv.lg = c(cnv.lg[overlapsAny(cnv.lg, fun.r)], 
        randRegions(rep(10000, 1000)))
    rbind(testLR(cnv.sm, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.sm&amp;quot;, 
        rep = ii), testLR(cnv.lg, fun.r) %&amp;gt;% mutate(region = &amp;quot;cnv.lg&amp;quot;, 
        rep = ii))
})
asso.df = do.call(rbind, asso.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df %&amp;gt;% filter(term == &amp;quot;regionTRUE&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;log odds ratio&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvassocgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df %&amp;gt;% filter(term == &amp;quot;fold-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 1) + ggtitle(&amp;quot;fold-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvassocgraph-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asso.df %&amp;gt;% filter(term == &amp;quot;diff-change&amp;quot;) %&amp;gt;% ggplot(aes(x = estimate, 
    colour = region)) + geom_density() + theme_bw() + 
    geom_vline(xintercept = 0) + ggtitle(&amp;quot;diff-change&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-09-05-GenomicRegionEnrichment_files/figure-html/cnvassocgraph-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected by construction, only the logistic regression estimate are similar. If we used the fold-change metric it would look like the small CNVs are more enriched; with the diff-change metric the large CNVs would.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Summary epigenetic mark tracks</title>
          <link>/Hippocamplus/2016/09/06/summary-epigenetic-mark-tracks/</link>
          <pubDate>Tue, 06 Sep 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2016/09/06/summary-epigenetic-mark-tracks/</guid>
          <description>&lt;p&gt;To assess the potential impact of variants (SNV, SVs) we might want to use some of the public epigentic datasets. The amount and heterogeneity of this data is a bit overwhelming. I would like to get a summary of which regions of the genome are the most functionally important.&lt;/p&gt;
&lt;p&gt;The plan is to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get annotated &lt;strong&gt;peaks&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;for the 6 &lt;strong&gt;typical histone marks&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;in &lt;strong&gt;5-6 tissues&lt;/strong&gt;, merging sub-tissues (e.g. brain subregions)&lt;/li&gt;
&lt;li&gt;keep regions &lt;strong&gt;supported by enough replicates&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Eventually, I could also annotate the regions that are tissue-specific or shared across tissues.&lt;/p&gt;
&lt;p&gt;The R-markdown source code is in the website’s &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/blob/gh-pages/_source/2016-09-06-epigeneticTracks.Rmd&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;annotationhub&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;AnnotationHub&lt;/h2&gt;
&lt;p&gt;I’ll use the &lt;a href=&#34;http://bioconductor.org/packages/release/bioc/html/AnnotationHub.html&#34;&gt;AnnotationHub&lt;/a&gt; package, which links Encode and EpigenomeRoadmap data (and more) directly in R.&lt;/p&gt;
&lt;p&gt;I search for &lt;em&gt;narrowPeak&lt;/em&gt; in &lt;em&gt;hg19&lt;/em&gt; from H3K27ac, H3K27me3, H3K36me3, H3K4me1, H3K4me3 or H3K9me3, in brain, blood, liver, muscle, lung, kidney, skin or heart. I also look for DNase peaks. Let’s see if I can find what I want.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/ahgraph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Most tissues have more than 3 tracks for each histone mark. I’ll just exclude liver and knidney that don’t. DNase is a bit more rare but there is at least one track per tissue. In total, it represents 360 different tracks, that I want to merge into one track per mark/tissue.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;download-and-merge-tracks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Download and merge tracks&lt;/h2&gt;
&lt;p&gt;For each mark/tissue, I download the available tracks, overlap the peaks into sub-peaks (&lt;em&gt;disjoin&lt;/em&gt;) and keep the pieces supported by more than half the tracks. Finally, these recurrent sub-peaks are stitched (&lt;em&gt;reduce&lt;/em&gt;) if closer than 500 bp.&lt;/p&gt;
&lt;p&gt;Afterwards, the regions for each mark is annotated with the number of tissues with overlapping regions.&lt;/p&gt;
&lt;p&gt;The results were uploaded there: &lt;a href=&#34;https://dl.dropboxusercontent.com/s/8c412u1ug2lwrc2/epiTracks.RData?dl=0&#34;&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/s/8c412u1ug2lwrc2/epiTracks.RData?dl=0&#34; class=&#34;uri&#34;&gt;https://dl.dropboxusercontent.com/s/8c412u1ug2lwrc2/epiTracks.RData?dl=0&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/overview-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/overview-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;./post/2016-09-06-epigeneticTracks_files/figure-html/overview-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;p&gt;I searched all tracks with keywords &lt;em&gt;&lt;span class=&#34;math&#34;&gt;\(tissue*, *\)&lt;/span&gt;mark&lt;/em&gt; (and &lt;em&gt;narrowPeak&lt;/em&gt;, &lt;em&gt;hg19&lt;/em&gt;). I’m &lt;strong&gt;not completely sure that the different tracks come from different replicates.&lt;/strong&gt; I think I avoided the “bioinformatics” replicates by taking only the &lt;em&gt;narrowPeaks&lt;/em&gt;. And when there are different sub-tissues (e.g. for brain), I decided to keep only regions supported by half the tracks, but then I &lt;strong&gt;might miss the specific a sub-tissue regions&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I also made &lt;strong&gt;some arbitrary choices&lt;/strong&gt;. For example, in for a particular mark/tissue, I stitch together regions that are at 500 bp or less. The main motivation is to reduce the amount of data. Also, I’m interested in large variants (SVs), so this resolution is fine.&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Gencode exploration</title>
          <link>/Hippocamplus/2016/06/04/gencode-exploration/</link>
          <pubDate>Sat, 04 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2016/06/04/gencode-exploration/</guid>
          <description>&lt;div id=&#34;gencode-v19&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gencode v19&lt;/h2&gt;
&lt;p&gt;I downloaded Gencode v19 at &lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&#34;&gt;&lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&#34; class=&#34;uri&#34;&gt;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;genes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Genes&lt;/h2&gt;
&lt;div id=&#34;number&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Number&lt;/h3&gt;
&lt;p&gt;Focusing on autosomes/X/Y, there are 57,783 “genes” of different types:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genetypes-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I merge the rare types into a &lt;em&gt;other&lt;/em&gt; class and some RNAs.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;gene_type.f&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20332&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;pseudogene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13931&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;other&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7417&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;lincRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7114&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;RNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5934&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;miRNA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3055&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;size&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Size&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genesize-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The largest annotated genes span more than 2 Mbp:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.Mbp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CNTNAP2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.304638&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PTPRD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.298478&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chrX&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DMD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.241765&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;LSAMP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.194861&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DLG2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.172912&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The smallest protein-coding annotated genes less than 100 bp:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.bp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC011308.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;59&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr12&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC055736.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PIH1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC012360.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;AC008914.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;protein_coding&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;102&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;density&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Density&lt;/h3&gt;
&lt;p&gt;Using non-overlapping windows of 1 Mb the gene density looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genedens-1.png&#34; width=&#34;768&#34; /&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/genedens-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chr 19, 17 and 11 have more protein-coding genes than the rest.&lt;/li&gt;
&lt;li&gt;Chr Y has more pseudogene compared to other classes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exons&lt;/h2&gt;
&lt;div id=&#34;number-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Number&lt;/h3&gt;
&lt;p&gt;Focusing on autosomes/X/Y, there are 1,196,256 “exons” from different types of genes:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exontype-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the rest of the analysis, I use only exons from protein-coding genes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;number-per-gene&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Number per gene&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exongene-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;mean.nb.exon&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;median.nb.exon&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;max.nb.exon&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;52.9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1696&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The gene with the most exons is the &lt;a href=&#34;http://www.genecards.org/cgi-bin/carddisp.pl?gene=TTN&#34;&gt;Titin gene&lt;/a&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;exon&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TTN&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1696&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SYNE1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1377&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;NEB&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1225&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CACNA1G&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1139&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;CACNA1C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1098&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;size-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Size&lt;/h3&gt;
&lt;p&gt;The average exon size is 232 bp.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exonsize-1.png&#34; width=&#34;768&#34; /&gt;&lt;img src=&#34;./post/2016-06-04-GencodeExploration_files/figure-html/exonsize-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The first exon seems to be slightly larger than the others. I used genes with at least 10 exons to be sure it’s not due to large single-exon genes.&lt;/p&gt;
&lt;p&gt;The largest annotated exons are more than 20 Kbp long:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.kb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRAPPC9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29.06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;MCC&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27.20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr12&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GRIN2B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr19&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;MUC16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21.69&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ABI2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20.55&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The smallest are just 1 bp !?&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;seqnames&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gene_name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size.bp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ALK&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ACAD11&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PPA2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;PAM&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;chr5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GALNT10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Preparing some genomic annotations</title>
          <link>/Hippocamplus/2016/06/03/preparing-some-genomic-annotations/</link>
          <pubDate>Fri, 03 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2016/06/03/preparing-some-genomic-annotations/</guid>
          <description>&lt;div id=&#34;mappability-track&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mappability track&lt;/h2&gt;
&lt;p&gt;I produced a mappability track from the UCSC track. The &lt;a href=&#34;http://hgdownload.soe.ucsc.edu/gbdb/hg19/bbi/wgEncodeCrgMapabilityAlign100mer.bw&#34;&gt;raw file&lt;/a&gt; contains, for each base in the genome, an estimation of the probability that a read is correctly mapped at this position.&lt;/p&gt;
&lt;p&gt;Using a sliding-window approach, I compute the average mappability in regions of size 1 Kbp. This is a more manageable amount of data and still informative, especially when interested in large regions (e.g. SVs).&lt;/p&gt;
&lt;p&gt;I used a custom Perl script to efficiently parse the bedGraph-transformed original file. See the code on &lt;a href=&#34;https://github.com/jmonlong/Hippocamplus/blob/gh-pages/_source/mappabilityBin.pl&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I uploaded the result there: &lt;a href=&#34;https://dl.dropboxusercontent.com/s/i537zjs65dpw34n/map100mer-1kbp.bed.gz?dl=0&#34;&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/s/i537zjs65dpw34n/map100mer-1kbp.bed.gz?dl=0&#34; class=&#34;uri&#34;&gt;https://dl.dropboxusercontent.com/s/i537zjs65dpw34n/map100mer-1kbp.bed.gz?dl=0&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can cut the genome into three mappability classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;unique&lt;/strong&gt; regions with high mappability estimate (&amp;gt;0.95).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;low-map&lt;/strong&gt; regions with a non-null mappability but lower than 0.95.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;no-map&lt;/strong&gt; regions with mappability 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-06-03-annotationPreparation_files/figure-html/summary-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;map.class&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mb&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;prop&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;unique&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2485.972&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.803&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;low-map&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;375.608&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.121&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;no-map&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;233.228&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.075&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Word Cloud in R</title>
          <link>/Hippocamplus/2016/02/26/word-cloud-in-r/</link>
          <pubDate>Fri, 26 Feb 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>/Hippocamplus/2016/02/26/word-cloud-in-r/</guid>
          <description>&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/wordcloud/index.html&#34;&gt;&lt;code&gt;wordcloud&lt;/code&gt; package&lt;/a&gt; is available on CRAN.&lt;/p&gt;
&lt;div id=&#34;fake-words&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fake words&lt;/h2&gt;
&lt;p&gt;I create fake words to see a bit how the command is working.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wordcloud)
createWords &amp;lt;- function(w.l = 3) paste(sample(letters, 
    w.l, TRUE), collapse = &amp;quot;&amp;quot;)
words = sapply(1:200, function(e) createWords(runif(1, 
    3, 10)))
freq = c(sample(1:30, 190, T), sample(30:150, 10, T))
freq = freq/sum(freq)
wordcloud(words, freq)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Big words in the center
wordcloud(words, freq, random.order = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Max word number
wordcloud(words, freq, max.words = 50)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Rotation: proportion of 90 degree
wordcloud(words, freq, rot.per = 0.01)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Color the most frequent words
wordcloud(words, freq, colors = c(&amp;quot;black&amp;quot;, &amp;quot;blue&amp;quot;, 
    &amp;quot;red&amp;quot;), random.order = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Color for each word
wordcloud(words, freq, colors = sample(c(&amp;quot;black&amp;quot;, &amp;quot;blue&amp;quot;, 
    &amp;quot;red&amp;quot;), length(words), TRUE), random.order = FALSE, 
    ordered.colors = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/example-6.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;command-history&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Command history&lt;/h2&gt;
&lt;p&gt;I retrieved the commands from my &lt;code&gt;.bash_history&lt;/code&gt; files (laptop and HPCs) and I want to make a word cloud showing the commands I use the most.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(RColorBrewer)
cmds = read.table(&amp;quot;../../data/bash-commands.tsv.gz&amp;quot;, 
    as.is = TRUE)
colnames(cmds) = c(&amp;quot;cmd&amp;quot;, &amp;quot;machine&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;laptop&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Laptop&lt;/h3&gt;
&lt;p&gt;By default the maximum history size was set to 500 commands so I don’t have the full set of commands, just the last 500. (I increased the limit, see you in 10,000 commands.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cmds.s = cmds %&amp;gt;% filter(machine == &amp;quot;laptop&amp;quot;, !grepl(&amp;quot;=&amp;quot;, 
    cmd), !grepl(&amp;quot;\\.&amp;quot;, cmd), !grepl(&amp;quot;/&amp;quot;, cmd)) %&amp;gt;% 
    group_by(cmd) %&amp;gt;% summarize(n = n()) %&amp;gt;% mutate(freq = n/sum(n))
wordcloud(cmds.s$cmd, cmds.s$freq, colors = c(&amp;quot;black&amp;quot;, 
    brewer.pal(8, &amp;quot;Set1&amp;quot;)), random.order = FALSE, scale = c(10, 
    1), title = &amp;quot;All&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/cmdlt-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hpc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;HPC&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cmds.s = cmds %&amp;gt;% filter(machine != &amp;quot;laptop&amp;quot;, !grepl(&amp;quot;=&amp;quot;, 
    cmd), !grepl(&amp;quot;\\.&amp;quot;, cmd), !grepl(&amp;quot;/&amp;quot;, cmd), !grepl(&amp;quot;\\$&amp;quot;, 
    cmd), !grepl(&amp;quot;\\:&amp;quot;, cmd)) %&amp;gt;% group_by(cmd) %&amp;gt;% 
    summarize(n = n()) %&amp;gt;% mutate(freq = n/sum(n))
wordcloud(cmds.s$cmd, cmds.s$freq, colors = c(&amp;quot;black&amp;quot;, 
    brewer.pal(8, &amp;quot;Set1&amp;quot;)), random.order = FALSE, scale = c(10, 
    1), title = &amp;quot;All&amp;quot;, min.freq = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2016-02-26-wordcloud_files/figure-html/cmdhpc-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Good see the usual suspects &lt;code&gt;ls&lt;/code&gt; and &lt;code&gt;cd&lt;/code&gt; and their “typo” versions &lt;code&gt;;s&lt;/code&gt;/&lt;code&gt;ks&lt;/code&gt;/&lt;code&gt;ld&lt;/code&gt; and &lt;code&gt;xs&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
        </item>
      
    

  </channel>
</rss>
